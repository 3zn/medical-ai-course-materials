{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequential Data Analysis with Deep Learning",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "qL7KO2SAQHuw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[![colab-logo](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/japan-medical-ai/medical-ai-course-materials/blob/master/notebooks/Sequential_Data_Analysis_with_Deep_Learning.ipynb)\n",
        "\n",
        "# 実践編: ディープラーニングを使ったモニタリングデータの時系列解析"
      ]
    },
    {
      "metadata": {
        "id": "6G2qenL-QR4S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "健康意識の高まりや運動人口の増加に伴って，活動量計などのウェアラブルデバイスが普及し始めています．センサーデバイスから心拍数などの情報を取得することで，リアルタイムに健康状態をモニタリングできる可能性があることから，近年ではヘルスケア領域での活用事例も増えてきています．2018年2月には，Cardiogram社とカリフォルニア大学が共同研究の成果を発表し，心拍数データに対してDeep Learningを適用することで，高精度に糖尿病予備群を予測可能であることを報告し，大きな注目を集めました．また，Apple Watch Series 4には心電図作成の機能が搭載されるなど，センサーデバイスも進歩を続け，より精緻な情報が取得できるようになってきています．こうした背景において，モニタリングデータを収集・解析し，健康管理に繋げていく取り組みは今後益々盛んになっていくものと考えられます．\n",
        "\n",
        "\n",
        "本章では，心電図の信号波形データを対象として，不整脈を検出する問題に取り組みます．"
      ]
    },
    {
      "metadata": {
        "id": "Yf3_nzfOQ4mk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 環境構築"
      ]
    },
    {
      "metadata": {
        "id": "oUE1bnmtQ7mW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "本章では, 下記のライブラリを利用します."
      ]
    },
    {
      "metadata": {
        "id": "cX4C1qqERA4F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Cupy\n",
        "* Chainer\n",
        "* Scipy\n",
        "* Matplotlib\n",
        "* Seaborn\n",
        "* Pandas\n",
        "* WFDB\n",
        "* Scikit-learn\n",
        "* Imbalanced-learn"
      ]
    },
    {
      "metadata": {
        "id": "IOG2_VY-RFJw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "以下のセルを実行 (Shift + Enter) して，必要なものをインストールして下さい. "
      ]
    },
    {
      "metadata": {
        "id": "b6zwznd_QUqg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt -y -q install tree\n",
        "!pip install wfdb==2.2.1 imbalanced-learn==0.4.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xmQRmQHW1mUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!curl https://colab.chainer.org/install | sh -"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHDRbMEQRQZ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "インストールが完了したら以下のセルを実行して，各ライブラリのインポート，及びバージョン確認を行って下さい."
      ]
    },
    {
      "metadata": {
        "id": "zlyEjUcRRJCL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import chainer\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import seaborn as sn\n",
        "import wfdb\n",
        "import sklearn\n",
        "import imblearn\n",
        "\n",
        "chainer.print_runtime_info()\n",
        "print(\"Scipy: \", scipy.__version__)\n",
        "print(\"Pandas: \", pd.__version__)\n",
        "print(\"Matplotlib: \", matplotlib.__version__)\n",
        "print(\"Seaborn: \", sn.__version__)\n",
        "print(\"WFDB: \", wfdb.__version__)\n",
        "print(\"Scikit-learn: \", sklearn.__version__)\n",
        "print(\"Imbalanced-learn: \", imblearn.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kyyJZRi3Z2AS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "また，本章の実行結果を再現可能なように，4章 (4.2.4.4) で紹介した乱数シードの固定を行います．\n",
        "\n",
        "（以降の計算を行う上で必ず必要となる設定ではありません．）"
      ]
    },
    {
      "metadata": {
        "id": "jHUmH48MbFx9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reset_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if chainer.cuda.available:\n",
        "        chainer.cuda.cupy.random.seed(seed)\n",
        "\n",
        "reset_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HAD7xxa6i2cH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 心電図(ECG)と不整脈診断について"
      ]
    },
    {
      "metadata": {
        "id": "DJAhIM6pi__I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**心電図(Electrocardiogram, ECG)**は，心筋の活動によって生じる電気的変動を記録したものであり，心電図検査は不整脈の診断に広く利用されている他，虚血性心疾患や呼吸器疾患などの診断にも利用可能です[[文献1](https://en.wikipedia.org/wiki/Electrocardiography), [文献2](https://www.ningen-dock.jp/wp/wp-content/uploads/2013/09/d4bb55fcf01494e251d315b76738ab40.pdf)]．\n",
        "\n",
        "標準的な心電図は，手足からとる心電図（四肢誘導）として，双極誘導（$Ⅰ$，$Ⅱ$，$Ⅲ$），及び単極誘導（$aV_R$，$aV_L$，$aV_F$）の6誘導，胸部からとる心電図（胸部誘導）として，$V_1$，$V_2$，$V_3$，$V_4$，$V_5$，$V_6$の6誘導，計12誘導から成ります．このうち，特に不整脈のスクリーニングを行う際には，$Ⅱ$誘導と$V_1$誘導に注目して診断が行われるのが一般的とされています．\n",
        "\n",
        "心臓が正常な状態では，ECGにおいては規則的な波形が観測され，これを**正常洞調律 (Normal sinus rhythm, NSR)**といいます．\n",
        "\n",
        "具体的には，以下の3つの主要な波形で構成されており，\n",
        "\n",
        "1. **P波**：心房の脱分極（心房の興奮）\n",
        "1. **QRS波**：心室の脱分極（心室の興奮）\n",
        "1. **T波**：心室の再分極（心室興奮の収まり）\n",
        "\n",
        "の順番で，下図のような波形が観測されます．\n",
        "\n",
        "![正常心電図の概略図](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/monitoring/sinus_rhythm.png)\n",
        "\n",
        "([[文献1](https://en.wikipedia.org/wiki/Electrocardiography)]より引用)\n",
        "\n",
        "こうした規則的な波形に乱れが生じ，調律に異常があると判断された場合，不整脈などの疑いがあるため，診断が行われることになります．"
      ]
    },
    {
      "metadata": {
        "id": "3v2kuCnmRdac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 使用するデータセット"
      ]
    },
    {
      "metadata": {
        "id": "eQZ6fRLZCz4H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここでは，ECGの公開データとして有名な[MIT-BIH Arrhythmia Database (mitdb)](https://www.physionet.org/physiobank/database/mitdb/)を使用します．\n",
        "\n",
        "47名の患者から収集した48レコードが登録されており，各レコードファイルには約30分間の2誘導($II$，$V_1$)のシグナルデータが格納されています．また，各R波のピーク位置に対してアノテーションが付与されています．(データとアノテーションの詳細については[こちら](https://www.physionet.org/physiobank/database/html/mitdbdir/intro.htm)を御覧ください．)\n",
        "\n",
        "データベースは[PhysioNet](https://www.physionet.org/)によって管理されており，ダウンロードや読み込み用のPythonパッケージが提供されているので，今回はそちらを利用してデータを入手します．"
      ]
    },
    {
      "metadata": {
        "id": "0tAhl0KJRZ1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_root = './dataset'\n",
        "download_dir = os.path.join(dataset_root, 'download')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R5wT-k6G6h4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "まずはmitdbデータベースをダウンロードしましょう．\n",
        "※実行時にエラーが出た場合は，再度実行して下さい．"
      ]
    },
    {
      "metadata": {
        "id": "hmX3OgAXR0Ug",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wfdb.dl_database('mitdb', dl_dir=download_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Uzp-QZ4D3sP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "無事ダウンロードが完了すると， `Finished downloading files` というメッセージが表示されます．\n",
        "\n",
        "ファイル一覧を確認してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "djD8QFXESMHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(sorted(os.listdir(download_dir)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KgMtCiKq4TcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ファイル名の数字はレコードIDを表しています．各レコードには3種類のファイルがあり，\n",
        "\n",
        "- `.dat` : シグナル（バイナリ形式）\n",
        "- `.atr` : アノテーション（バイナリ形式）\n",
        "- `.hea` : ヘッダ（バイナリファイルの読み込みに必要）\n",
        "\n",
        "となっています．"
      ]
    },
    {
      "metadata": {
        "id": "AzQYVT4NSmr2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## データ前処理"
      ]
    },
    {
      "metadata": {
        "id": "1v4SHt1jEAwC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ダウンロードしたファイルを読み込み，機械学習モデルへの入力形式に変換する**データ前処理**について説明します．\n",
        "\n",
        "本節では，以下の手順で前処理を行います．\n",
        "\n",
        "1. レコードIDを事前に 学習用 / 評価用 に分割\n",
        "    - 48レコードのうち，\n",
        "        - ID =（102, 104, 107, 217）のシグナルはペースメーカーの拍動が含まれるため除外します．\n",
        "        - ID = 114のシグナルは波形の一部が反転しているため，今回は除外します．\n",
        "        - ID = （201, 202）は同一の患者から得られたデータのため，202を除外します．\n",
        "    - 上記を除く計42レコードを，学習用とテスト用に分割します（分割方法は[[文献3](https://ieeexplore.ieee.org/document/1306572)]を参考）．\n",
        "1. シグナルファイル (.dat) の読み込み\n",
        "    - $Ⅱ$誘導シグナルと$V_1$誘導シグナルが格納されていますが，今回は$Ⅱ$誘導のみ利用します．\n",
        "    - サンプリング周波数は360 Hz なので，1秒間に360回のペースで数値が記録されていることになります．\n",
        "1.  アノテーションファイル (.atr) の読み込み\n",
        "    - 各R波ピークの位置 (positions) と，そのラベル (symbols) を取得します．\n",
        "1. シグナルの正規化\n",
        "    - 平均0，分散1になるように変換を行います．\n",
        "1. シグナルの分割 (segmentation)\n",
        "    - 各R波ピークを中心として2秒間(前後1秒ずつ)の断片を切り出していきます．\n",
        "1. 分割シグナルへのラベル付与\n",
        "    - 各R波ピークに付与されているラベルを，下表(※)に従って集約し，今回の解析では正常拍動 (Normal)，及び心室異所性拍動 (VEB) に対応するラベルが付与されている分割シグナルのみ学習・評価に利用します．\n",
        "    \n",
        "※ Association for the Advancement of Medical Instrumentation (AAMI)が推奨している基準([[文献3](https://ieeexplore.ieee.org/document/1306572)])で，5種類に大別して整理されています．\n",
        "\n",
        "![AAMIの分類基準](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/monitoring/aami_standard.png)\n",
        "\n",
        "([[文献4](https://arxiv.org/abs/1810.04121)]より引用)\n"
      ]
    },
    {
      "metadata": {
        "id": "YhdS_lLKMPxW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "まずは以下のセルを実行して，データ前処理クラスを定義しましょう．"
      ]
    },
    {
      "metadata": {
        "id": "bX7u2f5eR3VA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BaseECGDatasetPreprocessor(object):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            dataset_root,\n",
        "            window_size=720,  # 2 seconds\n",
        "    ):\n",
        "        self.dataset_root = dataset_root\n",
        "        self.download_dir = os.path.join(self.dataset_root, 'download')\n",
        "        self.window_size = window_size\n",
        "        self.sample_rate = 360.\n",
        "        # split list\n",
        "        self.train_record_list = [\n",
        "            '101', '106', '108', '109', '112', '115', '116', '118', '119', '122',\n",
        "            '124', '201', '203', '205', '207', '208', '209', '215', '220', '223', '230'\n",
        "        ]\n",
        "        self.test_record_list = [\n",
        "            '100', '103', '105', '111', '113', '117', '121', '123', '200', '210',\n",
        "            '212', '213', '214', '219', '221', '222', '228', '231', '232', '233', '234'\n",
        "        ]\n",
        "        # annotation\n",
        "        self.labels = ['N', 'V']\n",
        "        self.valid_symbols = ['N', 'L', 'R', 'e', 'j', 'V', 'E']\n",
        "        self.label_map = {\n",
        "            'N': 'N', 'L': 'N', 'R': 'N', 'e': 'N', 'j': 'N',\n",
        "            'V': 'V', 'E': 'V'\n",
        "        }\n",
        "\n",
        "    def _load_data(\n",
        "            self,\n",
        "            base_record,\n",
        "            channel=0  # [0, 1]\n",
        "    ):\n",
        "        record_name = os.path.join(self.download_dir, str(base_record))\n",
        "        # read dat file\n",
        "        signals, fields = wfdb.rdsamp(record_name)\n",
        "        assert fields['fs'] == self.sample_rate\n",
        "        # read annotation file\n",
        "        annotation = wfdb.rdann(record_name, 'atr')\n",
        "        symbols = annotation.symbol\n",
        "        positions = annotation.sample\n",
        "        return signals[:, channel], symbols, positions\n",
        "\n",
        "    def _normalize_signal(\n",
        "            self,\n",
        "            signal,\n",
        "            method='std'\n",
        "    ):\n",
        "        if method == 'minmax':\n",
        "            # Min-Max scaling\n",
        "            min_val = np.min(signal)\n",
        "            max_val = np.max(signal)\n",
        "            return (signal - min_val) / (max_val - min_val)\n",
        "        elif method == 'std':\n",
        "            # Zero mean and unit variance\n",
        "            signal = (signal - np.mean(signal)) / np.std(signal)\n",
        "            return signal\n",
        "        else:\n",
        "            raise ValueError(\"Invalid method: {}\".format(method))\n",
        "\n",
        "    def _segment_data(\n",
        "            self,\n",
        "            signal,\n",
        "            symbols,\n",
        "            positions\n",
        "    ):\n",
        "        X = []\n",
        "        y = []\n",
        "        sig_len = len(signal)\n",
        "        for i in range(len(symbols)):\n",
        "            start = positions[i] - self.window_size // 2\n",
        "            end = positions[i] + self.window_size // 2\n",
        "            if symbols[i] in self.valid_symbols and start >= 0 and end <= sig_len:\n",
        "                segment = signal[start:end]\n",
        "                assert len(segment) == self.window_size, \"Invalid length\"\n",
        "                X.append(segment)\n",
        "                y.append(self.labels.index(self.label_map[symbols[i]]))\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def preprocess_dataset(\n",
        "            self,\n",
        "            normalize=True\n",
        "    ):\n",
        "        # preprocess training dataset\n",
        "        self._preprocess_dataset_core(self.train_record_list, \"train\", normalize)\n",
        "        # preprocess test dataset\n",
        "        self._preprocess_dataset_core(self.test_record_list, \"test\", normalize)\n",
        "\n",
        "    def _preprocess_dataset_core(\n",
        "            self,\n",
        "            record_list,\n",
        "            mode=\"train\",\n",
        "            normalize=True\n",
        "    ):\n",
        "        Xs, ys = [], []\n",
        "        save_dir = os.path.join(self.dataset_root, 'preprocessed', mode)\n",
        "        for i in range(len(record_list)):\n",
        "            signal, symbols, positions = self._load_data(record_list[i])\n",
        "            if normalize:\n",
        "                signal = self._normalize_signal(signal)\n",
        "            X, y = self._segment_data(signal, symbols, positions)\n",
        "            Xs.append(X)\n",
        "            ys.append(y)\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        np.save(os.path.join(save_dir, \"X.npy\"), np.vstack(Xs))\n",
        "        np.save(os.path.join(save_dir, \"y.npy\"), np.concatenate(ys))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dxixFnx6EP7H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "データ保存先のrootディレクトリ(dataset_root)を指定し， `preprocess_dataset()` を実行することで，前処理後のデータがNumpy Array形式で所定の場所に保存されます．"
      ]
    },
    {
      "metadata": {
        "id": "zSFRco-FSsmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BaseECGDatasetPreprocessor(dataset_root).preprocess_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2DcLiL-1ZTSk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "実行後，以下のファイルが保存されていることを確認しましょう．\n",
        "\n",
        "* train/X.npy : 学習用シグナル\n",
        "* train/y.npy : 学習用ラベル\n",
        "* test/X.npy : 評価用シグナル\n",
        "* test/y.npy : 評価用ラベル"
      ]
    },
    {
      "metadata": {
        "id": "6LXhy1nmT-N5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tree ./dataset/preprocessed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nZa7kzJPElNO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次に，保存したファイルを読み込み，中身を確認してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "j5vghaTuSzmk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np.load(os.path.join(dataset_root, 'preprocessed', 'train', 'X.npy'))\n",
        "y_train = np.load(os.path.join(dataset_root, 'preprocessed', 'train', 'y.npy'))\n",
        "X_test = np.load(os.path.join(dataset_root, 'preprocessed', 'test', 'X.npy'))\n",
        "y_test = np.load(os.path.join(dataset_root, 'preprocessed', 'test', 'y.npy'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W5ftmdA6zAf2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "データセットのサンプル数はそれぞれ以下の通りです．\n",
        "\n",
        "* 学習用 : 47738個\n",
        "* 評価用 : 45349個\n",
        "\n",
        "各シグナルデータは，2 (sec) * 360 (Hz) = 720次元ベクトルとして表現されています．"
      ]
    },
    {
      "metadata": {
        "id": "Mj4_F6RVTEkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"X_train.shape = \", X_train.shape, \" \\t y_train.shape = \", y_train.shape)\n",
        "print(\"X_test.shape = \", X_test.shape, \" \\t y_test.shape = \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bNu5vvBL1eD4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "各ラベルはインデックスで表現されており，\n",
        "\n",
        "* 0 : 正常拍動 (Normal)\n",
        "* 1 : 心室異所性拍動 (VEB)\n",
        "\n",
        "となっています．\n",
        "\n",
        "学習用データセットに含まれている各ラベル毎のサンプル数をカウントしてみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "ss6w4JlJTYUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uniq_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "print(\"y_train count each labels: \", dict(zip(uniq_train, counts_train)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_vWWbRy4CpZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "評価用データについても同様にラベル毎のサンプル数をカウントします．"
      ]
    },
    {
      "metadata": {
        "id": "YaIUGDSQyvki",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uniq_test, counts_test = np.unique(y_test, return_counts=True)\n",
        "print(\"y_test count each labels: \", dict(zip(uniq_test, counts_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L31d0iKKBrvK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習用データ，評価用データ共に，VEBサンプルは全体の10%未満であり，大多数は正常拍動サンプルであることが分かります．"
      ]
    },
    {
      "metadata": {
        "id": "uyN7nUH1E5uI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次に，正常拍動，及びVEBのシグナルデータを可視化してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "TUpalkU0Tao1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXAuekJ6Edq7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "正常拍動の例を図示したものが以下になります．\n",
        "\n",
        "P波 - QRS波 - T波が規則的に出現していることが確認できます．"
      ]
    },
    {
      "metadata": {
        "id": "jOLyInm1TeBW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx_n = np.where(y_train == 0)[0]\n",
        "plt.plot(X_train[idx_n[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dojJ02FNF5u5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "一方でVEBの波形は規則性が乱れ，R波ピークの形状やピーク間距離も正常例とは異なる性質を示していることが分かります．"
      ]
    },
    {
      "metadata": {
        "id": "f_mYCNzwTlmz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx_s = np.where(y_train == 1)[0]\n",
        "plt.plot(X_train[idx_s[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7E6nqH2CIMYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "本章の目的は，ECGシグナル特徴をうまく捉え，新たな波形サンプルに対しても高精度に正常/異常を予測するモデルを構築することです．\n",
        "\n",
        "次節では，深層学習を利用したモデル構築について説明していきます．"
      ]
    },
    {
      "metadata": {
        "id": "kQEqTIlmTxPw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 深層学習を用いた時系列データ解析"
      ]
    },
    {
      "metadata": {
        "id": "irPb5xvfm_5j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習"
      ]
    },
    {
      "metadata": {
        "id": "Klt1--j8Iw08",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "まずはじめに，前節で準備した前処理済みデータをChainerで読み込むためのデータセットクラスを定義します．"
      ]
    },
    {
      "metadata": {
        "id": "oR3zBpQlTuWH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ECGDataset(chainer.dataset.DatasetMixin):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            path\n",
        "    ):\n",
        "        if os.path.isfile(os.path.join(path, 'X.npy')):\n",
        "            self.X = np.load(os.path.join(path, 'X.npy'))\n",
        "        else:\n",
        "            raise FileNotFoundError(\"{}/X.npy not found.\".format(path))\n",
        "        if os.path.isfile(os.path.join(path, 'y.npy')):\n",
        "            self.y = np.load(os.path.join(path, 'y.npy'))\n",
        "        else:\n",
        "            raise FileNotFoundError(\"{}/y.npy not found.\".format(path))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def get_example(self, i):\n",
        "        return self.X[None, i].astype(np.float32), self.y[i]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iNR4iHrWIsH3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "続いて，学習（＋予測）に利用するネットワーク構造を定義します．\n",
        "\n",
        "今回は，画像認識タスクで有名な，CNNベースの**ResNet34**と同様のネットワーク構造を利用します．[[文献5](https://arxiv.org/abs/1512.03385)]\n",
        "\n",
        "ただし，入力シグナルは1次元配列であることから，ここでは画像解析等で一般的に利用される2D Convolutionではなく，前章の遺伝子解析と同様，1D Convolutionを利用します．"
      ]
    },
    {
      "metadata": {
        "id": "i_uVEjDIT4s0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import reporter\n",
        "from chainer import Variable\n",
        "      \n",
        "    \n",
        "class BaseBlock(chainer.Chain):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            channels,\n",
        "            stride=1,\n",
        "            dilate=1\n",
        "    ):\n",
        "        self.stride = stride\n",
        "        super(BaseBlock, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.c1 = L.ConvolutionND(1, None, channels, 3, stride, dilate, dilate=dilate)\n",
        "            self.c2 = L.ConvolutionND(1, None, channels, 3, 1, dilate, dilate=dilate)\n",
        "            if stride > 1:\n",
        "                self.cd = L.ConvolutionND(1, None, channels, 1, stride, 0)\n",
        "            self.b1 = L.BatchNormalization(channels)\n",
        "            self.b2 = L.BatchNormalization(channels)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = F.relu(self.b1(self.c1(x)))\n",
        "        if self.stride > 1:\n",
        "            res = self.cd(x)\n",
        "        else:\n",
        "            res = x\n",
        "        h = res + self.b2(self.c2(h))\n",
        "        return F.relu(h)\n",
        "\n",
        "\n",
        "class ResBlock(chainer.Chain):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            channels,\n",
        "            n_block,\n",
        "            dilate=1\n",
        "    ):\n",
        "        self.n_block = n_block\n",
        "        super(ResBlock, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.b0 = BaseBlock(channels, 2, dilate)\n",
        "            for i in range(1, n_block):\n",
        "                bx = BaseBlock(channels, 1, dilate)\n",
        "                setattr(self, 'b{}'.format(str(i)), bx)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = self.b0(x)\n",
        "        for i in range(1, self.n_block):\n",
        "            h = getattr(self, 'b{}'.format(str(i)))(h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class ResNet34(chainer.Chain):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ResNet34, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.conv1 = L.ConvolutionND(1, None, 64, 7, 2, 3)\n",
        "            self.bn1 = L.BatchNormalization(64)\n",
        "            self.resblock0 = ResBlock(64, 3)\n",
        "            self.resblock1 = ResBlock(128, 4)\n",
        "            self.resblock2 = ResBlock(256, 6)\n",
        "            self.resblock3 = ResBlock(512, 3)\n",
        "            self.fc = L.Linear(None, 2)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = F.relu(self.bn1(self.conv1(x)))\n",
        "        h = F.max_pooling_nd(h, 3, 2)\n",
        "        for i in range(4):\n",
        "            h = getattr(self, 'resblock{}'.format(str(i)))(h)\n",
        "        h = F.average(h, axis=2)\n",
        "        h = self.fc(h)\n",
        "        return h\n",
        "      \n",
        "\n",
        "class Classifier(chainer.Chain):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            predictor,\n",
        "            lossfun=F.softmax_cross_entropy\n",
        "    ):\n",
        "        super(Classifier, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.predictor = predictor\n",
        "            self.lossfun = lossfun\n",
        "\n",
        "    def __call__(self, *args):\n",
        "        assert len(args) >= 2\n",
        "        x = args[:-1]\n",
        "        t = args[-1]\n",
        "        y = self.predictor(*x)\n",
        "\n",
        "        # loss\n",
        "        loss = self.lossfun(y, t)\n",
        "        with chainer.no_backprop_mode():\n",
        "            # other metrics\n",
        "            accuracy = F.accuracy(y, t)\n",
        "        # reporter\n",
        "        reporter.report({'loss': loss}, self)\n",
        "        reporter.report({'accuracy': accuracy}, self)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def predict(self, x):\n",
        "        with chainer.function.no_backprop_mode(), chainer.using_config('train', False):\n",
        "            x = Variable(self.xp.asarray(x, dtype=self.xp.float32))\n",
        "            y = self.predictor(x)\n",
        "            return y\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n2jCNB2zJCWa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習を実行するための準備として，以下の関数を用意します．\n",
        "\n",
        "- `create_train_dataset()`：学習用データセットを `ECGDataset` クラスに渡す\n",
        "- `create_trainer()`：学習に必要な設定を行い，Trainerオブジェクトを作成\n"
      ]
    },
    {
      "metadata": {
        "id": "YLOg6cJzT8EA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer import optimizers\n",
        "from chainer.optimizer import WeightDecay\n",
        "from chainer.iterators import MultiprocessIterator\n",
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "from chainer.training import triggers\n",
        "from chainer.backends.cuda import get_device_from_id\n",
        "\n",
        "\n",
        "def create_train_dataset(root_path):\n",
        "    train_path = os.path.join(root_path, 'preprocessed', 'train')\n",
        "    train_dataset = ECGDataset(train_path)\n",
        "\n",
        "    return train_dataset\n",
        "\n",
        "\n",
        "def create_trainer(\n",
        "    batchsize, train_dataset, nb_epoch=1,\n",
        "    device=0, lossfun=F.softmax_cross_entropy\n",
        "):\n",
        "    # setup model\n",
        "    model = ResNet34()\n",
        "    train_model = Classifier(model, lossfun=lossfun)\n",
        "\n",
        "    # use Adam optimizer\n",
        "    optimizer = optimizers.Adam(alpha=0.001)\n",
        "    optimizer.setup(train_model)\n",
        "    optimizer.add_hook(WeightDecay(0.0001))\n",
        "\n",
        "    # setup iterator\n",
        "    train_iter = MultiprocessIterator(train_dataset, batchsize)\n",
        "\n",
        "    # define updater\n",
        "    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
        "\n",
        "    # setup trainer\n",
        "    stop_trigger = (nb_epoch, 'epoch')\n",
        "    trainer = training.trainer.Trainer(updater, stop_trigger)\n",
        "    logging_attributes = [\n",
        "        'epoch', 'iteration',\n",
        "        'main/loss', 'main/accuracy'        \n",
        "    ]\n",
        "    trainer.extend(\n",
        "        extensions.LogReport(logging_attributes, trigger=(2000 // batchsize, 'iteration'))\n",
        "    )\n",
        "    trainer.extend(\n",
        "        extensions.PrintReport(logging_attributes)\n",
        "    )\n",
        "    trainer.extend(\n",
        "        extensions.ExponentialShift('alpha', 0.75, optimizer=optimizer),\n",
        "        trigger=(4000 // batchsize, 'iteration')\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4xYAJmBgJqY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "これで学習の準備が整ったので，関数を呼び出してtrainerを作成します．"
      ]
    },
    {
      "metadata": {
        "id": "LrhgE0WKUBxz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = create_train_dataset(dataset_root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uXfgr6e9UE4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer = create_trainer(256, train_dataset, nb_epoch=1, device=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JdDyLjLNJOFX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは学習を開始しましょう. (1分30秒程度で学習が完了します．)"
      ]
    },
    {
      "metadata": {
        "id": "aeNkaPdFUIfQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%time trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBpKeAFpvpWD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習が問題なく進めば，main/accuracyが0.99 (99%)付近まで到達していると思います．"
      ]
    },
    {
      "metadata": {
        "id": "NpgKemAtnV_f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 評価"
      ]
    },
    {
      "metadata": {
        "id": "dX54l8duJUqC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習したモデルを評価用データに当てはめて識別性能を確認するため，以下の関数を用意します．\n",
        "\n",
        "- `create_test_dataset()` : 評価用データの読み込み\n",
        "- `evaluate()` : 推論を行い結果を出力\n",
        "- `print_confusion_matrix()` : 予測結果から混同行列を作成\n",
        "- `print_scores()` : 予測結果から各種スコアを計算して表示"
      ]
    },
    {
      "metadata": {
        "id": "5CtgdOcbdn2i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer import cuda\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def create_test_dataset(root_path):\n",
        "    test_path = os.path.join(root_path, 'preprocessed', 'test')\n",
        "    test_dataset = ECGDataset(test_path)\n",
        "    return test_dataset\n",
        "\n",
        "  \n",
        "def evaluate(trainer, test_dataset, batchsize, device=-1):\n",
        "    model = trainer.updater.get_optimizer('main').target\n",
        "    ys = []\n",
        "    ts = []\n",
        "    for i in range(len(test_dataset) // batchsize + 1):\n",
        "        if i == len(test_dataset) // batchsize:\n",
        "            X, t = zip(*test_dataset[i*batchsize: len(test_dataset)])\n",
        "        else:\n",
        "            X, t = zip(*test_dataset[i*batchsize:(i+1)*batchsize])\n",
        "        X = cuda.to_gpu(np.array(X), device)\n",
        "        y = model.predict(X)\n",
        "        y = cuda.to_cpu(y.data.argmax(axis=1))\n",
        "        ys.append(y)\n",
        "        ts.append(np.array(t))\n",
        "    return np.concatenate(ts), np.concatenate(ys)\n",
        "\n",
        "  \n",
        "def print_confusion_matrix(y_true, y_pred):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    target_names = ['Normal', 'VEB']\n",
        "    cmx = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    df_cmx = pd.DataFrame(cmx, index=target_names, columns=target_names)\n",
        "    plt.figure(figsize = (5,3))\n",
        "    sn.heatmap(df_cmx, annot=True, annot_kws={\"size\": 18}, fmt=\"d\", cmap='Blues')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def print_scores(y_true, y_pred):\n",
        "    target_names = ['Normal', 'VEB']\n",
        "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "    print(\"accuracy: \", accuracy_score(y_true, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJsomKvlyvr2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "評価用データセットを用意し，"
      ]
    },
    {
      "metadata": {
        "id": "FNq4f8m3nVBW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dataset = create_test_dataset(dataset_root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EU-hnKu_yVwF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "評価用データに対して予測を行います． (17秒程度で予測が完了します)"
      ]
    },
    {
      "metadata": {
        "id": "TFq-W4Bgnjzg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%time y_true_test, y_pred_test = evaluate(trainer, test_dataset, 256, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3GsrOipy4BO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "予測結果の混同行列を確認してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "o1hGRaQ2HuLN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_confusion_matrix(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V42Ay9Hr1c9X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "続いて，予測結果の各種スコアを表示してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "2lzEaH9oyvEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_scores(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PVjh6T9l1hC7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "サンプル数が多い正常拍動に対する予測スコアは高い値を示す一方で，サンプル数の少ないVEBに対しては，スコアが低くなる傾向があります．今回のデータセットのように，サンプルが占めるクラスの割合が極端に偏っている不均衡データでは，こうした傾向がしばしば観測されることが知られています．\n",
        "\n",
        "次節では，このようなクラス不均衡問題への対応をはじめとして，予測モデルを改善するための試行錯誤について幾つか紹介していきます．\n"
      ]
    },
    {
      "metadata": {
        "id": "YZK61esDYVYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 精度向上に向けて"
      ]
    },
    {
      "metadata": {
        "id": "vYgRRiSl0NCG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "本節では，前節にて構築した学習器に対して，「データセット」「目的関数」「学習モデル」「前処理」といった様々な観点で工夫を行うことで，精度改善に寄与する方法を模索していきます．\n",
        "\n",
        "機械学習を用いて解析を行う際には，どの工夫が精度改善に有効なのか予め分からない場合が多く，試行錯誤が必要となります．ただし，手当たり次第の方法を試すことは得策では無いので，対象とするデータセットの性質に基づいて，有効となり得る手段を検討していくことが重要となります．\n",
        "\n",
        "まずはじめに，前節でも課題として挙がっていた，クラス不均衡の問題への対処法から検討していきましょう．"
      ]
    },
    {
      "metadata": {
        "id": "KPTsLjqklF30",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### クラス不均衡データへの対応"
      ]
    },
    {
      "metadata": {
        "id": "nVCVJPDf4PVc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "前節でも触れたように，**クラス不均衡データ**を用いて学習器を構築する際，大多数を占めるクラスに偏った予測結果となり，少数のクラスに対して精度が低くなってしまう場合があることが一般的に知られています．一方で，（今回のデータセットを含めて）現実世界のタスクにおいては，大多数の正常サンプルの中に含まれる少数の異常サンプルを精度良く検出することが重要であるというケースは少なくありません．こうした状況において，少数クラスの検出に注目してモデルを学習するための方策が幾つか存在します．\n",
        "\n",
        "具体的には，\n",
        "\n",
        "1. **サンプリング**\n",
        "    - 不均衡データセットからサンプリングを行い，クラス比率のバランスが取れたデータセットを作成．\n",
        "        - **Undersampling** : 大多数の正常サンプルを削減．\n",
        "        - **Oversampling**  : 少数の異常サンプルを水増し．\n",
        "1. **損失関数の重み調整**\n",
        "    - 正常サンプルを異常と誤分類した際のペナルティを小さく，異常サンプルを正常と誤分類した際のペナルティを大きくする．\n",
        "    - 例えば，サンプル数の存在比率の逆数を重みとして利用．\n",
        "1. **目的関数(損失関数)の変更**\n",
        "    - 異常サンプルに対する予測スコアを向上させるような目的関数を導入．\n",
        "1. **異常検知**\n",
        "    - 正常サンプルのデータ分布を仮定し，そこから十分に逸脱したサンプルを異常とみなす．\n",
        "\n",
        "などの方法があります．本節では，「1.サンプリング」，「3.目的関数の変更」の例を紹介していきます．"
      ]
    },
    {
      "metadata": {
        "id": "u6tD0TqYYt1D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### サンプリング\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_enZyrwC-hDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Undersampling**と**Oversampling**を組み合わせて，データセットの不均衡を解消することを考えます．\n",
        "\n",
        "今回は以下のステップでサンプリングを行います．\n",
        "\n",
        "1. Undersamplingにより，正常拍動サンプルのみ1/4に削減 (VEBサンプルは全て残す)\n",
        "    * ここでは，単純なランダムサンプリングを採用します．ランダム性があるため，分類にとって重要な（VEBサンプルとの識別境界付近にある）サンプルを削除してしまう可能性があります．\n",
        "    * ランダムサンプリングの問題を緩和する手法も幾つか存在しますが，今回は使用しません．\n",
        "1. Oversamplingにより，Undersampling後の正常拍動サンプルと同数になるまでVEBサンプルを水増し\n",
        "    * SMOTE (Synthetic Minority Over-sampling TEchnique) という手法を採用します．\n",
        "    * ランダムにデータを水増しする最も単純な方法だと，過学習を引き起こしやすくなります．SMOTEでは，VEBサンプルと，その近傍VEBサンプルとの間のデータ点をランダムに生成してデータに追加していくことで，過学習の影響を緩和しています．\n",
        "\n",
        "サンプリングを行うために， `SampledECGDataset` クラスを定義します．\n",
        "\n",
        "また，そのクラスを読み込んで学習用データセットオブジェクトを作成する `create_sampled_train_datset()` 関数を用意します．\n"
      ]
    },
    {
      "metadata": {
        "id": "91tUbBvilRxG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from imblearn.datasets import make_imbalance\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "class SampledECGDataset(ECGDataset):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            path\n",
        "    ):\n",
        "        super(SampledECGDataset, self).__init__(path)\n",
        "        _, counts = np.unique(self.y, return_counts=True)\n",
        "        self.X, self.y = make_imbalance(\n",
        "            self.X, self.y,\n",
        "            sampling_strategy={0: counts[0]//4, 1: counts[1]}\n",
        "        )\n",
        "        smote = SMOTE(random_state=42)\n",
        "        self.X, self.y = smote.fit_sample(self.X, self.y)\n",
        "\n",
        "        \n",
        "def create_sampled_train_dataset(root_path):\n",
        "    train_path = os.path.join(root_path, 'preprocessed', 'train')\n",
        "    train_dataset = SampledECGDataset(train_path)\n",
        "\n",
        "    return train_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pdpAAftuwfBD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = create_sampled_train_dataset(dataset_root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLJ3AGo9bmNH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは先程と同様に，trainerを作成して学習を実行してみましょう．(1分程度で学習が完了します．)"
      ]
    },
    {
      "metadata": {
        "id": "UpyvYJMyoxOM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer = create_trainer(256, train_dataset, nb_epoch=2, device=0)\n",
        "%time trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LL0k_u5ubzv0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習が完了したら，評価用データで予測を行い，精度を確認してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "n3P1Mqnhpkrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%time y_true_test, y_pred_test = evaluate(trainer, test_dataset, 256, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ThK6B8xppt8W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_confusion_matrix(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DM8aI7hOpuA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_scores(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWg_Xn_Xb77g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "先程の予測結果と比較して，サンプリングの効果によりVEBサンプルに対する検出精度（特にrecall）が向上しているかを確認してみて下さい．\n",
        "\n",
        "(サンプリングのランダム性や，学習の初期値依存性などの影響があるため，必ず精度向上するとは限らないことにご注意下さい．)"
      ]
    },
    {
      "metadata": {
        "id": "0LtXj5nrpztA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 損失関数の変更"
      ]
    },
    {
      "metadata": {
        "id": "0mF7a6A_h38t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "続いて，**損失関数を変更**することで，少数の異常サンプルに対して精度向上させる方法を検討します．少数クラスの予測精度向上に注目した損失関数はこれまでに幾つも提案されていますが，今回はその中で，**Focal loss** という損失関数を利用します．\n",
        "\n",
        "Focal lossは，画像の物体検知手法の研究論文 [[文献6](https://arxiv.org/abs/1708.02002)] の中で提案された損失関数です．One-stage物体検知手法において，大量の候補領域の中で実際に物体が存在する領域はたかだか数個であることが多く，クラス不均衡なタスクになっており，学習がうまく進まないという問題があります．こうした問題に対処するために提案されたのがfocal lossであり，以下の式によって記述されます．\n",
        "\n",
        "$$\n",
        "FL(p_t) = - (1 - p_t)^{\\gamma}\\log(p_t)\n",
        "$$\n",
        "\n",
        "ここで$p_t$はSoftmax関数の出力（確率値）です．$\\gamma = 0$の場合，通常のSoftmax cross-entorpy lossと等しくなりますが，$\\gamma > 0$の場合，明確に分類可能な（識別が簡単な）サンプルに対して，相対損失を小さくする効果があります．その結果，分類が難しいサンプルにより注目して学習が進んでいくことが期待されます．\n",
        "\n",
        "下図は，正解クラスの予測確率値と，その際の損失の関係をプロットしており，$\\gamma$の値を変化させた場合に，相対損失がどのように下がっていくかを示しています．\n",
        "\n",
        "![正解予測確率と損失の関係](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/monitoring/focal_plot.png)\n",
        "\n",
        "([[文献6](https://arxiv.org/abs/1708.02002)]より引用)\n",
        "\n",
        "それでは実際に，Focal loss関数を定義してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "umASFtsw4XyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer.backends.cuda import get_array_module\n",
        "\n",
        "def focal_loss(x, t, class_num=2, gamma=0.5, eps=1e-6):\n",
        "    xp = get_array_module(t)\n",
        "\n",
        "    p = F.softmax(x)\n",
        "    p = F.clip(p, x_min=eps, x_max=1-eps)\n",
        "    log_p = F.log_softmax(x)\n",
        "    t_onehot = xp.eye(class_num)[t.ravel()]\n",
        "\n",
        "    loss_sce = -1 * t_onehot * log_p\n",
        "    loss_focal = F.sum(loss_sce * (1. - p) ** gamma, axis=1)\n",
        "\n",
        "    return F.mean(loss_focal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rdc0wPArpvIX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "前項目で実施したデータサンプリングは行わず，初期(§8.5)の学習時と同様の設定にした上で，損失関数をfocal lossに変更します．\n"
      ]
    },
    {
      "metadata": {
        "id": "Y64crW5o6Cxg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = create_train_dataset(dataset_root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ee4pqByA6Lm9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer = create_trainer(256, train_dataset, nb_epoch=1, device=0, lossfun=focal_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9LjwPBTXqQ_k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは学習を開始しましょう．(1分30秒ほどで学習が完了します．)"
      ]
    },
    {
      "metadata": {
        "id": "xfgBxkaZ6sGm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%time trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EaVcFO7rrWQ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習が完了したら，評価用データにて予測結果を確認してみましょう．"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X3dGV0Z9kWK6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%time y_true_test, y_pred_test = evaluate(trainer, test_dataset, 256, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CnN8bb_0kWK_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_confusion_matrix(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GJ1wY_0ZkWLC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_scores(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8OpQJTcOrc8s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "初期モデルの予測結果と，今回の予測結果を比較してみて下さい．\n",
        "\n",
        "（余力があれば，$\\gamma$の値を変化させた場合に，予測結果にどのような影響があるか確認してみて下さい．）"
      ]
    },
    {
      "metadata": {
        "id": "PRMXPtNqvKya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ネットワーク構造の変更"
      ]
    },
    {
      "metadata": {
        "id": "yKCFw0pVsiSc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "続いて，学習に用いる**ネットワーク構造を変更**することを検討します．\n",
        "\n",
        "ここでは，最初に用いたResNet34構造に対して以下の拡張を行います．\n",
        "\n",
        "1. 1D Convolutionを，**1D Dilated Convolution**に変更\n",
        "    - Dilated Convolutionを用いることで，パラメータ数の増大を抑えながら，より広範囲の特徴を抽出可能になると期待されます（遺伝子解析の際と同様のモチベーション）．\n",
        "    - 広範囲の特徴が重要でないタスクの場合には，精度向上に繋がらない（または，場合によっては精度が低下する）可能性もあります．\n",
        "1. 最終層の手前に全結合層を追加し，**Dropout**を適用\n",
        "    - Dropoutを行うことで，学習器の汎化性能が向上することを期待します．ただし複数の先行研究([[文献7](https://arxiv.org/abs/1506.02158v6)]など)において，単純に畳み込み層の直後にDropoutを適用するだけでは汎化性能の向上が期待出来ないと報告されていることから，今回は全結合層に適用することにします．\n",
        "\n",
        "それでは，上記の拡張を加えたネットワークを定義しましょう．（ResBlockクラスは，初期モデル構築時に定義済み）\n",
        "   "
      ]
    },
    {
      "metadata": {
        "id": "h5-FR_e5wezQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DilatedResNet34(chainer.Chain):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DilatedResNet34, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.conv1 = L.ConvolutionND(1, None, 64, 7, 2, 3)\n",
        "            self.bn1 = L.BatchNormalization(64)\n",
        "            self.resblock0 = ResBlock(64, 3, 1)\n",
        "            self.resblock1 = ResBlock(128, 4, 1)\n",
        "            self.resblock2 = ResBlock(256, 6, 2)\n",
        "            self.resblock3 = ResBlock(512, 3, 4)\n",
        "            self.fc1 = L.Linear(None, 512)\n",
        "            self.fc2 = L.Linear(None, 2)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = F.relu(self.bn1(self.conv1(x)))\n",
        "        h = F.max_pooling_nd(h, 3, 2)\n",
        "        for i in range(4):\n",
        "            h = getattr(self, 'resblock{}'.format(str(i)))(h)\n",
        "        h = F.average(h, axis=2)\n",
        "        h = F.dropout(self.fc1(h), 0.5)\n",
        "        h = self.fc2(h)\n",
        "        return h\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ait4aFm7At_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "初期(§8.5)の学習時と同様の設定にした上で，ネットワーク構造を `DilatedResNet34` に変更して学習を行います．"
      ]
    },
    {
      "metadata": {
        "id": "bGGFdPWIJ_kW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_trainer(\n",
        "    batchsize, train_dataset, nb_epoch=1,\n",
        "    device=0, lossfun=F.softmax_cross_entropy\n",
        "):\n",
        "    # setup model\n",
        "    model = DilatedResNet34()\n",
        "    train_model = Classifier(model, lossfun=lossfun)\n",
        "\n",
        "    # use Adam optimizer\n",
        "    optimizer = optimizers.Adam(alpha=0.001)\n",
        "    optimizer.setup(train_model)\n",
        "    optimizer.add_hook(WeightDecay(0.0001))\n",
        "\n",
        "    # setup iterator\n",
        "    train_iter = MultiprocessIterator(train_dataset, batchsize)\n",
        "\n",
        "    # define updater\n",
        "    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
        "\n",
        "    # setup trainer\n",
        "    stop_trigger = (nb_epoch, 'epoch')\n",
        "    trainer = training.trainer.Trainer(updater, stop_trigger)\n",
        "    logging_attributes = [\n",
        "        'epoch', 'iteration',\n",
        "        'main/loss', 'main/accuracy'        \n",
        "    ]\n",
        "    trainer.extend(\n",
        "        extensions.LogReport(logging_attributes, trigger=(2000 // batchsize, 'iteration'))\n",
        "    )\n",
        "    trainer.extend(\n",
        "        extensions.PrintReport(logging_attributes)\n",
        "    )\n",
        "    trainer.extend(\n",
        "        extensions.ExponentialShift('alpha', 0.75, optimizer=optimizer),\n",
        "        trigger=(4000 // batchsize, 'iteration')\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DaMN5SPrJ_on",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = create_train_dataset(dataset_root)\n",
        "test_dataset = create_test_dataset(dataset_root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KUidNkHlKTjh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer = create_trainer(256, train_dataset, nb_epoch=1, device=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fSRYgJgCBD6Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは，これまでと同様に学習を開始しましょう．(1分30秒ほどで学習が完了します．)"
      ]
    },
    {
      "metadata": {
        "id": "kawTWjlNKZTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%time trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wMPjaOZd4-gR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習が完了したら，評価用データで予測を行い，精度を確認してみましょう．"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C_7Qhz7RPLgP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%time y_true_test, y_pred_test = evaluate(trainer, test_dataset, 256, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "R4C-mFzBPLgQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_confusion_matrix(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "n3z2ygYkPLgU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_scores(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dc1j5V9tJObY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "初期モデルの予測結果と，今回の予測結果を比較してみて下さい．"
      ]
    },
    {
      "metadata": {
        "id": "QUZQOrwaY1iA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ノイズ除去の効果検証"
      ]
    },
    {
      "metadata": {
        "id": "0n54KBAxRy0R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "最後に，心電図に含まれる**ノイズの除去**について検討します．\n",
        "\n",
        "心電図波形には，以下のような外部ノイズが含まれている可能性があります．[[文献8](http://www.iosrjournals.org/iosr-jece/papers/ICETEM/Vol.%201%20Issue%201/ECE%2006-40-44.pdf)]\n",
        "\n",
        "* 高周波\n",
        "    * **筋電図ノイズ** (Electromyogram noise)\n",
        "        - 体動により，筋肉の電気的活動が心電図に混入する場合があります．\n",
        "    * **電力線誘導障害** (Power line interference)\n",
        "        - 静電誘導により交流電流が流れ込み，心電図に混入する場合があります．\n",
        "        - 電源配線に電流が流れることで磁力線が発生し，電磁誘導作用により交流電流が流れ込む場合があります．\n",
        "    * **加算性白色ガウスノイズ** (Additive white Gaussian noise)\n",
        "        - 外部環境に由来する様々な要因でホワイトノイズが混入してきます．\n",
        "* 低周波\n",
        "    * **基線変動** (Baseline wandering)\n",
        "        - 電極の装着不良，発汗，体動などの影響で，基線がゆっくり変動する場合があります．\n",
        "\n",
        "心電図を解析する際は，頻脈や徐脈などの異常波形を正確に判別するために，上記のようなノイズを除去する前処理が行われるのが一般的です．\n",
        "\n",
        "ノイズを除去する方法は幾つかありますが，最も単純なのは，線形フィルタを適用する方法です．今回は線形フィルタの一つであるバターワースフィルタを用いて，ノイズ除去を試してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "oyWFLqKFjoLM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`BaseECGDatasetPreprocessor` にシグナルノイズ除去の機能を追加した， `DenoiseECGDatasetPreprocessor` クラスを定義します．"
      ]
    },
    {
      "metadata": {
        "id": "JErWrrR07cjB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "\n",
        "class DenoiseECGDatasetPreprocessor(BaseECGDatasetPreprocessor):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            dataset_root='./',\n",
        "            window_size=720\n",
        "    ):\n",
        "        super(DenoiseECGDatasetPreprocessor, self).__init__(\n",
        "        dataset_root, window_size)\n",
        "\n",
        "    def _denoise_signal(\n",
        "            self,\n",
        "            signal,\n",
        "            btype='low',\n",
        "            cutoff_low=0.2,\n",
        "            cutoff_high=25.,\n",
        "            order=5\n",
        "    ):\n",
        "        nyquist = self.sample_rate / 2.\n",
        "        if btype == 'band':\n",
        "            cut_off = (cutoff_low / nyquist, cutoff_high / nyquist)\n",
        "        elif btype == 'high':\n",
        "            cut_off = cutoff_low / nyquist\n",
        "        elif btype == 'low':\n",
        "            cut_off = cutoff_high / nyquist\n",
        "        else:\n",
        "            return signal\n",
        "        b, a = butter(order, cut_off, analog=False, btype=btype)\n",
        "        return lfilter(b, a, signal)\n",
        "\n",
        "    def _segment_data(\n",
        "            self,\n",
        "            signal,\n",
        "            symbols,\n",
        "            positions\n",
        "    ):\n",
        "        X = []\n",
        "        y = []\n",
        "        sig_len = len(signal)\n",
        "        for i in range(len(symbols)):\n",
        "            start = positions[i] - self.window_size // 2\n",
        "            end = positions[i] + self.window_size // 2\n",
        "            if symbols[i] in self.valid_symbols and start >= 0 and end <= sig_len:\n",
        "                segment = signal[start:end]\n",
        "                assert len(segment) == self.window_size, \"Invalid length\"\n",
        "                X.append(segment)\n",
        "                y.append(self.labels.index(self.label_map[symbols[i]]))\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def prepare_dataset(\n",
        "            self,\n",
        "            denoise=False,\n",
        "            normalize=True\n",
        "    ):\n",
        "        if not os.path.isdir(self.download_dir):\n",
        "            self.download_data()\n",
        "\n",
        "        # prepare training dataset\n",
        "        self._prepare_dataset_core(self.train_record_list, \"train\", denoise, normalize)\n",
        "        # prepare test dataset\n",
        "        self._prepare_dataset_core(self.test_record_list, \"test\", denoise, normalize)\n",
        "\n",
        "    def _prepare_dataset_core(\n",
        "            self,\n",
        "            record_list,\n",
        "            mode=\"train\",\n",
        "            denoise=False,\n",
        "            normalize=True\n",
        "    ):\n",
        "        Xs, ys = [], []\n",
        "        save_dir = os.path.join(self.dataset_root, 'preprocessed', mode)\n",
        "        for i in range(len(record_list)):\n",
        "            signal, symbols, positions = self._load_data(record_list[i])\n",
        "            if denoise:\n",
        "                signal = self._denoise_signal(signal)\n",
        "            if normalize:\n",
        "                signal = self._normalize_signal(signal)\n",
        "            X, y = self._segment_data(signal, symbols, positions)\n",
        "            Xs.append(X)\n",
        "            ys.append(y)\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        np.save(os.path.join(save_dir, \"X.npy\"), np.vstack(Xs))\n",
        "        np.save(os.path.join(save_dir, \"y.npy\"), np.concatenate(ys))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ASH3PS2a4td",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "線形フィルタを適用することで，学習モデルが異常拍動のパターンを特徴として捉えやすくなる可能性があります．一方で，異常拍動を検出するにあたって重要な情報も除去されてしまう可能性があることに注意してください．\n",
        "\n",
        "また，線形フィルタにおいては，その周波数特性（どの帯域の周波数成分を遮断するか）によって，幾つかの大まかな分類があります．例えば，以下のものがあります．\n",
        "\n",
        "\n",
        "* **ローパスフィルタ (Low-pass filter)** : 低周波成分のみ通過 (高周波成分を遮断)\n",
        "* **ハイパスフィルタ (High-pass filter)** : 高周波成分のみ通過 (低周波成分を遮断)\n",
        "* **バンドパスフィルタ(Band-pass filter)** : 特定の帯域成分のみ通過 (低周波，高周波成分を遮断)\n",
        "\n",
        "![線形フィルタの周波数特性による分類](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/monitoring/band_form.png)\n",
        "\n",
        "([[文献9](https://en.wikipedia.org/wiki/Filter_%28signal_processing%29)] より引用)\n"
      ]
    },
    {
      "metadata": {
        "id": "PNCCO2nTEOjm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "mitdbでは，予め0.1 Hz 以下の低周波と，100 Hz 以上の高周波をバンドパスフィルタによって除去済みであるため，ここではさらに，25 Hz のローパス・バターワースフィルタによって高周波ノイズを取り除きます．"
      ]
    },
    {
      "metadata": {
        "id": "qAPRfmp4kyZz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは，ノイズ除去オプションを有効にして，前処理を実行してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "U19pzjkY85IP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DenoiseECGDatasetPreprocessor(dataset_root).prepare_dataset(denoise=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P3GJLKwBZSDj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "実際に，高周波ノイズ除去後の波形を可視化してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "RCIkhIvUNhcQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_d = np.load(os.path.join(dataset_root, 'preprocessed', 'train', 'X.npy'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EDsqmOiYOYUL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(X_train[idx_n[0]])\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(X_train_d[idx_n[0]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yYWeI-n5ccof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "左図がフィルタリング前の波形，右図がフィルタリング後の波形です．\n",
        "細かな振動が取り除かれていることが確認できると思います．\n",
        "\n",
        "これまでと同様に，ノイズ除去後のデータを用いて学習を行ってみましょう．(1分30秒ほどで学習が完了します．)"
      ]
    },
    {
      "metadata": {
        "id": "Yvx5uLSwHz0e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = create_train_dataset(dataset_root)\n",
        "test_dataset = create_test_dataset(dataset_root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C70lLfAHbOOH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer = create_trainer(256, train_dataset, nb_epoch=1, device=0)\n",
        "%time trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8dTSeQiViGH_"
      },
      "cell_type": "markdown",
      "source": [
        "学習が完了したら，評価用データで予測を行い，精度を確認してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "5U3EVnexeasF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%time y_true_test, y_pred_test = evaluate(trainer, test_dataset, 256, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qHnh-vFuelQk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_confusion_matrix(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0R_lnZLcIn-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_scores(y_true_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TOdAyYBKiAQl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "高周波のノイズを除去したことで，予測精度がどのように変わったか確認してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "IUfM-tiaBa2x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## おわりに"
      ]
    },
    {
      "metadata": {
        "id": "2T86ACWRBehT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "本章では，ECGの公開データセットを利用して，不整脈検知の問題に取り組みました．\n",
        "\n",
        "本講義内容を通じてお伝えしたかったことは，以下となります．\n",
        "\n",
        "1. 心電図を解析するにあたって必要となる最低限の知識\n",
        "1. モニタリングデータを解析するための基本的な前処理手順\n",
        "1. CNNベースのモデルを利用した学習器の構築\n",
        "1. データセットの性質を考慮した学習方法や前処理の工夫\n",
        "\n",
        "また，精度向上に向けて様々な手法を試してみましたが，現実世界のタスクにおいては，どの工夫が有効に働くか自明で無い場合がほとんどです．従って，試行錯誤を行いながら，その問題設定に適合するやり方を模索していく必要があります．\n",
        "\n",
        "さらなる取り組みとしては，例えば下記内容を検討する余地があります．\n",
        "\n",
        "* 情報の追加\n",
        "    * $Ⅱ$誘導シグナルに加えて，$V_1$誘導シグナルも同時に入力として与えます．([[文献10](https://www.kdd.org/kdd2018/files/deep-learning-day/DLDay18_paper_16.pdf)]などで実施)\n",
        "* 前処理の工夫\n",
        "    * セグメント長の変更\n",
        "        * より長時間のセグメントを入力とすることで，長期的な波形情報を抽出．([[文献4](https://arxiv.org/abs/1810.04121)]では10秒のセグメントを解析に利用)\n",
        "        * 入力情報が増えることで，却って学習が難しくなってしまう可能性あり．\n",
        "    * リサンプリング\n",
        "        * サンプリング周波数を下げることで，長期的な波形情報を抽出．([[文献4](https://arxiv.org/abs/1810.04121)]では180 Hzにダウンサンプリング)\n",
        "            * 波形が粗くなることで学習に影響する可能性あり．\n",
        "            * 適切な前処理を行わないと，折り返し雑音と呼ばれる歪みが発生．\n",
        "            * （モデルに入力する前に情報を縮小する処理は，画像解析などの分野では一般的）\n",
        "    * ラベルの追加\n",
        "        * Normal，VEBに加えて，SVEB（上室異所性拍動）等も追加．\n",
        "    * ラベルの与え方の変更\n",
        "        * セグメント範囲内に正常以外のピークラベルが含まれる場合に優先的にそのラベルを付与する，等．\n",
        "* モデルの変更\n",
        "    * 長期的な特徴を抽出するために，CNNの後段にRNNベースの構造(LSTMなど)を組み込む ([[文献4](https://arxiv.org/abs/1810.04121)]などで実施)．\n",
        "\n",
        "余力がある方は，是非チャレンジしてみてください．\n",
        "\n",
        "また，最近では独自に収集した大規模なモニタリングデータを対象として，研究成果を発表する事例も幾つか出てきています．\n",
        "\n",
        "* Cardiogram社とカリフォルニア大学の共同研究で，活動量計から心拍数データを収集し，深層学習を用いて糖尿病予備群を予測するDeepHeartを発表[[文献11](https://arxiv.org/abs/1802.02511)]．\n",
        "* スタンフォード大学のAndrew Ng.の研究室でも，独自に収集したECGレコードから$14$種類の波形クラス分類を予測するモデルを構築し，医師と比較実験を実施[[文献12](https://arxiv.org/abs/1707.01836)]．\n",
        "\n",
        "デバイスの進歩によって簡単に精緻な情報が収集可能になってきていることから，こうした研究は今後益々盛んになっていくと考えられます．\n",
        "\n",
        "以上で，モニタリングデータの時系列解析の章は終了となります．お疲れ様でした．"
      ]
    },
    {
      "metadata": {
        "id": "o3jHP07dN8W9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 参考文献"
      ]
    },
    {
      "metadata": {
        "id": "Bvr5T47ROAof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. **Electrocardiography** Wikipedia: The Free Encyclopedia. Wikimedia Foundation, Inc. 22 July 2004. Web. 10 Aug. 2004, [[Link](https://en.wikipedia.org/wiki/Electrocardiography)]\n",
        "1. **心電図健診判定マニュアル**, 日本人間ドック学会, 平成26年4月,  [[Link](https://www.ningen-dock.jp/wp/wp-content/uploads/2013/09/d4bb55fcf01494e251d315b76738ab40.pdf)]\n",
        "1. **Automatic classification of heartbeats using ECG morphology and heartbeat interval features**, Phillip de Chazal et al., June 2004, [[Link](https://ieeexplore.ieee.org/document/1306572)]\n",
        "1. **Inter-Patient ECG Classification with Convolutional and Recurrent Neural Networks**, Li Guo et al., Sep 2018, [[Link](https://arxiv.org/abs/1810.04121)]\n",
        "1. **Deep Residual Learning for Image Recognition**, Kaiming He et al., Dec 2015, [[Link](https://arxiv.org/abs/1512.03385)]\n",
        "1. **Focal Loss for Dense Object Detection**, Tsung-Yi Lin et al., Aug 2017, [[Link](https://arxiv.org/abs/1708.02002)]\n",
        "1. **Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference**, Yarin Gal et al., Jun 2015, [[Link](https://arxiv.org/abs/1506.02158v6)]\n",
        "1. **Noise Analysis and Different Denoising Techniques of ECG Signal - A Survey**, Aswathy Velayudhan et al., ICETEM2016, [[Link](http://www.iosrjournals.org/iosr-jece/papers/ICETEM/Vol.%201%20Issue%201/ECE%2006-40-44.pdf)]\n",
        "1. **Filter (signal processing)**, Wikipedia: The Free Encyclopedia. Wikimedia Foundation, Inc. 22 July 2004. Web. 10 Aug. 2004, [[Link](https://en.wikipedia.org/wiki/Filter_%28signal_processing%29)]\n",
        "1. **Arrhythmia Detection from 2-lead ECG using Convolutional Denoising Autoencoders**, Keiichi Ochiai et al., KDD2018, [[Link](https://www.kdd.org/kdd2018/files/deep-learning-day/DLDay18_paper_16.pdf)]\n",
        "1. **DeepHeart: Semi-Supervised Sequence Learning for Cardiovascular Risk Prediction**, Brandon Ballinger et al., Feb 2018, [[Link](https://arxiv.org/abs/1802.02511)]\n",
        "1. **Cardiologist-Level Arrhythmia Detection with Convolutional Neural Networks**, Pranav Rajpurkar et al., Jul 2017, [[Link](https://arxiv.org/abs/1707.01836)]"
      ]
    }
  ]
}