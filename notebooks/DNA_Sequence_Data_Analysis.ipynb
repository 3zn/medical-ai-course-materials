{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNA Sequence Data Analysis",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hillbig/medical-ai-course-materials/blob/master/notebooks/DNA_Sequence_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "yoiTUC_zXAb9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[![colab-logo](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/japan-medical-ai/medical-ai-course-materials/blob/master/notebooks/DNA_Sequence_Data_Analysis.ipynb)\n",
        "\n",
        "# 実践編: ディープラーニングを使った配列解析\n",
        "\n",
        "近年，次世代シーケンサ（NGS; Next Generation Sequencer）の発展により，遺伝子の塩基配列が高速，大量，安価に読み取られるようになってきました．\n",
        "\n",
        "ここではディープラーニングを用いて，DNA配列からエピジェネティックな影響や転写制御を予測する問題に取り組みます．ディープラーニングは複雑なモデルを表現でき，遠距離の影響も考慮することができ，より高い精度で予測することが期待できます．\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "6l-Quu1SS7F9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "CkqRZHc8crS4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 環境構築\n",
        "\n",
        "ここで用いるライブラリは\n",
        "\n",
        "\n",
        "*  Chainer\n",
        "*  Cupy\n",
        "*  matplotlib\n",
        "\n",
        "です．Google Colab上では，以下のようにしてインストールすることができます．以下のセルを実行（Shit+Enter）してください．\n"
      ]
    },
    {
      "metadata": {
        "id": "muhQoVk7c9y1",
        "colab_type": "code",
        "outputId": "932c578a-16bd-4f9a-d46e-da1f3e14381a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1173
        }
      },
      "cell_type": "code",
      "source": [
        "!curl https://colab.chainer.org/install | sh -"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1379  100  1379    0     0   7790      0 --:--:-- --:--:-- --:--:--  7790\n",
            "+ apt -y -q install cuda-libraries-dev-9-2\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  cuda-cublas-dev-9-2 cuda-cufft-dev-9-2 cuda-curand-dev-9-2\n",
            "  cuda-cusolver-dev-9-2 cuda-cusparse-dev-9-2 cuda-npp-dev-9-2\n",
            "  cuda-nvgraph-dev-9-2 cuda-nvrtc-dev-9-2\n",
            "The following NEW packages will be installed:\n",
            "  cuda-cublas-dev-9-2 cuda-cufft-dev-9-2 cuda-curand-dev-9-2\n",
            "  cuda-cusolver-dev-9-2 cuda-cusparse-dev-9-2 cuda-libraries-dev-9-2\n",
            "  cuda-npp-dev-9-2 cuda-nvgraph-dev-9-2 cuda-nvrtc-dev-9-2\n",
            "0 upgraded, 9 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 332 MB of archives.\n",
            "After this operation, 972 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cublas-dev-9-2 9.2.148.1-1 [50.4 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cufft-dev-9-2 9.2.148-1 [106 MB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-curand-dev-9-2 9.2.148-1 [57.8 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cusolver-dev-9-2 9.2.148-1 [8,184 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cusparse-dev-9-2 9.2.148-1 [27.8 MB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-nvrtc-dev-9-2 9.2.148-1 [9,348 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-nvgraph-dev-9-2 9.2.148-1 [30.1 MB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-npp-dev-9-2 9.2.148-1 [52.0 MB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-libraries-dev-9-2 9.2.148-1 [2,598 B]\n",
            "Fetched 332 MB in 7s (50.0 MB/s)\n",
            "Selecting previously unselected package cuda-cublas-dev-9-2.\n",
            "(Reading database ... 26397 files and directories currently installed.)\n",
            "Preparing to unpack .../0-cuda-cublas-dev-9-2_9.2.148.1-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-dev-9-2 (9.2.148.1-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-9-2.\n",
            "Preparing to unpack .../1-cuda-cufft-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-9-2.\n",
            "Preparing to unpack .../2-cuda-curand-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-9-2.\n",
            "Preparing to unpack .../3-cuda-cusolver-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-9-2.\n",
            "Preparing to unpack .../4-cuda-cusparse-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-9-2.\n",
            "Preparing to unpack .../5-cuda-nvrtc-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-9-2.\n",
            "Preparing to unpack .../6-cuda-nvgraph-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-9-2.\n",
            "Preparing to unpack .../7-cuda-npp-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-9-2.\n",
            "Preparing to unpack .../8-cuda-libraries-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-npp-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-curand-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-nvrtc-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cusolver-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cufft-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cusparse-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cublas-dev-9-2 (9.2.148.1-1) ...\n",
            "Setting up cuda-nvgraph-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-libraries-dev-9-2 (9.2.148-1) ...\n",
            "+ pip install -q cupy-cuda92  chainer \n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mEPaj4MfdEyh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "インストールが完了したら，以下のセルを実行して，各ライブラリのバージョンを確認してください．\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "p4X-dmKrdDhd",
        "colab_type": "code",
        "outputId": "70107620-da49-4c61-f044-6d81ca8230b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import cupy\n",
        "import matplotlib\n",
        "\n",
        "chainer.print_runtime_info()\n",
        "print('matplotlib:', matplotlib.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Platform: Linux-4.14.65+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Chainer: 5.1.0\n",
            "NumPy: 1.14.6\n",
            "CuPy:\n",
            "  CuPy Version          : 5.1.0\n",
            "  CUDA Root             : /usr/local/cuda\n",
            "  CUDA Build Version    : 9020\n",
            "  CUDA Driver Version   : 9020\n",
            "  CUDA Runtime Version  : 9020\n",
            "  cuDNN Build Version   : 7301\n",
            "  cuDNN Version         : 7301\n",
            "  NCCL Build Version    : 2307\n",
            "iDeep: 2.0.0.post3\n",
            "('matplotlib:', '2.1.2')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0nsNNeFEkjB_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Platform: Linux-4.14.65+-x86_64-with-Ubuntu-18.04-bionic\n",
        "Chainer: 5.1.0\n",
        "NumPy: 1.14.6\n",
        "CuPy:\n",
        "  CuPy Version          : 5.1.0\n",
        "  CUDA Root             : /usr/local/cuda\n",
        "  CUDA Build Version    : 9020\n",
        "  CUDA Driver Version   : 9020\n",
        "  CUDA Runtime Version  : 9020\n",
        "  cuDNN Build Version   : 7301\n",
        "  cuDNN Version         : 7301\n",
        "  NCCL Build Version    : 2307\n",
        "iDeep: 2.0.0.post3\n",
        "('matplotlib:', '2.1.2')\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "MzdDwd7aeYmT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 配列解析について\n",
        "\n",
        "次世代シーケンサの発展・普及とともに，大量の遺伝子配列が読み取られるようになりました．そうした中で，塩基配列で表現された遺伝子型と病気や形態などの表現型との関係を推定するようなGWAS（Genome Wide Association Study; ゲノムワイド関連解析）が行われてきましたが，遺伝子の変異だけでは全ての表現型の変化を説明できないことがわかってきました．特に，非翻訳領域が遺伝子発現に影響を与え，表現型の変化を生じさせていることが様々な実験結果からわかってきています．遺伝子発現時に周辺領域がどのように影響を与えているのかを調べるために様々な手法が提案されています．\n",
        "\n",
        "![エピゲノム解析概略図(Encode Projectより引用)](https://www.encodeproject.org/images/c45f4d8c-0340-4fcb-abe3-e4ff0bb919be/@@download/attachment/EncodeDatatypes2013-7.png)\n",
        "\n",
        "例えば，ChiP-Seq（クロマチン免疫沈降）は，転写調節因子やそのほかのタンパク質が直接の相互作用を起こすDNAの特定部位を分離し，それらをシーケンシングして同定し，どの程度出現していたかを定量化します．これにより，タンパク質のDNA中の結合部位を正確かつ効率的に同定することができます．\n",
        "\n",
        "このような技術で抽出された配列を学習データとして利用し，DNA配列のみからそこが結合部位かどうかだけでなく，どの程度，出現していたのかというカバレッジ値を推定します．例えば，修飾ヒストンのChiPの学習データを利用した場合はDNA配列を入力としてどこ位置がヒストン修飾サイトであるかを推定できるようになります，様々な種類の実験データを学習データとして用いることでDNA配列から，転写因子，クロマチンアクセシビリティ，ヒストン修飾を予測することができるようになり，様々な遺伝子変異に対する有益な洞察を与えてくれます．\n",
        "\n",
        "一方で，DNA配列中のどの領域が遺伝子発現に影響を及ぼすのかを調べるためには非常に遠距離のDNA配列も必要である場合が多く，これが機械学習による解析を困難としていました．今回紹介する手法はこのような遠距離の関係を捉えるため，10万超の長さのDNA配列を入力として受け取り，128 bpごとにその領域がどの程度各手法で発現していたのか，カバレッジ値を予測するタスクを考えます．\n",
        "\n",
        "今回は、数百種類の人の細胞型から得られた数千のエピジェネティックや転写制御のプロファイルを利用して、DNA配列を入力としてCAGEの結果計測されたmRNAの発現量を推定する問題を考えます[1]。"
      ]
    },
    {
      "metadata": {
        "id": "db3ngEYHgSmd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## データセット\n",
        "\n",
        "ここでは，Basenji[1]で使われた実験データセットの一部を利用します.これらはCAGEなどの配列解析して作られたデータセットです．\n",
        "\n",
        "下のセルを実行してデータをダウンロードしてください．\n",
        "\n",
        "この配列はそれぞれが長さ131072塩基からなり，128塩基毎に対しそのカバレッジ値が記録されています．このカバレッジ値の配列の長さは131072/128=1024です．\n",
        "\n",
        "この問題の目標は長さ131072の配列を入力として受け取った時に，この128塩基毎のカバレッジ値を推定することが目標です．\n",
        "\n",
        "今回は10種類の異なる実験のカバレッジ値を同時に予測する問題を扱います．"
      ]
    },
    {
      "metadata": {
        "id": "LjxWi_2chwkX",
        "colab_type": "code",
        "outputId": "7fb7d61f-aab2-4eef-b146-08b0493ea28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-05 13:40:51--  https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/c79a0800-f713-11e8-8d6c-255563d45b1b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181205T134051Z&X-Amz-Expires=300&X-Amz-Signature=682297718ad4a994248d2253502dd963b7904bee8c8125900c6ff21136040293&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dseq.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2018-12-05 13:40:51--  https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/c79a0800-f713-11e8-8d6c-255563d45b1b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181205T134051Z&X-Amz-Expires=300&X-Amz-Signature=682297718ad4a994248d2253502dd963b7904bee8c8125900c6ff21136040293&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dseq.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.228.232\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.228.232|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 594118876 (567M) [application/octet-stream]\n",
            "Saving to: ‘seq.h5’\n",
            "\n",
            "seq.h5              100%[===================>] 566.60M  45.5MB/s    in 13s     \n",
            "\n",
            "2018-12-05 13:41:05 (43.0 MB/s) - ‘seq.h5’ saved [594118876/594118876]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9yuEHGl_XC2B",
        "colab_type": "code",
        "outputId": "7eaa113d-9954-471d-c271-5ac8aab4aed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 567M\n",
            "drwxr-xr-x 2 root root 4.0K Nov 29 18:21 sample_data\n",
            "-rw-r--r-- 1 root root 567M Dec  3 06:54 seq.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l8NsMudgiHBI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "data.h5というファイルが正しくダウンロードされているかを確認してください．サイズは567MBです．\n",
        "\n",
        "data.h5はHDF5形式でデータを格納したファイルです．HDF5ファイルは，ファイルシステムと同様に，階層的にデータを格納することができ，行列やテンソルデータをそれぞれの位置で名前付きで格納することができます．\n",
        "\n",
        "HDF5形式のファイルを操作するためにh5pyというライブラリがあります．h5pyのFile()関数でファイルを開き，keys()関数でその中に含まれているキーを列挙します．また取得したキーを'[]'内で指定することでそのキーに紐付けられて格納されている各データを参照することができます．\n",
        "\n",
        "テンソルデータはnumpyと同様にshapeという属性でそのサイズを取得することができます．\n",
        "\n",
        "以下のセルを実行して格納されているデータを確認してください．\n",
        "\n",
        "各データの名前にtrain（学習），validate（検証），test（テスト）の接頭辞がつけられ，inが入力の塩基配列，outが出力のカバレッジ値に対応します．\n",
        "\n",
        "例えば，'train_in'は学習用の入力データであり(6240, 131072, 4)というサイズを持ちます．これは長さが130172からなる配列が6240個あり，それぞれA, T, C, Gの対応する次元の値が1, それ以外は0であるような配列です．\n",
        "\n",
        "また,'train_out'は学習用の出力データであり,（'6240, 1024, 3')というサイズを持ちます.これは長さが1024からなる配列が6240個あり,それぞれが3種類の異なるChiPSeqの結果のカバレッジ値が格納されています."
      ]
    },
    {
      "metadata": {
        "id": "bBQVPyKxi-uE",
        "colab_type": "code",
        "outputId": "7b95f234-9e4a-42f4-994c-8260e69cfc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "with h5py.File('seq.h5', 'r') as hf:\n",
        "    for key in hf.keys():\n",
        "        print(key, hf[key].shape, hf[key].dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(u'target_labels', (10,), dtype('S29'))\n",
            "(u'test_in', (500, 131072, 4), dtype('bool'))\n",
            "(u'test_out', (500, 1024, 10), dtype('<f2'))\n",
            "(u'train_in', (5000, 131072, 4), dtype('bool'))\n",
            "(u'train_out', (5000, 1024, 10), dtype('<f2'))\n",
            "(u'valid_in', (500, 131072, 4), dtype('bool'))\n",
            "(u'valid_out', (500, 1024, 10), dtype('<f2'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T7OkqzE-jXlq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "(u'target_labels', (10,), dtype('S29'))\n",
        "(u'test_in', (500, 131072, 4), dtype('bool'))\n",
        "(u'test_out', (500, 1024, 10), dtype('<f2'))\n",
        "(u'train_in', (5000, 131072, 4), dtype('bool'))\n",
        "(u'train_out', (5000, 1024, 10), dtype('<f2'))\n",
        "(u'valid_in', (500, 131072, 4), dtype('bool'))\n",
        "(u'valid_out', (500, 1024, 10), dtype('<f2'))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NkAYTB2ZkEXr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "h5py形式のファイルをnumpyデータとして扱うには，コピーする必要があります．以下のコードは'train_in'というキーに対応するテンソルデータをnumpyデータとして読み出し，そのデータの一部を表示します．\n",
        "\n",
        "試しに最初のデータを取り出して，それの出力の値を表示してみます．\n",
        "\n",
        "下のセルを実行してみてください．最初のデータの出力の三つの値を線グラフで出力します．（ここまでのセルを実行していてください）．"
      ]
    },
    {
      "metadata": {
        "id": "lik6qHPD4m9V",
        "colab_type": "code",
        "outputId": "7bdb014f-1b2c-447d-e31c-c988ce742ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with h5py.File('seq.h5') as hf:\n",
        "    y = hf['train_out'][:100]\n",
        "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "    fig_size[0] = 20\n",
        "    fig_size[1] = 5\n",
        "    for i in range(3):\n",
        "        plt.bar(range(y.shape[1]), y[0,:,i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABHwAAAEvCAYAAAA3qtbRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4fe6433410>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9dB69Y47k-y_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dilated Convolutionを用いた解析\n",
        "\n",
        "### 配列解析の戦略\n",
        "\n",
        "今回は配列データが入力であるような問題である．\n",
        "\n",
        "配列データを扱うためには大きく３つの戦略があります．\n",
        "\n",
        "一つ目は，配列中の順序情報は捨てて，配列をその特徴の集合とみなすことです．これはBag of Words（BoW）表現とよびます．このBoW表現は特徴に十分情報が含まれていれば強力な手法ですがDNA配列のような4種類の文字からなる配列やその部分配列だけではその特徴を捉えることは困難です．\n",
        "\n",
        "二つ目は配列中の要素を左から右に順に読み込んでいき計算していく手法です．これは4章でも少し触れたRNNを用いて解析します．RNNは時刻毎に入力を一つずつ読み取り内部状態を更新していきます．RNNの問題点はその計算が逐次的であり計算量が配列長に比例するという点です．現在の計算機は計算を並列化することで高速化を達成していますがRNNは計算を並列化することが困難です．もう一つの問題は遠距離間の関係を捉えることが難しいという点です．RNNはその計算方式から，計算の途中結果を全て固定長の内部状態ベクトルに格納する必要があります．遠距離間の関係を捉えようとすると，多くの情報を覚えておかなければなりませんが状態ベクトルサイズは有限なので，遠距離間の関係を捉えることが困難となっていきます．\n",
        "\n",
        "三つ目は配列データを1次元の画像とみなし，画像処理の時と同様にCNNを用いて解析する手法です．CNNはRNNの場合と違って各位置の処理を独立に実行できるため並列に処理することができます．また，後述するDilated Convolutionを使うことで各位置の処理は遠距離にある情報を直接読み取ることができます．次の章でDilated Convolutionについてさらに詳しくみていきます．\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RWl4yYm_nqg7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dilated Convolution\n",
        "\n",
        "従来の畳み込み層を使って配列解析をする場合を考えてみます．\n",
        "以下の図のようにある位置の入力の情報は各層で隣接する位置からしか読み込まれません．どのくらい離れた位置から情報を取得するかはカーネルサイズによって決定され，カーネルサイズがKの時，Dだけ離れた距離にある情報を取得するためにはD/K層必要となります．今回の問題の場合Dは数百から数万，Kは3や5といった値ですので必要な層数も百から万といった数になってしまい現実的ではありません．"
      ]
    },
    {
      "metadata": {
        "id": "gJ2MdbaHneLk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "![従来の畳み込み層の計算イメージ](http://musyoku.github.io/images/post/2016-09-17/naive_conv.png)\n",
        "\n",
        "[WaveNet: A Generative Model for Raw Audio](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)より引用"
      ]
    },
    {
      "metadata": {
        "id": "Gazys1FUoV4m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それに対し，Dilated Convolution（atrous convolutionやconvolution weith holesともよばれます）は読み取る場所をずらしたところからうけとります．例えばDilation=4の場合，4だけ離れた位置から情報を受け取ります．このDilatedを倍々にしていき，カーネルサイズを2とした場合，Dだけ離れた位置の情報を受取るには log_2 D層だけ必要になります．今回のDが数百から数万の場合，10から20層程度あれば済むことになります．\n",
        "\n",
        "今回はこのDilated Convolutionを使うことで遠距離にある情報を考慮できるモデルを作成します．"
      ]
    },
    {
      "metadata": {
        "id": "Vl5f4eonQGU9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "![Dilated Convolutionの計算イメージ](https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif)\n",
        "\n",
        "[WAVENET: A GENERATIVE MODEL FOR RAW AUDIO, blog](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)より\n"
      ]
    },
    {
      "metadata": {
        "id": "p0bcCznko_wD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ブロック\n",
        "\n",
        "それでは最初に，ネットワークの全体を設計します．\n",
        "このネットワークは二つのブロックから構成されます．\n",
        "\n",
        "１つ目のブロックは長さが$2^{17}$から配列を入力として長さが$2^{10}$のベクトルを出力とします．これにより入力の128 bpが出力の1つの位置に対応するようになります．これを実現しているのが，SqueezeBlockです．\n",
        "\n",
        "二つ目のブロックは遠距離にある情報を考慮して各ベクトルの値を計算していく部分であり，DilatedBlockが担当します．\n",
        "\n",
        "それでは，以下のコードを実行してみましょう．\n"
      ]
    },
    {
      "metadata": {
        "id": "5M6BDmVdpLkE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import cupy as cp\n",
        "\n",
        "bc = 24 # base channel\n",
        "\n",
        "default_squeeze_params = [\n",
        "    # out_ch, kernel, stride, dropout\n",
        "    [bc*2, 21, 2, 0], #1 128 -> 64\n",
        "    [int(bc*2.5), 7, 4, 0.05], #2  64 -> 16\n",
        "    [int(bc*3.2), 7, 4, 0.05], #3  16 -> 4\n",
        "    [bc*4, 7, 4, 0.05]  #4  4 -> 1\n",
        "]\n",
        "\n",
        "\n",
        "default_dilated_params = [\n",
        "# out_ch, kernel, dilated\n",
        "  [bc, 3, 1, 0.1],\n",
        "  [bc, 3, 2, 0.1], \n",
        "  [bc, 3, 4, 0.1], \n",
        "  [bc, 3, 8, 0.1], \n",
        "  [bc, 3, 16, 0.1], \n",
        "  [bc, 3, 32, 0.1],\n",
        "  [bc, 3, 64, 0.1]\n",
        "]\n",
        "\n",
        "\n",
        "class Net(chainer.Chain):\n",
        "\n",
        "    def __init__(self, squeeze_params=default_squeeze_params, dilated_params=default_dilated_params, n_targets=10):\n",
        "        super(Net, self).__init__()\n",
        "        self._n_squeeze = len(squeeze_params)\n",
        "        self._n_dilated = len(dilated_params)\n",
        "        with self.init_scope():\n",
        "            in_ch = 4\n",
        "            for i, param in enumerate(squeeze_params):\n",
        "                out_ch, kernel, stride, do_rate = param\n",
        "                setattr(self, \"s_{}\".format(i), SqueezeBlock(in_ch, out_ch, kernel, stride, do_rate))\n",
        "                in_ch = out_ch\n",
        "            for i, param in enumerate(dilated_params):\n",
        "                out_ch, kernel, dilated, do_rate = param\n",
        "                setattr(self, \"d_{}\".format(i), DilatedBlock(in_ch, out_ch, kernel, dilated, do_rate))\n",
        "                in_ch += out_ch\n",
        "            self.l = L.ConvolutionND(1, None, n_targets, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x : (B, X, 4)\n",
        "        xp = cp.get_array_module(x)\n",
        "        h = xp.transpose(x, (0, 2, 1))\n",
        "        h = h.astype(xp.float32)\n",
        "                \n",
        "        for i in range(self._n_squeeze):\n",
        "            h = self[\"s_{}\".format(i)](h)\n",
        "    \n",
        "        hs = [h]\n",
        "        for i in range(self._n_dilated):\n",
        "            h = self[\"d_{}\".format(i)](hs)\n",
        "            hs.append(h)\n",
        "\n",
        "        h = self.l(F.concat(hs, axis=1))\n",
        "        h = xp.transpose(h, (0, 2, 1))\n",
        "        return h\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kc3RNwK_qHzS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このネットワークは初期化時の引数としてSqueezeBlockに関するパラメータと，DilatedBlockに関するパラメータを受け取ります．\n",
        "\n",
        "それぞれ，出力チャンネル，カーネルサイズ，プーリングの三つ組からなるリストと，出力チャンネル，カーネルサイズ，dilatedサイズの三つ組からなるリストを受け取ります．"
      ]
    },
    {
      "metadata": {
        "id": "s3T5pRubrlba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次に，ブロックの定義をします．"
      ]
    },
    {
      "metadata": {
        "id": "shOuWcBkrpOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import cupy as cp\n",
        "\n",
        "class WNConvolutionND(L.ConvolutionND):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(WNConvolutionND, self).__init__(*args, **kwargs)\n",
        "        self.add_param('g', self.W.data.shape[0])\n",
        "        norm = np.linalg.norm(self.W.data.reshape(\n",
        "            self.W.data.shape[0], -1), axis=1)\n",
        "        self.g.data[...] = norm\n",
        "\n",
        "    def __call__(self, x):\n",
        "        norm = F.batch_l2_norm_squared(self.W) ** 0.5\n",
        "        channel_size = self.W.data.shape[0]\n",
        "        norm_broadcasted = F.broadcast_to(\n",
        "            F.reshape(norm, (channel_size, 1, 1)), self.W.data.shape)\n",
        "        g_broadcasted = F.broadcast_to(\n",
        "            F.reshape(norm, (channel_size, 1, 1)), self.W.data.shape)\n",
        "        return F.convolution_nd(\n",
        "            x, g_broadcasted * self.W / norm_broadcasted, self.b, self.stride,\n",
        "            self.pad, self.cover_all, self.dilate)\n",
        "\n",
        "class SqueezeBlock(chainer.Chain):  \n",
        "    def __init__(self, in_ch, out_ch, kernel, stride, do_rate):\n",
        "        super(SqueezeBlock, self).__init__()\n",
        "        \n",
        "        self.do_rate = do_rate\n",
        "        with self.init_scope():\n",
        "            pad = kernel // 2\n",
        "            self.conv = WNConvolutionND(1, in_ch, out_ch*2, kernel, pad=pad, stride=stride)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        h = self.conv(x)\n",
        "        h, g = F.split_axis(h, 2, 1)\n",
        "        h = F.dropout(h * F.sigmoid(g), self.do_rate)\n",
        "        return h\n",
        "\n",
        "class DilatedBlock(chainer.Chain):\n",
        "     def __init__(self, in_ch, out_ch, kernel, dilate, do_rate):\n",
        "        super(DilatedBlock, self).__init__()\n",
        "        self.do_rate = do_rate\n",
        "        with self.init_scope():\n",
        "            self.conv = WNConvolutionND(1, in_ch, out_ch*2, kernel, pad=dilate, dilate=dilate)\n",
        "      \n",
        "     def forward(self, xs):\n",
        "        x = F.concat(xs, axis=1)\n",
        "        h = self.conv(x)\n",
        "        h, g = F.split_axis(h, 2, 1)\n",
        "        h = F.dropout(h * F.sigmoid(g), self.do_rate)\n",
        "        return h\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fHZuRr36bxHv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![network](https://https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/7/network.png)"
      ]
    },
    {
      "metadata": {
        "id": "RrTAARyW2AYQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "WeightNormalization[2]はパラメータの表現を長さと向きに分解して表現する手法で，今回の系列問題のような場合に使われる正規化法です．コード中ではWeightNormalizationが適用された畳み込み層である`WNConvolutionND`が定義されています.\n",
        "\n",
        "SqueezeBlockは配列を縮めていき，長さが$2^{17}$の配列を$2^{10}$に縮めるためのブロックです（上図）．\n",
        "1次元配列を扱うためWNConvolutionNDを使い，最初の引数で1次元配列であることを示す`1`を指定しています．\n",
        "また，活性化関数では$h = Wx * sigmoid(Ux)$と表されるGated Linear Unit[3]を利用しています．計算では効率化のため，WxとUxを別々に計算するのではなく2倍の出力チャンネル数を持つConvolutionを適用した後に出力結果をチャンネル方向に２つに分割し$(Wx, Ux)$、片方にsigmoid関数を適用した後、それらを要素毎にかけ合わせます．\n",
        "\n",
        "DilatedBlockはすでに長さ1024の長さになった配列に対し，Dilated Convolutionを使って遠距離にある情報も使って計算していく部分です．引数としてdilatedを受け取ります．Dilated Convolutionを使う場合は通常のConvolution層（今回はConvolutionNDだが，Convolution2Dも同様）の引数にdilatedを加えるだけで計算できます．\n",
        "\n",
        "また，計算の際は入力結果に現在の結果を足しこむスキップ接続を使います．これはResNetと呼ばれるネットワークで提案された手法であり，層が増えても勾配が減衰せず，学習がしやすくなります．\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "y-ZdRuhSq2Rq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは，試しにネットワークを構築して，そこにサンプルデータを流してみましょう．\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DARrKIMurGiH",
        "colab_type": "code",
        "outputId": "8b90760d-f8a2-452e-caac-cb4517ab37b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n = Net()\n",
        "size = 131072 # 128 * 1024\n",
        "batchsize = 4\n",
        "x = np.empty((batchsize, size, 4), dtype=np.bool)\n",
        "y = n.forward(x)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 1024, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ydR6gwYCsATQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "(4, 1024, 3)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OyJ8lu_psGlk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここで，もともとバッチサイズ(B)=4, 入力長(L)=131072, 入力チャンネル数(C)=4だった配列が計算後はB=4, L=1024, C=3の配列となりました．"
      ]
    },
    {
      "metadata": {
        "id": "vLNgEVh0vjOt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "今回の学習では対数ポアソン損失関数を利用します．これはモデルはポアソン分布の唯一のパラメータである平均を出力し，そのポアソン分布を学習データを使った最尤推定をします．この際，学習対象パラメータ以外は無視しています．\n",
        "また，この最適化関数の最小値はそのままだと$0$にはならので，最小値である$t \\log t$をひいておき，損失関数の最小値が$0$となるようにします．"
      ]
    },
    {
      "metadata": {
        "id": "rgQmu0Pgvh0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer.functions as F\n",
        "import math\n",
        "import sklearn\n",
        "import numpy as np\n",
        "\n",
        "def log_poisson_loss(log_x, t):\n",
        "    #return F.mean(F.exp(log_x) - t * log_\n",
        "    loss =  F.mean(F.exp(log_x) - t * log_x) \n",
        "    t = chainer.cuda.to_cpu(t.astype(np.float32))  \n",
        "    offset = F.mean(cp.array(t - t * np.ma.log(t)))\n",
        "    return loss - offset\n",
        "\n",
        "\n",
        "def log_r2_score(log_x, t):\n",
        "    return F.r2_score(F.exp(log_x), t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "40kTUr3O2lu5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "また，学習率の調整にCosineSchedulerを使います．ニューラルネットワークの学習では，徐々に学習率を小さくしていくと，より汎化性能の高い解を見つけられることがわかっています．ニューラルネットワークの学習の目的関数は多くの性能の悪い局所解があるため、最初は学習率を高くして局所解にはまらないようにして全体の中での良い解を探し，後半は徐々に学習率を0に近づけていき収束させるというものです．\n",
        "CosineSchedulerはCosine関数の0度から90度までの変化のように学習率を変化させます．また学習は初期が不安定なので最初のn_warmup回，学習率を0から初期学習率まで線形に増やすことも一般的です．今回は学習率が低めで学習も安定しているのでn_warmupは0としてあります．\n"
      ]
    },
    {
      "metadata": {
        "id": "QvjM_C-z2o8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer import training\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class CosineScheduler(training.Extension):\n",
        "\n",
        "    def __init__(self, attr='lr', init_val=0.0001, n_decays=200, n_warmups=3, target=None, optimizer=None):\n",
        "        self._attr = attr\n",
        "        self._target = target\n",
        "        self._optimizer = optimizer\n",
        "        self._min_loss = None\n",
        "        self._last_value = None\n",
        "        self._init_val = init_val\n",
        "        self._n_decays = n_decays - n_warmups\n",
        "        self._decay_count = 0\n",
        "        self._n_warmups = n_warmups\n",
        "\n",
        "    def __call__(self, trainer):\n",
        "        updater = trainer.updater\n",
        "        optimizer = self._get_optimizer(trainer)\n",
        "        epoch = updater.epoch\n",
        "        if epoch < self._n_warmups:\n",
        "            value = self._init_val / (self._n_warmups + 1) * (epoch + 1)\n",
        "        else:\n",
        "            value = 0.5 * self._init_val * (1 + math.cos(math.pi * (epoch - self._n_warmups) / self._n_decays))\n",
        "        self._update_value(optimizer, value)\n",
        "\n",
        "\n",
        "    def _get_optimizer(self, trainer):\n",
        "        return self._optimizer or trainer.updater.get_optimizer('main')\n",
        "\n",
        "    def _update_value(self, optimizer, value):\n",
        "        setattr(optimizer, self._attr, value)\n",
        "        self._last_value = value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "56jZaaD82p-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "最後に学習中に訓練データに意味を変えない変化を加えるData Augmentationを適用します．これは画像において回転させたり，平行移動させたりする場合と同じです．\n",
        "今回は128bp毎にカバレッジ値を予測していますが，数塩基（例えば4~8など）移動したとしてもカバレッジ値は同じ程度になることが規定されます．そこで最大max_shift分だけ配列を前後にシフトします（完全にランダムな塩基配列を余った部分に入れると実際の塩基配列の分布と変わる可能性があるのでここではroll()関数を巡回シフトしています）．"
      ]
    },
    {
      "metadata": {
        "id": "UX2NE83o274Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import random\n",
        "\n",
        "class PreprocessedDataset(chainer.dataset.DatasetMixin):\n",
        "\n",
        "    def __init__(self, xs, ys, max_shift):\n",
        "        self.xs = xs\n",
        "        self.ys = ys\n",
        "        self.max_shift = max_shift\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)\n",
        "\n",
        "    def get_example(self, i):\n",
        "        # It applies following preprocesses:\n",
        "        #     - Cropping\n",
        "        #     - Random flip\n",
        "\n",
        "        x = self.xs[i]\n",
        "        y = self.ys[i]\n",
        "\n",
        "\n",
        "        s = random.randint(-self.max_shift, self.max_shift)\n",
        "        x = np.roll(x, s, axis=0)\n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9RCVvBw0v9i-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "これで全部準備ができました．残りはchainerのtrainerを改造して学習するだけです．以下のコードを実行してください．\n",
        "\n",
        "元々のデータ全体では学習に時間がかかるので，データ/`ratio`分だけを学習，検証用データとして利用します．今回`ratio`は1に設定されています．この場合30分程度で学習が完了します．短い時間で試したい方はratio=1をratio=10やratio=20として実験してみてください．\n"
      ]
    },
    {
      "metadata": {
        "id": "b1_e0bE7wB48",
        "colab_type": "code",
        "outputId": "1aa9168c-f8a8-4048-b195-068f7a746e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import numpy as np\n",
        "from chainer.training import extensions\n",
        "from chainer import training\n",
        "import h5py\n",
        "\n",
        "ml_h5 = h5py.File('seq.h5')\n",
        "\n",
        "train_x = ml_h5['train_in']\n",
        "train_y = ml_h5['train_out']\n",
        "\n",
        "valid_x = ml_h5['valid_in']\n",
        "valid_y = ml_h5['valid_out']\n",
        "\n",
        "test_x = ml_h5['test_in']\n",
        "test_y = ml_h5['test_out']\n",
        "\n",
        "ratio = 1\n",
        "train_x = train_x[:len(train_x)//ratio]\n",
        "train_y = train_y[:len(train_y)//ratio]\n",
        "valid_x = valid_x[:len(valid_x)//ratio]\n",
        "valid_y = valid_y[:len(valid_y)//ratio]\n",
        "\n",
        "\n",
        "max_shift_for_data_augmentation = 5\n",
        "train = PreprocessedDataset(train_x, train_y, max_shift_for_data_augmentation)\n",
        "val = chainer.datasets.TupleDataset(valid_x, valid_y)\n",
        "\n",
        "batchsize = 8\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "val_iter = chainer.iterators.SerialIterator(val, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "model = L.Classifier(Net(), lossfun=log_poisson_loss, accfun=log_r2_score)\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = chainer.optimizers.Adam(alpha=lr, beta1=0.97, beta2=0.98)\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer_hooks.GradientClipping(threshold=0.01))\n",
        "\n",
        "\n",
        "updater = training.updaters.StandardUpdater(\n",
        "     train_iter, optimizer, device=0)\n",
        "\n",
        "n_epochs = 10\n",
        "n_warmups = 0\n",
        "out = \"out\"\n",
        "trainer = training.Trainer(updater, (n_epochs, 'epoch'), out=out)\n",
        "trainer.extend(CosineScheduler(attr='alpha', init_val=lr, n_decays=n_epochs, n_warmups=n_warmups), trigger=(1, 'epoch'))\n",
        "\n",
        "trainer.extend(extensions.Evaluator(val_iter, model, device = 0))\n",
        "trainer.extend(extensions.LogReport(trigger=(0.2, 'epoch')))\n",
        "trainer.extend(extensions.snapshot_object(model, 'model_epoch_{.updater.epoch}'), trigger=(1, 'epoch'))\n",
        "\n",
        "trainer.extend(extensions.PrintReport(\n",
        "          ['epoch', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger = (0.1, 'epoch'))\n",
        "\n",
        "# trainer.extend(extensions.ProgressBar())\n",
        "           \n",
        "trainer.run()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   validation/main/loss  elapsed_time\n",
            "\u001b[J0           2.09475                           67.376        \n",
            "\u001b[J0           1.83986                           117.536       \n",
            "\u001b[J0           1.89423                           167.924       \n",
            "\u001b[J0           1.81473                           217.551       \n",
            "\u001b[J1           1.85181     1.85538               277.913       \n",
            "\u001b[J1           1.79594                           328.016       \n",
            "\u001b[J1           1.75834                           378.054       \n",
            "\u001b[J1           1.75767                           427.627       \n",
            "\u001b[J1           1.72855                           478.089       \n",
            "\u001b[J2           1.73131     1.73589               538.179       \n",
            "\u001b[J2           1.70612                           587.781       \n",
            "\u001b[J2           1.71587                           638.244       \n",
            "\u001b[J2           1.65469                           688.26        \n",
            "\u001b[J2           1.70864                           738.252       \n",
            "\u001b[J3           1.62061     1.72332               798.245       \n",
            "\u001b[J3           1.67583                           848.08        \n",
            "\u001b[J3           1.64706                           898.58        \n",
            "\u001b[J3           1.68464                           948.667       \n",
            "\u001b[J3           1.64478                           998.855       \n",
            "\u001b[J4           1.62203     1.69327               1058.92       \n",
            "\u001b[J4           1.61279                           1109.06       \n",
            "\u001b[J4           1.65285                           1158.67       \n",
            "\u001b[J4           1.61581                           1209.11       \n",
            "\u001b[J4           1.63106                           1259.33       \n",
            "\u001b[J5           1.57932     1.6559                1319.33       \n",
            "\u001b[J5           1.64708                           1369.34       \n",
            "\u001b[J5           1.59305                           1418.89       \n",
            "\u001b[J5           1.6324                            1469.35       \n",
            "\u001b[J5           1.57734                           1519.27       \n",
            "\u001b[J6           1.57082     1.63748               1579.2        \n",
            "\u001b[J6           1.57364                           1629.27       \n",
            "\u001b[J6           1.56504                           1678.91       \n",
            "\u001b[J6           1.59908                           1729.31       \n",
            "\u001b[J6           1.5736                            1779.31       \n",
            "\u001b[J7           1.58521     1.62563               1839.25       \n",
            "\u001b[J7           1.54763                           1889.26       \n",
            "\u001b[J7           1.59983                           1939.32       \n",
            "\u001b[J7           1.55214                           1989.29       \n",
            "\u001b[J7           1.58855                           2039.31       \n",
            "\u001b[J8           1.58165     1.62321               2099.19       \n",
            "\u001b[J8           1.57746                           2149.05       \n",
            "\u001b[J8           1.51869                           2199.07       \n",
            "\u001b[J8           1.54404                           2249.08       \n",
            "\u001b[J8           1.56723                           2298.59       \n",
            "\u001b[J9           1.59699     1.61174               2359.01       \n",
            "\u001b[J9           1.55694                           2409.1        \n",
            "\u001b[J9           1.54513                           2459.19       \n",
            "\u001b[J9           1.51078                           2509.35       \n",
            "\u001b[J9           1.5535                            2559.16       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mN4nDWQW3Dki",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習が成功したならば，ディレクトリのout以下に学習されたモデルが出力されているはずです．実際にモデルが出力されているのかを確認しましょう．"
      ]
    },
    {
      "metadata": {
        "id": "hfT1yyTl3C9X",
        "colab_type": "code",
        "outputId": "e3a5774c-c906-49b9-a39b-ab4025188eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l out/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 14172\n",
            "-rw-r--r-- 1 root root   10463 Dec  5 14:26 log\n",
            "-rw-r--r-- 1 root root 1446319 Dec  5 13:48 model_epoch_1\n",
            "-rw-r--r-- 1 root root 1447573 Dec  5 14:27 model_epoch_10\n",
            "-rw-r--r-- 1 root root 1446569 Dec  5 13:52 model_epoch_2\n",
            "-rw-r--r-- 1 root root 1446831 Dec  5 13:56 model_epoch_3\n",
            "-rw-r--r-- 1 root root 1447090 Dec  5 14:01 model_epoch_4\n",
            "-rw-r--r-- 1 root root 1447341 Dec  5 14:05 model_epoch_5\n",
            "-rw-r--r-- 1 root root 1447398 Dec  5 14:09 model_epoch_6\n",
            "-rw-r--r-- 1 root root 1447855 Dec  5 14:14 model_epoch_7\n",
            "-rw-r--r-- 1 root root 1447819 Dec  5 14:18 model_epoch_8\n",
            "-rw-r--r-- 1 root root 1447746 Dec  5 14:22 model_epoch_9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L4eQCDXG3L6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次に，学習したモデルを用いてテストデータに対しても予測してみます．次のようにして学習が終わったモデルを読み込み，テストデータに対してモデルを適用してみましょう．"
      ]
    },
    {
      "metadata": {
        "id": "UfJ7ZEQX3UQS",
        "colab_type": "code",
        "outputId": "540fcfc5-e08e-4aef-bf9b-052ad9678abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.links as L\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_n_epoch = 10\n",
        "out_dir = 'out'\n",
        "model = L.Classifier(Net())\n",
        "chainer.serializers.load_npz('{}/model_epoch_{}'.format(out_dir, model_n_epoch), model)\n",
        "predictor = model.predictor\n",
        "\n",
        "print(len(test_x))\n",
        "with chainer.no_backprop_mode():\n",
        "    test_y_estimated = F.exp(predictor(test_x[:1]))\n",
        "\n",
        "test_y = test_y[:1]\n",
        "\n",
        "print(test_y_estimated.shape)     \n",
        "print(test_y_estimated[0,:,0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "(1, 1024, 10)\n",
            "variable([1.8609519  1.5452818  1.5602845  ... 1.0467381  0.81922424\n",
            "          0.8216049 ])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dlA0DLxY3atL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "結果を抜粋して表示してみましょう．ここでは3つ目（i=2）の出力について正解と推定結果を出力しています．今回の場合でも，学習データを絞り（クラス数を10とした），学習回数も少ないですが，ピークをか捉えられていることがわかると思います．"
      ]
    },
    {
      "metadata": {
        "id": "nN4rkeuU7rjV",
        "colab_type": "code",
        "outputId": "a200d5fe-0d25-46c5-d1a9-ce48cf295db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "y = test_y_estimated.data\n",
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = 20\n",
        "fig_size[1] = 10\n",
        "i = 0\n",
        "b1 = plt.bar(range(y.shape[1]), y[0,:,i])\n",
        "b2 = plt.bar(range(y.shape[1]), test_y[0,:,i])\n",
        "plt.legend((b1, b2), ('estimated', 'observed'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4fe18dbb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIIAAAI/CAYAAAALEXL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xm0ZVV9J/BvDUAKLO0CXhKCEUXM\njoQYh6gdRwSMGDXagU7S7ZiSCKQ0gJFqNYCioiySjpBAIi41QaJRM7XY2GCwIg5xQFEwre4OATNY\nImUoWMVgSRXVf7z34PLG++6979373v581qpV993hnH2G3xm+Z597V+3ZsycAAAAArHyrh90AAAAA\nAJaGIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKARa4c58m3bdqyY367fsGHfbN9+\n17CbASNFXcDM1AZMpy5gOnUB06mL7oyNrV8122t6BA3I2rVrht0EGDnqAmamNmA6dQHTqQuYTl30\nr6seQaWUI5J8NMk7a60XllJ+MsmlSdYk+W6Sl9Zad5ZSXpzk1CT3Jnl3rfW9i9RuAAAAABZo3h5B\npZT9kvxRkk92PP2WJBfVWp+e5IYkGyfed1aSY5IcmeS0Usr+A28xAAAAAD3p5tawnUl+KcnWjueO\nTHLZxOOPZTz8eXKSa2qtt9da707yuSRPHVxTAQAAAOjHvLeG1Vp3JdlVSul8er9a686Jx7ckOSjJ\njyfZ1vGeyecBAAAAGAGD+NWw2b6JetZvqJ60YcO+K+qLnsbG1g+7CTBy1AXMTG3AdOoCplMXMJ26\n6E+vQdAdpZR1E7eAHZzx28a2ZrxX0KSDk3xhroGspJ98Gxtbn23bdgy7GTBS1AXMTG3AdOoCplMX\nMJ266M5cYVmvPx9/VZLjJh4fl+SKJF9M8sRSyn8qpTwo498P9Jkehw8AAADAgHXzq2FPKKV8Kskr\nkpwy8fjsJC8vpXwmyf5JLpnoHfT6JFdmPCg6u9Z6+yK1GwAAAGBJ3XDDP+Vf//VfkiRvetMbsnPn\nD3oe1te+dm22b7+1q/feddddOf74F/Q8rk7dfFn0VzL+K2FTPXuG9/5Vkr/qv1kAAABAqzaeu2Wg\nw3vf648ayHCuvnpLfvqnD8/DHnZIzj77HX0N6/LLL8t/+28vyYYN+w+kbd0axJdFAwAAACxbu3fv\nznnnnZOtW7+TXbt25YQTTsott3wvf/M3H8natXvlsMN+Ki960XH56Ef/JldfvSUbNmzIWWe9Ie9/\n/4fzzneelw0bNqTWb+W227bnxS9+eS6//GO5/fbbcuGF786qVcnZZ5+Ru+++Oz/4wQ9y2mmn5847\n78hnPvOp3HTTjXnb285Lrd/Ihz7051mzZm1KeXRe85rTcuedd+R3f3dzfvjDH+Yxj3nswKZVEAQA\nAAA07e/+7ooccMCBecMbzsptt92WU045KUly3nnn58d+7Mdz+eWX5aEPfWie/ORfyJFHHp3DDz/i\nAZ9fs2ZtLrjgT3L22Wfk61+/Phdc8Md561vPzLXXfjkPf/gj8vznvyjPeMaR+cpXrskHPnBJzjnn\n93LYYT+V1752cx784Afnkkvem3e960+z995758wzX5/rr/9abrjhn3LooY/Mb//27+STn/xErrrq\nyoFMqyAIAAAAaNo//uP1ue66r+b667+WJNm5c2d+8Refmze+8fQ85znPzTHHPCf77PMjs37+0Y/+\nmSTJAQccmEMOeXiSZMOGA3LnnXdk//0PyCWXvCd/8ReX5p577smP/MgDh3PTTTfme9+7Oa997auT\nJHfeeUduvvnmfPvbN+axj31CkuRxj3vCwKZVEAQAAAA0be3avfKyl23Ms5997AOe/6Vf+uV86lNX\n5bd/++RcdNG7Z/38mjVrZny8Z8+efOQjH8yBB/5ozjzzrfnWt76RCy88/wGf3Wuv8dvB/uAPLnzA\n81//+nVZvXpVkuTee/f0PG1T9frz8QAAAAArwuGHH5HPfvbqJMn27bfm4osvysUXX5QDDzwwv/7r\nL8kRR/xsbr755qxatSq7d+9e0LBvv/22HHzwQ5MkV1/999m1a1eSZPXq1dm9e3ce9rCH59vfvum+\nXxB773svzrZtt+RhDzsk3/rWN5Mk11775UFNqiAIAAAAaNtRRx2Tdev2zUknbczmzaflMY95bPbd\nd7+ceOJv5JRTTs6qVavyqEf9VH7u5x6X88//vXz5y1/qetjHHvu8fPjDH8hpp23Kz/zMEfmP//iP\nXH75ZXnsYx+fM874H9m69Ts55ZTfyeted0pOPnljbr/9thx44FiOPfZ5+b//9+s55ZST82//9i9Z\ntWrVQKZ11Z49g+tetFDbtu0Y3sgHbGxsfbZt2zHsZsBIURcwM7UB06kLmE5dwHTqojtjY+tnTY30\nCAIAAABohCAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIgAAAAgCmOP/4Fueuu\nu4bahgsvPD8f//jHBjrMtQMdGgAAAECfNm3ZPNDhXXTUeQMd3nImCAKWxKYtm218AQCAkbRr166c\nd9452br1O/nhD3+YE044KUly6aV/muuu+2rWrFmTt7/993PnnXfmrW89M6tXr87u3btz1llvzdjY\nj9732V27duWEE07KE57wxLz61a/KoYc+Mvfee28+//nP5YMf/Ovss88++epXv5K//MsP5Ywz3py3\nv/3s7NixI7t3786pp56eww57VK688uP5wAcuydjYj2WfffbJoYc+cqDTKggCAAAAmvZ3f3dF9t57\n71x44bvz/e9vy6tffWKS5JGPPCwnnrgpF154fq688vLs2rUrT3zik/OKV5yQWr+V73//+/na167N\nAQccmDe84azcdtttOeWUk3LJJR9Kkhx66CPzohcdn3e84y35yleuyVOe8rR89rNX58gjj85HPvIX\nefKTn5IXvOBFuemmG3PBBb+fd77zolx88UV573svzfr1D84rX/mSgU+rIAgAAABoWq3fzOMe94Qk\nyYEHjmXvvffKrbf+Rx7/+J9Pkjz60T+T6667Ni960XF54xtPz44dO/KsZx2dI454TK644n/nuuu+\nmuuv/1qSZOfOnbnnnnsmPndEkuSZzzwqn/vcp/OUpzwtX/ziF/LKV56YM898Q267bXuuvPLjE5/7\nQW6//fbsu+9+2bBh/yTJz/7szw18WgVBAAAAQONWZc+ePff9dc8992T16lVZtWrV/e9YtSqHHnpY\n/uzP/iJf+tIX8q53XZjnPe+Xs3btXnnZyzbm2c8+dtpQ99prPHb5+Z9/Uv74jy/IP//zDTn44IOz\n7777Za+91ua0007PEUc85r73b9++PatX3z/Oe++9d+BT6lfDAAAAgKY9+tGH59prv5wk+d73bs7q\n1avzoAetz3XXfTVJ8o1vfD2HHPKIXHXVlbnxxhvyjGccmd/8zd9Krd/M4Ycfkc9+9uokyfbtt+bi\niy+aNvy99947j3zko/LBD74/Rx55dJLk8MOPyKc//akkyU033ZgPfejP85CHPCR33HFHduzYkV27\nduXrX79u4NOqRxAAAADQtKOP/sV89atfyWtec2J27bonp5/+xrztbW/KTTfdmL/9279Okmzc+Kr8\n+7//e37/99+edev2zerVq3PqqafnoQ/9yVx77TU56aSN2b17dzZufNWM43jmM4/KOee8KaeeenqS\n5Pjjfy3nnPPm/NZvnZB77703p576uqxevTobN74qr371q3LQQQcN/Iuik2RVZ9enpbZt247hjXzA\nxsbWZ9u2HcNuBoyUzrrwq2FwP/sMmE5dwHTqAqZTF90ZG1u/arbX3BoGAAAA0AhBEAAAAEAjBEEA\nAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABAIwRB\nAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCME\nQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAj\nBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABA\nIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAA\nQCMEQQAAAACNEAQBAAAANEIQBCy6TVs2D7sJAAAARBAEAAAA0AxBEAAAAEAjBEEAAAAAjRAEAQAA\nADRCEAQAAADQCEEQAAAAQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAEA\nAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCMEQQAAAACNEAQB\nAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAE\nAQAAADRCEAQAAADQCEEQAAAAQCMEQQAAAACNWNvLh0opD0ry/iQbkuyT5OwkNyf5kyR7klxfaz15\nUI0EAAAAoH+99gh6RZJaa31WkuOTXJDk/CSn1FqfmuQhpZTnDqaJAAAAAAxCr0HQ95McMPF4Q5Jb\nkzyi1nrNxHMfS3JMn20DAAAAYIB6CoJqrR9K8rBSyg1JPp3kdUm2d7zlliQH9d88AAAAAAal1+8I\nekmSf621HltK+bkkf5vk9o63rOpmOBs27Ju1a9f00oSRNDa2fthNgJHTWRdqBO6nHmA6dQHTqQuY\nTl30p6cgKMlTk1yZJLXW60op65Ls1fH6wUm2zjeQ7dvv6nH0o2dsbH22bdsx7GbASJlaF2oExtln\nwHTqAqZTFzCduujOXGFZr98RdEOSJydJKeWQJDuSfLOU8rSJ138lyRU9DhsAAACARdBrj6CLk7yv\nlHL1xDBOyvjPx19cSlmd5Iu11qsG1EYAAAAABqCnIKjWekeSX53hpaf31xwAAAAAFkuvt4YBAAAA\nsMwIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAAAACARgiCAAAAABohCAIAAABohCAIAAAAoBGCIAAA\nAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAA\nAACARgiCAAAAABohCAIAAABohCAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIg\nAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAAAACARgiCAAAAABohCAIAAABohCAIAAAAoBGC\nIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKAR\ngiAAAACARgiCAAAAABohCAIAAABohCAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACg\nEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAAAACARgiCAAAAABohCAIAAABohCAIAAAA\noBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAA\nAKARgiAAAACARgiCAAAAABohCAIAAABohCAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgA\nAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAAAACARgiCAAAAABohCAIAAABohCAI\nAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQg\nCAAAAKARgiAAAACARgiCAAAAABohCAIAAABohCAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiE\nIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaMTaXj9YSnlxks1JdiU5K8n1SS5NsibJd5O8tNa6\ncxCNBAAAAKB/PfUIKqUckORNSZ6W5PlJXpjkLUkuqrU+PckNSTYOqpEAAAAA9K/XW8OOSXJVrXVH\nrfW7tdZXJTkyyWUTr39s4j0AAAAAjIhebw17eJJ9SymXJdmQ5M1J9uu4FeyWJAf13ToAAAAABqbX\nIGhVkgOS/JckhyT5+4nnOl+f14YN+2bt2jU9NmH0jI2tH3YTYOR01oUagfupB5hOXcB06gKmUxf9\n6TUI+l6Sf6i17kryz6WUHUl2lVLW1VrvTnJwkq3zDWT79rt6HP3oGRtbn23bdgy7GTBSptaFGoFx\n9hkwnbqA6dQFTKcuujNXWNbrdwR9IslRpZTVE18c/aAkVyU5buL145Jc0eOwAQAAAFgEPQVBtdbv\nJPmrJF9I8n+SvCbjvyL28lLKZ5Lsn+SSQTUSAAAAgP71emtYaq0XJ7l4ytPP7q85AAAAACyWXm8N\nAwAAAGCZEQQBAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAj\nBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABA\nIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAA\nQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEABN\n2LRl87CbAAAAQycIAgAAAGiEIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAA\nAACARgiCAAAAABohCAIAAABohCAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIg\nAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAAAACARgiCAAAAABohCAIAAABohCAIAAAAoBGC\nIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKAR\ngiAAAACARgiCAAAAABohCAIAAABohCAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACg\nEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAAAACARgiCAAAAABohCAIAAABohCAIAAAA\noBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAA\nAKARgiAAAACARgiCAAAAABohCAIAAABohCAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgA\nAACgEYIgAJqxacvmYTcBAACGShAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRibT8fLqWsS/KP\nSd6a5JNJLk2yJsl3k7y01rqz7xYCAAAAMBD99gg6I8mtE4/fkuSiWuvTk9yQZGOfwwYAAABggHoO\ngkopP53k8CSXTzx1ZJLLJh5/LMkxfbUMAAAAgIHqp0fQ/0zy2o6/9+u4FeyWJAf1MWwAAAAABqyn\n7wgqpbwsyedrrTeVUmZ6y6puhrNhw75Zu3ZNL00YSWNj64fdBBg5nXWhRhgFo7Iejko7YJSoC5hO\nXcB06qI/vX5Z9POSHFpKeX6ShybZmeSOUsq6WuvdSQ5OsnW+gWzfflePox89Y2Prs23bjmE3A0bK\n1LpQI4yCUVgP7TNgOnUB06kLmE5ddGeusKynIKjW+muTj0spb07y7SRPSXJckj+f+P+KXoYNAAAA\nwOLo91fDOr0pyctLKZ9Jsn+SSwY4bAAAAAD61OutYfeptb65489n9zs8AAAAABbHIHsEAQAAADDC\nBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABA\nIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRCEAQsmU1bNg+7CQAA\nAE0TBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCMEQQAA\nAACNEAQBAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEA\nAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABAIwRB\nAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCME\nQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAj\nBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABA\nIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAA\nQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAA\nAEAjBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQAAAAQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAA\nAABAIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEAAAAAjRAEAQAAADRCEAQAAADQCEEQ\nAAAAQCMEQQAAAACNEAQBAAAANEIQBAAAANCItb1+sJRyXpKnTwzjHUmuSXJpkjVJvpvkpbXWnYNo\nJAAAAAD966lHUCnlWUmOqLX+QpJjk5yf5C1JLqq1Pj3JDUk2DqyVAAAAAPSt11vDPp3kv048vi3J\nfkmOTHLZxHMfS3JMXy0DAAAAYKB6ujWs1ro7yZ0Tf74yyceTPKfjVrBbkhzUf/MAAAAAGJSevyMo\nSUopL8x4EPSLSf6p46VV3Xx+w4Z9s3btmn6aMFLGxtYPuwkwcqbWhTph2EZlHRyVdsAoURcwnbqA\n6dRFf/r5sujnJPndJMfWWm8vpdxRSllXa707ycFJts43jO3b7+p19CNnbGx9tm3bMexmwEiZqS7U\nCcM2CuugfQZMpy5gOnUB06mL7swVlvX6ZdEPSfJ7SZ5fa7114umrkhw38fi4JFf0MmwAAAAAFkev\nPYJ+LcmBST5SSpl87uVJ3lNKOTHJvyS5pP/mAQAAADAovX5Z9LuTvHuGl57dX3MAAAAAWCy9/nw8\nAAAAAMuMIAgAAACgEYIgAOjCpi2bh90EAADomyAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiE\nIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAAAACARgiCAAAAABohCAIAAABo\nhCAIAAAAoBGCIAAAAIBGCIIAAAAAGiEIAgAAAGiEIAgA5rFpy+ZhNwEAAAZCEAQAAADQCEEQAAAA\nQCMEQQAAAACNEAQBAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAA\nAEAjBEEAAAAAjRAEAcAAbdqyedhNAACAWQmCAAAAABohCAIWld4RAAAAo0MQBAAAANAIQRAAAABA\nIwRBAAAAAI0QBAEAAAA0QhAEAAAA0AhBEAAAAEAjBEEANGfTls3DbgIAAAyFIAgAAACgEYIgAAAA\ngEYIggAAAAAaIQgCAAAAaIQgCAAAAKARgiAAAACARgiCAAAAABohCAIAAABohCAIAAAAoBGCIAAA\nAIBGCIIAAAAAGiEIAgAAAGiEIAgAAACgEYIgAFgCm7ZsHnYTAABAEAQAAADQCkEQAAAAQCMEQQAA\nAACNEAQBAAAANEIQBEBTfGkzAAAtEwQBAAAANEIQBAAAANAIQRAAAABAIwRBAAAAAI0QBAFLauO5\nW4bdBAAAgGYJggAAAAAaIQgCAAAAaIQgCAAAAKARgiAAmrRpy+ZhNwEAAJacIAgABkS4BADAqBME\nAQyQIAAAABhlgiAA6JKgDwCA5U4QBAAAANAIQRAAzEEvIAAAVhJBEMCQCBgAAIClJggCAAAAaIQg\nCAAAAKARgiAAmOB2PQAAVjpBEABMIRACAGClEgQBy46TdAAAgN4IggAg0wNGgSMAACuRIAgAAABW\nMBe46CQIgoZtPHfLsJvQtU1bNtuBseS6Wefmeo91Fgajc3+18dwty2r/BQCjRhAEI2QYJ40OpgEA\nANohCAKGTq8JAACApSEIWoGcVK88K7XXjnWV5ajf28UAAKZq/dih9elfaoIgGLLlstEbVDvXPemK\ngQwHBmG51B8ALBb7wuEw3xkmQVCDbHSWl8neQMuxV9CvfvjkYTeBDmp/cY3a/B219jAarBcArFT2\ncd0TBLHoui3IhRTuYr2XwVhIaGX59GdY889yo1XW/cEZ1Xk5qu0CgEERBNE3B0xLZxDzenIY/fQw\nmhzGXO1Zjj2YWjIqdTsq7egkaJ6ulekcBeY1DIZaApidIIhp7DhXjn6XpXWhP93Mv2EEZpbr0lru\n81uoC3Obr8Y3bdl837/WmQdts/wHY7nPx+Xe/pVCELSCKbKFWw7zbKUEBzNNx2zfh9T59yguo36X\nyaCW6aDmjRP/wehcHr0sm6VY10exnmDU9VPbaq4N9qOjbSXU4WJMQ7/HLSwvgqABUjDT9fv9QJM7\n0sXu2TJKG75uDh4637OQg41BfHdPt/On118H23julqx70hWLNl1LYeO5W+Zdp0dVLyc1w66ZUbAc\n50G/Pda6uUV0OVkp0zHqhr3NsJz7sxLnX6/TNIrzYqnaNOrHMixfo1hXK5UgaEBe8Dsfve/xKGwc\n5yuiQbdxMYKUYc/HpQyHZpvWbubBbIHLXG1ezOnp9eSy1+U9GRyNuvmmr9vpn2n+bjx3S8+f76YX\nVgtG7cBjsZfHqE0v46Yul5UYSfgMAAAM5UlEQVS8nHr5vrqVvF0apWnrZr1bqnVzqWpipuGu5Prr\n10Iv2HXqZ74u9jJpeZm3PO2tEgQNWC+9GQY57lG5RWXqsBZ7fvRz0LLUodko6SdAmWm+9LMTmakt\nk+MYtaCnsyfEoG9b6+Zq+Vw9jjrfM59+e4gtpKcd4ybnya9++OQ5X5800/rVzbZ+JW+3urHQfcJS\nz6+ZluFS3mI0iOOFXsY5iM8uVvjfTQ/kuebbQpfHcqvRYbZ3kPuS1n7sYliB3agZ9faNqqnHIObj\nyiIIGpC5DkqWS9EMq9dLv4bdu2Uxda5XcwUlU5/r5YC0m1uZ5uqNsljzaq71Zqa2DWtH1c0tNL2G\nRgutnaknSlMDq0lT16mZeqEsVjg8SoZZ570s287H3X5+skb7Xe+mjrOXXh2D1G8gOvn52fbhc9Xs\nINebxejxNdv2ehh6Cab76SU53+vdjGuuUHYQutmnD3sZDvr2z4WGL93W7yDG36vJ/etSXvycrR3D\n+Gy3wxr28fSkqdvGlm5TXUg9LzQAWsjFl0FN9+QFtVFZnsuRIGiF63anO+jbELq51Wm28KDXk8+F\nXt0dtZPShZ7gzTQv55qfsw1v6sHoIDaiS9GDZ6arwku5TBdyAt7r8BdycDk5LxYaNs0XNnYOZ75Q\nrjNw6iZY7Ob5lWjq/JzvwLTfHhD9nkxNjnvTls0zrmejpptwaJD7iH63mb2cAPeic/ktttm2W93W\nfy/zfq4ge6YLFjOtB91sYxdithC+23H2895RMlfQNtMyma8mFnrxqd9woteQZ5jLa7GOg7vptdrP\n8OYy1/FFN+c7oxQSLOQiw1zrX6/7u0Gum6M0X1kYQdCAdR4ozJSmDrtYurnq1fnefq5Wd5qcL5O3\nzS1kpzrXBny+E9PZDvKm/j/X46UyqAP0qcPpZbgLnf5exrEYJySz1d9iGuR0dNNrp/O5hRzoDaKd\n3d72OtcJ2VzvX04nOb0G1p3WPemKBa+z8y3H2bav841napi80H3VUt++OdtB9EzTvpAT8ZlCz7mG\nOVuAPzUAmK22FxryDfsYYiGmrovdTOcLfuejffXE6WVb0s1xxGw1002wNVfPn+W2XewmoEkeeMzb\nzQl6Nyeqc12omOu4cr7jvW63H1ODxW4vZA5iXzGXqe2atO5JVzxge965Ls/WprmW10KnY77zjW6G\nN/memQLVzuenTme/FnuZ9dKObs5RFnp+Ndvnkrm31/MNt9tOCIO4nXYUltNytnbYDVjpxg/yht+G\n973+qFkLaL72zVZk73v9UV29b6p1T7oid3/p2AWNa+p71j1p8v/pvVk6h93t7VSzvXcUTc6/zvnY\nbdu7OYkc9vo6qGlZbL2Of/zkLw+Yz90Ma67a6KZXT6/Dnu393a4n4zv6Y+9r191fOnbKwerk/1fc\n99rUbUvrZlumnfNskEZhOzCpc32Yum50tnO2oGXqvqaXIHPquOb7TOd7O/dJc+2LZ2r75HZi05bN\nueio8x4QUnWGwd3Uyygt04WY3H50Y756WOyLD8ns68Fcn5/a5m7CpcU0td2Tf08Nk6dOW+cJ60zT\nPbVee1kfe63DhY5jOZltO9fttPdyHrDQ4Y+3c2Hj6MfksCa3t3Pd+jvTup7cvw1erOOR2c5Pul2/\n53p+vhBuvuEttKfc1P1w59+T86/b29Fm+mznsDuX7dQ2j58bddV0Jgy8R1Ap5Z2llM+XUv6hlPLE\nQQ+fuc33PQcL7S3SecV6pgOeqVcf+m3nfK/3Or6FfmbYIUOnxeop1O175zoJXQq9ritLrZ9gaDGH\nP+h2dPP5uYY1uU2Z2htmUO1YzhZjm9bLPB61ZdC5r+m84ruQdnZeNe6l5vrdDnYGN7Ot+3OZ6yRp\nvquvs90StpjLuZf9zWzHJ/0G5XONc77n5/p7KetkKUOgqY+76RnQ+d5hHLN08/mlOEYddd22u7O3\nzXzH3TP1FJ4avsxXb/2s37O1qdsezMngehL1Y+r4p27XB73O9Vsf3fTmmvx/rnVoph5Pna91fr5z\n+7KceseOsoEGQaWUZyZ5VK31F5K8MskfDnL4jL6l2DkOage9XHfkyeK1fdjzZNjjX0z9TNuw5stS\nj3c5Lf9hB3PDDmKXcln1E2IM8sS0m/H22tZ+g+TOA+Zhn9DMZLF74wx7feznfd1+fqmPrxb7xHOu\nccz3/DD3FaN8jLmY86eXYQ7yZL3bbfkgL8oNe7vS78WhxV5Xu23zfMOfq9cWi2vQPYKOTvK/kqTW\n+s0kG0opDx7wOJaFUdhZdZpvA7rQds51RX9Q41gKo9impTLq0z7q7RsFo3Lltd9hLddlPQrB99T3\njtq+p19LEXoPOnQblZOwpRzeoI16+2bTa/0tt+kddhA923tXUuC4EC7a9GYYYetcluNF3rlC20GE\n4cNeJivdoIOgH0+yrePvbRPPNWmUV97ZimsYJ5ajPJ+S0b4KN6i0fyUeRIzKFcNBLtulClkGfeA7\n6jW+3CxV0DBKy23UrsLPdAIxCoHSKB04D7NHRLfP9zvcQQxvvtob5SCi17oc5IXJXj4zikHWKFno\ncl3M+hql7cgwzLRNX8h2rt95u1jb1MUY5igtt+Vi1Z49ewY2sFLKu5NcXmv96MTfn02ysdb6/wY2\nEgAAAAB6MugeQVvzwB5AP5HkuwMeBwAAAAA9GHQQ9IkkxydJKeXxSbbWWncMeBwAAAAA9GCgt4Yl\nSSnl3CTPSHJvkk211usGOgIAAAAAejLwIAgAAACA0TToW8MAAAAAGFGCIAAAAIBGrB12A1aCUso7\nk/znJHuSnFJrvWbITYIlVUo5L8nTM75NeUeSa5JcmmRNxn858KW11p2llBcnOTXj3yH27lrre4fU\nZFh0pZR1Sf4xyVuTfDJqAjKxzm9OsivJWUmuj9qgYaWUByV5f5INSfZJcnaSm5P8ScbPLa6vtZ48\n8d7Tk/zXiefPrrV+fCiNhkVUSjkiyUeTvLPWemEp5SfT5X6ilLJXkj9LckiS3Ul+o9Z64zCmY9Tp\nEdSnUsozkzyq1voLSV6Z5A+H3CRYUqWUZyU5YqIGjk1yfpK3JLmo1vr0JDck2VhK2S/jB/3HJDky\nyWmllP2H02pYEmckuXXisZqgeaWUA5K8KcnTkjw/yQujNuAVSWqt9VkZ//XlCzJ+LHVKrfWpSR5S\nSnluKeURSX4999fPH5RS1gypzbAoJrb/f5TxC2iTFrKf+O9Jbqu1Pi3JORm/QM0MBEH9OzrJ/0qS\nWus3k2wopTx4uE2CJfXpjF+dSpLbkuyX8Q3yZRPPfSzjG+knJ7mm1np7rfXuJJ9L8tSlbSosjVLK\nTyc5PMnlE08dGTUBxyS5qta6o9b63Vrrq6I24PtJDph4vCHjFxAe0XGHwWRdPCvJ/6m1/rDWui3J\nv2R8PwMryc4kv5Rka8dzR6b7/cTRSf524r1Xxb5jVoKg/v14km0df2+beA6aUGvdXWu9c+LPVyb5\neJL9aq07J567JclBmV4rk8/DSvQ/k7y24281AcnDk+xbSrmslPKZUsrRURs0rtb6oSQPK6XckPGL\na69Lsr3jLeqCZtRad00EO50Wsp+47/la671J9pRS9l7cVi9PgqDBWzXsBsAwlFJemPEg6NVTXpqt\nJtQKK1Ip5WVJPl9rvWmWt6gJWrUq4z0ffiXjt8P8aR643qsNmlNKeUmSf621HpbkqCR/PuUt6gLu\nt9B6UCezEAT1b2se2APoJzL+JVbQjFLKc5L8bpLn1lpvT3LHxBflJsnBGa+TqbUy+TysNM9L8sJS\nyheSnJDkzKgJSJLvJfmHiSu+/5xkR5IdaoPGPTXJlUlSa70uybokB3a8ri5o3UKOoe57fuKLo1fV\nWn+4hG1dNgRB/ftExr/YLaWUxyfZWmvdMdwmwdIppTwkye8leX6tdfKLca9KctzE4+OSXJHki0me\nWEr5TxO/kPHUJJ9Z6vbCYqu1/lqt9Ym11v+c5D0Z/9UwNQHjx0xHlVJWT3xx9IOiNuCGjH/fSUop\nh2Q8IP1mKeVpE6//SsbrYkuS55VS9i6l/ETGT3y/MYT2wlJbyH7iE7n/u0tfkOTvl7ity8aqPXv2\nDLsNy14p5dwkz8j4T9dtmkjzoQmllFcleXOS/9fx9MszfgL8Ixn/MsPfqLXeU0o5PsnpGf/Z0z+q\ntX5giZsLS6qU8uYk38741d73R03QuFLKiRm/jThJ3pbkmqgNGjZxEvu+JD+WZG3Ge5HenOTijF+0\n/2Kt9bUT731NkhdnvC7OqLV+csaBwjJVSnlCxr9n8eFJ7knynYyv83+WLvYTE7+k954kj8r4F0+/\notb6b0s9HcuBIAgAAACgEW4NAwAAAGiEIAgAAACgEYIgAAAAgEYIggAAAAAaIQgCAAAAaIQgCAAA\nAKARgiAAAACARgiCAAAAABrx/wFBpRFw7Rp/lAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4fe6433210>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pmaz68ZrsFOb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "時間に余裕があれば学習のn_epochsを60から200程度に増やしたり，総数を増やしたり，チャンネル数を増やしたり，学習データ数（ratio=20をratio=5などにして）に増やしたりして，より高精度なモデルが学習できるのかを調べてみましょう．\n"
      ]
    },
    {
      "metadata": {
        "id": "7ThNVkbDGWrN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   [1] \"Sequential regulatory activity prediction across chromosomes with convolutional neural networks\", D. R. Kelly and et al., Genome Res. 2018. 28: 739-750\n",
        "*  [2] \"Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks\",  T. Salimans and et al., arXiv:1602.07868\n",
        "*  [3]  \"Language Modeling with Gated Convolutional Networks\", Y. N. Dauphin and et al., arXiv:1612.08083\n"
      ]
    }
  ]
}