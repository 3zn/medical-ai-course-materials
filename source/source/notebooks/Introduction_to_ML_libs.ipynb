{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習ライブラリの基礎\n",
    "\n",
    "ここでは、代表的な機械学習アルゴリズムの紹介とチューニングのポイントをその数学的な背景と合わせて紹介します。\n",
    "機械学習の考え方を身に着ける練習として、単回帰分析と重回帰分析のアルゴリズムを一緒に考えていきましょう。これらを学ぶことで微分と線形代数、統計に関する知識が大幅に深まります。\n",
    "\n",
    "## 単回帰分析\n",
    "\n",
    "機械学習アルゴリズムの第一弾として、最も基礎的な単回帰分析について紹介する。ほかの書籍では、基礎的な数学を前半で紹介して、後半で機械学習アルゴリズムを紹介するものも多いが、単回帰分析を学びながら具体的な微分の計算が身につくため、本書では基礎的な数学とそれに対応する機械学習アルゴリズムを交互に学びながら、知識を深めていくこととする。\n",
    "\n",
    "単回帰分析は教師あり学習の一種である。その中でも、数値（厳密には連続値）を予測する**回帰**を取り扱う手法である。単回帰分析は、ひとつの入力変数からひとつの出力変数を予測する機械学習アルゴリズムである。\n",
    "\n",
    "### 問題設定\n",
    "\n",
    "身近な例で想像がつきやすいものとして、家賃の予測を考えることとする。つまり家賃が出力変数 $y$ となる。\n",
    "\n",
    "次に考えるべき問題としては、入力変数として何を採用するかである。機械学習では、データをもとに学習するが、一番最初にどのデータを使ってどの値を予測させるかは人間側で決めないといけない。そのため、入力変数として何を採用するかといった問題は、人間側の経験に依存する。例えば、今回で言えば、部屋の広さか、駅からの距離か、それとも犯罪発生率を入力変数として採用するか悩ましいところである。今回は私の経験上、重要そうだと感じる部屋の広さを入力変数$x$として採用することとする。実際には、このように複数の候補があった際に、それらすべてを扱うことができるようなモデル化が一般的であり、この次の重回帰分析以降で紹介していく。\n",
    "\n",
    "機械学習アルゴリズムは、どの手法も大きく分けて3つのステップで成り立っており、この3つのステップが1セットでひとつのアルゴリズムである。\n",
    "\n",
    "- モデルを決める\n",
    "- 目的関数を決める\n",
    "- 最適なパラメータを求める\n",
    "\n",
    "### Step1. モデルを決める\n",
    "\n",
    "まず**Step1**は**モデル**を決める。このモデルとは一見もっともらしい用語ではあるが、具体的には何であるのか。それは、出力変数$y$と入力変数$x$の関係性を定式化したものである。家賃の予測値を$y$とした際に、どのように定式化すればうまく予測することができるのか。このモデルは残念ながら機械が自動的に決めてくれるわけではなく、人間が経験と勘で決める作業になる。\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/3/01.png)\n",
    "\n",
    "例えば、与えられたデータセットにおいて、家賃と部屋の広さの関係性が次のようになっている。数値は実際の家賃ではなく計算が簡単にできるように設定しているが、部屋の広さが広くなるほど、家賃が高くなるという設定である。このデータを見た際に、どのように予測のための線を描けば良いかと考えると、このように直線を引く人が多いのではないだろうか。\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/3/02.png)\n",
    "\n",
    "直線の式は中学の数学でもおさらいしたが、$y=ax+b$ である。$a$ を傾き、$b$ を切片と呼んでいた。\n",
    "\n",
    "今回、このデータセットに対して、直線を引くことが適切であると（人間側の経験で）判断したため、以下のようにモデルを決める。\n",
    "$$\n",
    "y = wx + b\n",
    "$$\n",
    "傾き $a$ の箇所が $w$ となっているが、一般的に機械学習では、傾きの箇所を**重み (weight)** $w$, 切片 $b$ の箇所を**バイアス (bias)** $b$ で記述することが多いので覚えておいてほしい。\n",
    "\n",
    "単回帰分析では、このように直線 $y = wx + b$ と決めて、その重みとバイアスの値をデータにうまくフィットするように調整していくのである。この調整すべき変数のことを**パラメータ**と呼ぶ。つまり、今回は $w$ と $b$ がパラメータである。これより、この単回帰分析含めた機械学習の（学習工程の）ゴールとしては、与えられたデータセットに基づいて、最適なパラメータを求めることである。ここで与えられたデータセットとは、部屋の広さ $x$ と教師データとなる家賃 $t$ のことであり、$\\mathcal{D} = \\{x_n, t_n\\}_{n=1}^{N}$ として表す。ここで、添え字 $n$ ($n=1,2,\\ldots,N$)は$n$番目の物件という意味であり、$N$は全体の物件数のことである。この$N$を**サンプル数**という。\n",
    "\n",
    "ここで、この後の計算を楽に進めるために、**データの中心化**というテクニックを紹介する。図に示すように、部屋の広さと家賃は両方とも正の値であるため、左のグラフのような形になる。これは当然のことで問題はないが、これを中心化では、平均を0とした中央に配置するように変換の処理を施す。この中心化はどのアルゴリズムでも前処理として行うことが一般的である（厳密には正規化がよく用いられ、〇〇章で解説する）。\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/3/03.png)\n",
    "\n",
    "この中心化の処理自体はそれほど難しいものではないが、なぜこのような処理を行うのかが問題である。それはデータの中心化によって、バイアス $b$ が0となり、$y_{c} = wx_{c}$ とすることができ、調整すべきパラメータを2つから1つに減らすことができる。\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/3/04.png)\n",
    "\n",
    "今回は、2つのパラメータを手計算で求めることを楽にするために、このデータの標準化を前処理として使用することとする。一般に、数式を変形していく際に、バイアス $b$ を省略できたほうが計算が楽なケースが多く、そのような場合は、前処理としてデータの標準化を行ったこととして、議論を進めることが多いため、この処理も覚えておいてほしい。\n",
    "\n",
    "さて、データの中心化の目的は明確となったところで、このデータの中心化が難しければ、まったく意味がない。何かを簡単にするために、複雑な処理を挟んでしまっては本末転倒である。しかし、データの中心化は非常に簡単であり、入出力の平均をデータの全体から引くだけでよい。つまり、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{c} &= x - \\bar{x} \\\\\n",
    "t_{c} &= t - \\bar{t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "となる。\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/3/05.png)\n",
    "\n",
    "例えば、具体的な数値で見ると、下図となる。\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/3/06.png)\n",
    "\n",
    "この処理をプログラムで書くことは非常に容易である。\n",
    "\n",
    "添え字の $c$ に関して、この先も書いていくと表現が冗長となるため、今後はこの添え字を省略し、データの中心化を事前に行っていることを前提とする。この時、モデルは\n",
    "$$\n",
    "y = wx\n",
    "$$\n",
    "となる。このとき、単回帰分析のゴールは、データセット $\\mathcal{D} = \\{x_n, t_n\\}_{n=1}^{N}$ に基づいて、パラメータ$w$ を適切に調整することである。\n",
    "\n",
    "### Step2. 目的関数を決める\n",
    "\n",
    "Step1では決めたゴールには曖昧さが残っていた。それは「適切」という言葉である。一見もっともらしくも聞こえるが、適切の定義を決めていない中で適切は存在しない。そこで、適切の定義を決める必要があり、これを関数として定義したものを**目的関数**と呼ぶ。領域によっては評価関数と呼ばれることもある。\n",
    "\n",
    "さて、今回はどのように目的関数を決めれば良いか。それは微分の時にもすでに紹介しているが、教師データと予測値の二乗誤差が小さければ小さいほど、適切と呼べるのではないだろうか。理想的には二乗誤差が0となれば、t = y となり、完璧な予測といえる。そのため、$n$ 番目の物件に対する教師データ$t_{n}$ と予測値$y_{n}$の二乗誤差は\n",
    "$$\n",
    "(t{_n} - y_{n})^{2}\n",
    "$$\n",
    "となる。これを全物件で考慮する必要があるため、最終的な目的関数は\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=\\left( t_{1}-y_{1}\\right)^{2}+\\left( t_{2}-y_{2}\\right)^{2}+\\ldots + (t_{N}-y_{N})^{2} \\\\\n",
    "&=\\sum^{N}_{n=1}\\left( t_{n}-y_{n}\\right)^{2}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "となる。また、Step1で決めたモデルより、\n",
    "$$\n",
    "y_{n} = wx_{n}\n",
    "$$\n",
    "となるため、目的関数は\n",
    "$$\n",
    "\\mathcal{L}=\\sum^{N}_{n=1}\\left( t_{n}-wx_{n}\\right)^{2}\n",
    "$$\n",
    "とパラメータを含んだ形式で表現することができる。目的関数の中でも、教師データと予測値の差（損失）を考慮したんものを**損失関数**と呼ぶ。損失関数は常に最小化したいというモチベーションでパラメータの最適化を行う。\n",
    "\n",
    "### Step3. 最適なパラメータを求める \n",
    "\n",
    "モデルと目的関数が決まると、あとは目的関数を最小化するようなパラメータを求めるだけである。ここで、ある関数を最小化する点を求める方法としては微分が使えることをすでに学んでいる。そのため微分して「傾き0」となる点が最適なパラメータである。\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac{\\partial }{\\partial w} \\mathcal{L}  &= \\dfrac{\\partial}{\\partial w} { \\sum^{N}_{n=1} ( t_{n}-wx_{n})^{2} }\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "ここで、微分は線形性の性質を持っており、わかりにくいかもしれないが、現状ではすべての足し算を終えた後に微分を行っているが、これはそれぞれ微分した後に、それを足し算することでも同じ結果であった。これより、\n",
    "$$\n",
    "\\dfrac{\\partial}{\\partial w} \\mathcal{L}=\\sum^{N}_{n=1}\\dfrac {\\partial }{\\partial w}\\left( t_{n}-wx_{n}\\right)^{2}\n",
    "$$\n",
    "も同じである。この微分と総和 $\\sum$ の記号が入れ替わる場面はよくあるので、この理由もしっかりと覚えておきたい。とりあえず入れ替えられるではなく、式変形の裏側には必ず理由がある。そして、\n",
    "$$\n",
    "\\dfrac {\\partial }{\\partial w}\\left( t_{n}-wx_{n}\\right)^{2}\n",
    "$$\n",
    "の部分は合成関数になっていることがわかる。$u_{n} = t_{n} - wx_{n}$ とおくと、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac {\\partial }{\\partial w}\\left( t_{n}-wx_{n}\\right)^{2} &=  \\dfrac {\\partial }{\\partial w} f(u_{n}) \\\\ \\because f(u_{n}) &= u_{n}^{2}\\\\\n",
    "\\Rightarrow \\dfrac {\\partial }{\\partial w} f(u_{n}) &= \\dfrac {\\partial u_{n}}{\\partial w} \\dfrac{\\partial f(u_{n})}{\\partial w} \\\\\n",
    "&=-x_{n} \\times 2 \\left( t_{n}-wx_{n}\\right)  \\\\\n",
    "&= -2x_{n}( t_{n}-wx_{n} )\n",
    "\\end{aligned}\n",
    "$$\n",
    "が得られる。これより、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac{\\partial }{\\partial w} \\mathcal{L}\n",
    "&=\\sum^{N}_{n=1}\\dfrac {\\partial }{\\partial w}\\left( t_{n}-wx_{n}\\right)^{2}\n",
    "\\\\&=-\\sum^{N}_{n=1}2x_{n}\\left( t_{n}-wx_{n}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "となる。この微分の値が0となるように$w$を決めていくと、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac {\\partial }{\\partial w} \\mathcal{L} &=0\\\\\n",
    "-2\\sum^{N}_{n=1}x_{n}\\left( t_{n}-wx_{n}\\right) &=0\\\\\n",
    "-2 \\sum^{N}_{n=1}x_{n}t_{n} + 2\\sum^{n}_{n=1}wx^{2}_{n}&=0\\\\\n",
    "-2\\sum^{N}_{n=1}x_{n}t_{n}+2w\\sum^{N}_{n=1}x^{2}_{n}&=0\\\\\n",
    "w\\sum^{N}_{n=1}x^{2}_{n}&=\\sum^{n}_{n=1}x_{n}t_{n}\\\\\n",
    "\\Rightarrow w&=\\dfrac {\\displaystyle  \\sum^{N}_{n=1}x_{n}t_{n}}{\\displaystyle  \\sum^{N}_{n=1}x^{2}_{n}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "となる。この求まったパラメータを確認すると、データセット $\\mathcal{D} = \\{x_n, t_n\\}_{n=1}^{N}$ のみから決定できていることがわかる。\n",
    "\n",
    "数式での議論を進めることができたため、もう少し具体的なイメージを持つために、例題にあげていた数値例でパラメータ $w$ を求めてみる。まずは、データの中心化が必要である。\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\bar{x} &= \\dfrac{1}{3} (1 + 2 + 3) = 2 \\\\\n",
    "\\bar{t} &= \\dfrac{1}{3}(2 + 3.9 + 6.1) = 4\n",
    "\\end{aligned}\n",
    "$$\n",
    "そして、各変数に対して前処理として、平均を引く中心化の処理を施す。\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{1} &= 1 - 2 = -1 \\\\\n",
    "x_{2} &= 2 -2 = 0 \\\\\n",
    "x_{3} &= 3- 2 = 1\\\\\n",
    "t_{1} &= 2 - 4 = -2\\\\\n",
    "t_{2} &= 3.9 - 4 = -0.1\\\\\n",
    "t_{3} &= 6.1 - 4 = 2.1 \n",
    "\\end{aligned}\n",
    "$$\n",
    "そして、中心化後の値を用いて、最適なパラメータ$w$を導出する。\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w &= \\dfrac{\\displaystyle \\sum_{n=1}^{N}x_{n}t_{n}}{\\displaystyle  \\sum_{n=1}^{N}x_{n}^{2}} \\\\\n",
    "&= \\dfrac{x_{1}t_{1} + x_{2}t_{2} + x_{3}t_{3}}{x_{1}^{2} + x_{2}^{2} + x_{3}^{2}} \\\\\n",
    "&= \\dfrac{-1 \\times (-2) + 0 \\times 0.1 + 1 \\times 2.1}{(-1)^{2} + 0^2 + 1^2} \\\\\n",
    "&= 2.05\n",
    "\\end{aligned}\n",
    "$$\n",
    "これで単回帰分析の学習の手順が完了した。この求まったパラメータを使用したモデルが学習済みモデルである。\n",
    "\n",
    "ただし、機械学習は学習済みモデルを使用して推論を行うことで初めて活用であることを忘れてはならない。例えば、$x_{q}=1.5$ となるデータが新たなサンプルとして与えられた時の推論を行うと、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{q} - \\bar{t} &= w(x_{q}-\\bar{x}) \\\\\n",
    "\\Rightarrow y_{q} &= w(x_{q}-\\bar{x}) + \\bar{t} \\\\\n",
    "&= 2.05 \\times (1.5 - 2) + 4 \\\\\n",
    "&= 2.975\n",
    "\\end{aligned}\n",
    "$$\n",
    "のように新たなサンプルに対する予測値が求まった。これが機械学習の一連の手順である。単回帰分析自体は本書の中で最もシンプルな方法であるが、全体像を把握することと、微分の使いどころを把握するために、とても良い学びとなったと思う。\n",
    "\n",
    "## 重回帰分析\n",
    "\n",
    "多変数の入力変数を扱う際にその基礎となるアルゴリズムが重回帰分析。そして、この重回帰分析を学ぶことで線形代数に関する知識が大幅に深まる。\n",
    "\n",
    "重回帰分析は単回帰分析と同様に教師あり学習の一種であり、回帰を取り扱う手法である。問題設定に関しては、ほとんど単回帰分析と同じであるが、重回帰分析では入力変数の数が複数となる。つまり、複数の入力変数から複数の出力変数を予測できる機械学習アルゴリズムである。\n",
    "\n",
    "### 問題設定\n",
    "\n",
    "ここでは単回帰分析の場合と同様、身近な例で想像がつきやすい家賃の予測を考えることとする。つまり家賃が出力変数$y$となる。そして、入力変数としては、前回の単回帰分析では考慮しきれていなかった駅からの距離や犯罪発生率なども考慮していく。例えば、部屋の広さ$x_{1}$, 駅からの距離$x_{2}$, ..., 犯罪さっ成立$x_{M}$ のように $M$ 個の入力変数がある前提で話を進めていくこととする。\n",
    "\n",
    "単回帰分析でも紹介したが、どの手法も大きく分けて以下の3つのステップで成り立っている。\n",
    "\n",
    "- モデルを決める\n",
    "- 目的関数を決める\n",
    "- 最適なパラメータを求める\n",
    "\n",
    "### Step1. モデルを決める\n",
    "\n",
    "単回帰分析のモデルは、\n",
    "$$\n",
    "y = wx + b\n",
    "$$\n",
    "であった。ここで、$w$を重み（weight）、$b$をバイアス(bias)と呼んだ。重回帰分析では、この式を複数の入力変数に拡張し、\n",
    "$$\n",
    "y=w_{1}x_{1}+w_{2}x_{2}+\\ldots +w_{M}x_{M}+b\n",
    "$$\n",
    "のような線形結合の形で表す。果たして、このような定式化が実際の問題にうまくいくのだろうか。実問題では、このような定式化ではうまく表現できないような問題も多数存在する。この点もしっかりと押さえておく必要がある。参考書で紹介されると、その方法が良いように感じるが、良い場合と悪い場合とある。**ノーフリーランチ定理**という有名な定理で述べられているが、すべての問題に対して、高性能なアルゴリズムは存在しない。そのため、どの手法に関しても一長一短があり、各問題に合わせて取捨選択をするる必要がある。重回帰分析は数式がシンプルで理解しやすく、計算量が少ないといったメリットを持つ反面、データ構造が複雑になっているケースに関しては、うまく適合できないといったデメリットがある。重回帰分析ではうまくいかないような場合の機械学習アルゴリズムは今後紹介していくので安心してほしい。それでは、まず重回帰分析からしっかり理解していきたい。\n",
    "\n",
    "重回帰分析のモデルでは、規則性を持っているため、きれいに書くことができる。例えば、\n",
    "$$\n",
    "y = \\sum_{m=1}^{M} w_{m} x_{m} + b\n",
    "$$\n",
    "のように書くのはどうだろうか。このようにすっきりと書くことができるが、私はこの書き方があまり好きではない。線形代数で学んだ事項を使うと、もっとすっきりと直感的な式でかけるためである。\n",
    "\n",
    "まず、バイアス$b$がきれいな規則性に沿っていないため、この取り扱いについて考える。単回帰分析では、データの中心化によって、バイアス$b$を無視できように式変形を行ったが、前回はそれによって、求めるべきパラメータが$w$の１つだけになり、手計算の量が減るというメリットがあったが、今回$b$が省略できたところで、パラメータの数が$M+1$個から$M$個に減るだけでほとんどメリットがない。そこで、下記のように、バイアス$b$を$w$で表現して、同じ規則性で包含できるようにする。\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y&=w_{1}x_{1}+w_{2}x_{2}+\\ldots +w_{M}x_{M}+b\\\\\n",
    "&=w_{1}x_{1}+w_{2}x_{2}+\\ldots +w_{M}x_{M}+w_{0} x_{0}\\\\\n",
    "&=w_{0}x_{0}+w_{1}x_{1}+\\ldots +w_{M}x_{M}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "ただし、$x_{0}=1$, $w_{0}=b$である。このようにバイアス$b$を包含するテクニックは機械学習を学ぶ上、そして本書でも何度も登場するため、しっかりと覚えてほしい。そして、この式を整理していくと、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y&=w_{0}x_{0}+w_{1}x_{1}+\\ldots +w_{M}x_{M}\\\\\n",
    "&=\\begin{bmatrix}\n",
    "w_{0} & w_{1} & \\ldots  & w_{n}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "x_{0} \\\\\n",
    "x_{1} \\\\\n",
    "\\vdots  \\\\\n",
    "x_{M}\n",
    "\\end{bmatrix}\\\\\n",
    "&=w^{T}x\n",
    "\\end{aligned}\n",
    "$$\n",
    "のように、線形結合で表される場合、ベクトルの内積で表現することができる。また、今後取り扱う際には、$x$が前に来ているほうが何かと便利なことから、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y&=w_{0}x_{0}+w_{1}x_{1}+\\ldots +w_{M}x_{M}\\\\\n",
    "&=\\begin{bmatrix}\n",
    "x_{0} & x_{1} & \\ldots  & x_{n}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "w_{0} \\\\\n",
    "w_{1} \\\\\n",
    "\\vdots  \\\\\n",
    "w_{M}\n",
    "\\end{bmatrix}\\\\\n",
    "&=x^{T}w\n",
    "\\end{aligned}\n",
    "$$\n",
    "として表すこともできる。今回はこちらで進めていく。\n",
    "\n",
    "### Step2. 目的関数を決める\n",
    "\n",
    "単回帰分析では、教師データ$t$と予測値$y$の二乗誤差を小さくできるほど、良い予測であると定義して、この総和を目的関数として定めた。さて、重回帰分析では、これと問題設定が変わるだろうか。単回帰分析でも重回帰分析でも、予測値$y$を求めるということは同じであるため、同じ目的関数で良い。そのため、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L&=\\left( t_{1}-y_{1}\\right)^{2}+\\left( t_{2}-y_{2}\\right)^{2}+\\ldots + \\left( t_{N}-y_{N}\\right)^{2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "のように、二乗誤差の総和を単回帰分析同様、目的関数として採用する。単回帰分析では、これを\n",
    "$$\n",
    "\\mathcal{L}=\\sum^{N}_{n=1} ( t_{n} - y_{n})^{2}\n",
    "$$\n",
    "のように、総和の記号を使ってまとめていたが、ここでも線形代数で学んだテクニックを活かして、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L&=\\left( t_{1}-y_{1}\\right)^{2}+\\left( t_{2}-y_{2}\\right)^{2}+\\ldots + \\left( t_{N}-y_{N}\\right)^{2}\\\\\n",
    "&=\\begin{bmatrix} t_{1} - y_{1} & t_{2}-y_{2} & \\ldots & t_{N}-y_{N} \\end{bmatrix} \\begin{bmatrix}\n",
    "t_{1}-y_{1} \\\\\n",
    "t_{2}-y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "t_{N}-y_{N}\n",
    "\\end{bmatrix}\\\\\n",
    "&=\\left( t-y\\right)^{T}\\left( t-y\\right) \n",
    "\\end{aligned}\n",
    "$$\n",
    "のようにベクトルの内積で表現する。また、$y$に関して、Step3に入る前に式を整理しておくと、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y=\\begin{bmatrix}\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "y_{N}\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "x_{1}^{T}w \\\\\n",
    "x_{2}^{T}w \\\\\n",
    "\\vdots  \\\\\n",
    "x_{N}^{T}w\n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "x_{1}^{T} \\\\\n",
    "x_{2}^{T} \\\\\n",
    "\\vdots  \\\\\n",
    "x_{N}^{T}\n",
    "\\end{bmatrix}\n",
    "w\n",
    "\\end{aligned}\n",
    "$$\n",
    "のように、書くことができ、中の構造の抽象度が高まりわかりにくくなってきたため一度分解すると、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y&=\n",
    "\\begin{bmatrix}\n",
    "x_{10} & x_{11} & x_{12} & \\ldots  & x_{1M} \\\\\n",
    "x_{20} & x_{21} & x_{22} & \\ldots  & x_{2M} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots  & \\vdots  \\\\\n",
    "x_{N0} & x_{N1} & x_{N{2}} & \\ldots  & x_{NM}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "w_{1} \\\\\n",
    "w_{2} \\\\\n",
    "\\vdots  \\\\\n",
    "w_{M}\n",
    "\\end{bmatrix}\\\\\n",
    "\\Rightarrow y&=Xw\n",
    "\\end{aligned}\n",
    "$$\n",
    "となっている。ここで、行（横）方向がサンプルを表しており、例えば各物件に相当する。列（縦）方向が入力変数を表しており、例えば、部屋の広さ駅からの距離などが入っている。もう少し具体的な数値で考え、部屋の広さ50m$^{2}$で駅からの距離600m, 犯罪発生率2%のような物件の場合、\n",
    "$$\n",
    "x^{T} = \\begin{bmatrix}\n",
    "1 & 50 & 600 & \\cdots & 0.02\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "のようにデータが行方向格納されているイメージである。先頭の $1$ はバイアスを包含する際に使用している$x_{0}$であることに注意されたい。\n",
    "\n",
    "### Step3. パラメータを最適化する\n",
    "\n",
    "それでは、Step1で定めたモデルのパラメータを、Step2で定めた目的関数を最小化するように決めていく。\n",
    "\n",
    "まずは目的関数に関して、パラメータ$w$で表現できるように式変形を行うと、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=\\left( t-y\\right)^{T}\\left( t-y\\right) \\\\\n",
    "&=\\left( t-Xw\\right)^{T}\\left( t-Xw\\right) \\\\\n",
    "&= \\left\\{ t^{T}-(Xw)^{T}\\right\\}\\left( t-Xw\\right) \\\\\n",
    "&=\\left( t^{T}-w^{T}X^{T}\\right)\\left( t-Xw\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "となり、転置の公式 $(AB)^{T} = B^{T}A^{T}$ を使っている。さらに分配法則を使って展開を進めていくと、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=t^{T}t-t^{T}Xw-w^{T}X^{T}t + w^{T}X^{T}Xw\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "となる。ここに対して微分をしていくのも良いがさらにもう少し整理することができる。この整理には少しテクニックが必要である。\n",
    "$$\n",
    "(1)^T = 1\n",
    "$$\n",
    "というように、当然であるが、スカラーは転置しても同じであることがわかる。さて、上式の中で出てくる $t^{T}Xw$ はスカラー・ベクトル・行列のどれに対応するであろうか。忘れた方はサイズ感のページで確認していただきたい。これはスカラーである。そのため、\n",
    "$$\n",
    "(t^{T}Xw)^{T} = t^{T}Xw\n",
    "$$\n",
    "が成り立つはずである。さらに、転置の公式 $(ABC)^T = A^TB^TC^T$ より、\n",
    "$$\n",
    "(t^{T}Xw)^T = w^{T} X^{T} t\n",
    "$$\n",
    "も成り立つ。これより、\n",
    "$$\n",
    "(t^{T}Xw)^{T} = t^{T}Xw = w^{T} X^{T} t\n",
    "$$\n",
    "を導くことができ、目的関数が、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}=t^{T}t-2t^{T}Xw + w^{T}X^{T}Xw\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "とまとめることができる。ここで、今回は$w$に関する偏微分を行っていくため、ひとまず$w$に以外の定数項をまとめると、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L&=t^{T}t-2t^{T}Xw+w^{T}X^{T}Xw\\\\\n",
    "&=t^{T}t-2\\left( X^{T}t\\right)^{T} w+w^{T}X^{T}Xw \\\\\n",
    "&=c+b^{T}w+w^{T}Aw \n",
    "\\end{aligned}\n",
    "$$\n",
    "のように、線形代数で学んだ$w$に関する二次関数となっており、$A= X^{T}X, \\ b =-2 X^{T}t, \\ c=t^{T}t$ である。ここで、$b$ を転置の形式にした理由は、線形代数で学んだベクトルで微分の公式の形式に合わせるためである。\n",
    "\n",
    "それでは、目的関数を最小化することができるパラメータ$w$の求め方を考える。先述の通り、目的関数はパラメータ$w$に関して二次関数である。例えば、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w = \\begin{bmatrix}\n",
    "w_{1} \\\\ w_{2}\n",
    "\\end{bmatrix}, \n",
    "A=\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix},b=\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2\n",
    "\\end{bmatrix},C=1\n",
    "\\end{aligned}\n",
    "$$\n",
    "のように具体的な数値例で考えてみると、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L} &=\n",
    "w^{T}Aw+b^{T}w+c\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "w_{1} & w_{2}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "w_{1} \\\\\n",
    "w_{2}\n",
    "\\end{bmatrix}\n",
    "+\\begin{bmatrix}\n",
    "1 & 2\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "w_{1} \\\\\n",
    "w_{2}\n",
    "\\end{bmatrix}+1\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "w_{1} & w_{2}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "w_{1}+2w_{2} \\\\\n",
    "3w_{1}+4w_{2}\n",
    "\\end{bmatrix}+w_{1}+2w_{2}+1\\\\\n",
    "&=w_{1}\\left( w_{1}+2w_{2}\\right) +w_{1}\\left( 3w_{1}+4w_{2}\\right) +w _{1}+2w_{2}+1\\\\\n",
    "&=w^{2}_{1}+5w_{1}w_{2}+4w^{2}_{2}+w_{1}+2w_{2}+1 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "となり、$w_{1}, w_{2}$に関してそれぞれまとめると、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}\n",
    "&=w^{2}_{1}+\\left( 5w_{2}+1\\right) w_{1} + \n",
    "\\left( 4w^{2}_{2}+2w_{2}+1\\right) \\\\\n",
    "&=w^{2}_{2}+\\left( 5w_{1}+2\\right) w_{2}+\\left( w^{2}_{1}+w_{1}+1\\right) \\end{aligned}\n",
    "$$\n",
    "のようにそれぞれの二次関数であることがわかる。ただし、$w_{1}$と$w_{2}$が独立であるといった仮定もあるが、詳細な仮定は数式が複雑になるため、ひとまず置いておくとする。\n",
    "\n",
    "そして、二次関数であれば、このような形となることがわかる。\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/5/01.png)\n",
    "\n",
    "これを3次元でイメージすると、下図のようになる。\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/5/02.png)\n",
    "\n",
    "そして、各変数で微分して傾きが0となる位置において、目的関数である二乗誤差の総和が最小となる点である。\n",
    "\n",
    "![](https://github.com/japan-medical-ai/medical-ai-course-materials/raw/master/notebooks/images/5/03.png)\n",
    "\n",
    "この例では、$w_{1}$ と $w_{2}$ の２つのパラメータの場合で考えたが、これは $w_{1}$, $w_{2}$, $\\ldots$, $w_{M}$ の場合でも同様に考えることができ、目的関数が最小となる点は\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\dfrac {\\partial }{\\partial w_{0}}\\mathcal{L}=0\\\\\n",
    "\\dfrac {\\partial }{\\partial w_{1}}\\mathcal{L}=0\\\\\n",
    "\\ \\ \\ \\ \\ \\vdots \\\\\n",
    "\\dfrac {\\partial }{\\partial w_{M}}\\mathcal{L}=0\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "となり、これをまとめると、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "\\dfrac {\\partial}{\\partial w_{0}} \\mathcal{L} \\\\\n",
    "\\dfrac {\\partial}{\\partial w_{1}} \\mathcal{L} \\\\\n",
    "\\vdots  \\\\\n",
    "\\dfrac {\\partial}{\\partial w_{M}} \\mathcal{L} \\\\\n",
    "\\end{bmatrix}&=\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\vdots  \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "\\Rightarrow \\dfrac {\\partial}{\\partial w} \\mathcal{L} &= 0 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "のように表される。あとは、上式を満たすように$w$を決めていけばよい。下記の計算にはベクトルの微分をはじめとして、線形代数で学んだ内容をフル活用しているため、計算途中がわからなくなった場合は、線形代数の章を確認されたい。\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dfrac {\\partial }{\\partial w}\\mathcal{L} =\\dfrac {\\partial }{aw}\\left( c+b^{T}w+w^{T}Aw\\right) \\\\\n",
    "\\Rightarrow \\dfrac {\\partial }{\\partial u}\\left( c\\right) +\\dfrac {\\partial }{\\partial w}\\left( b^{T}w\\right) +\\dfrac {\\partial }{\\partial w}\\left( w^{T}Aw\\right) \n",
    "=0\\\\\n",
    "\\Rightarrow 0+b+\\left( A+A^{T}\\right) w =0\\\\\n",
    "\\Rightarrow -2X^{T}t+\\left\\{ X^{T}X^{T}\\left( X^{T}X\\right)^{T}\\right\\} w\n",
    "=0\\\\\n",
    "\\Rightarrow -2X^{T}t+2X^{T}Xw=0\\\\\n",
    "\\Rightarrow X^{T}Xw=X^{T}t\\\\\n",
    "\\Rightarrow \\left( X^{T}X\\right)^{-1}X^{T}X w =\\left( X^{T}X\\right)^{-1}X^{T}t \\\\\n",
    "Iw=\\left( X^{T}X\\right)^{-1}X^{T}t \\\\\n",
    "w=\\left( X^{T}X\\right)^{-1}X^{T}t\n",
    "\\end{aligned}\n",
    "$$\n",
    "ここで、$I$は単位行列である。このように、最適なパラメータが与えられているデータセット $X, t$ で求まることがわかる。また、式変形の際に気を付ける点として、\n",
    "$$\n",
    "w = \\dfrac{X^{T}t}{X^{T}X}\n",
    "$$\n",
    "のような分数にはならない。これは行列の計算には割り算がないためである。そのため、逆行列を使って行列積のみで計算できるように工夫する。\n",
    "\n",
    "また、もうひとつよくある間違いとして、\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X^{T}Xw&=X^{T}t\\\\\n",
    "\\Rightarrow \\left( X^{T}\\right) ^{-1}X^{T}Xw&=\\left( X^{T}\\right) ^{-1}X^{T}t\\\\\n",
    "\\Rightarrow Xw&=t\\\\\n",
    "\\Rightarrow X^{-1}Xw&=X^{-1}t\\\\\n",
    "\\Rightarrow w&=X^{-1}t\n",
    "\\end{aligned}\n",
    "$$\n",
    "のように式変形できないのかといった意見もある。しかし、これは一般的には成立しない。その理由として、線形代数の章で説明した逆行列を持つための条件として、正方行列であることが満たされないためである。バイアス$b$を$w$に包含することを無視する場合 $X \\in \\mathcal{R}^{N \\times M}$ であり、バイアスの包含を考慮する場合は $X \\in \\mathcal{R}^{N \\times (M+1)}$ である。一般的に、サンプル数$N$と入力変数の数$M$は等しくないため、$X$は正方行列ではなく、逆行列をもたない。それに対し、$X \\in \\mathcal{R}^{N \\times M}$ の場合、$X^{T}X \\in \\mathcal{R}^{M\\times M}$ となり、サンプル数に依存することなく、常に正方行列となるのである。ほかにも逆行列となるためには、さらに厳しい条件等もあるが、これも複雑になりすぎるため、後の章で説明することとする。\n",
    "\n",
    "推論の際は学習で得られたパラメータ$w$を用いて、\n",
    "$$\n",
    "y = w^{T}x\n",
    "$$\n",
    "のように計算すれば良い。\n",
    "\n",
    "\n",
    "\n",
    "## Numpyによる実装\n",
    "\n",
    "それでは、重回帰分析の実装を行おう。PythonにはNumpyと呼ばれる線形代数を簡単に扱えるライブラリが存在し、これを使うことが標準となっている。次の章で紹介するChainerの中でもNumpyは多用されている。\n",
    "\n",
    "Pythonの文法に関しては把握していることを前提に進めている。具体的には、変数（数値・文字列、リスト、タプル、辞書）、制御構文（for、if）、関数、クラスを理解している必要がある。\n",
    "\n",
    "重回帰分析では、最終的に最適なパラメータ $w$ が\n",
    "\n",
    "$$\n",
    "w=\\left( X^{T}X\\right)^{-1}X^{T}t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "で求まる。この最適なパラメータを求めるためには、以下の5つを扱える必要がある。\n",
    "\n",
    "- ベクトルの定義\n",
    "- 行列の定義\n",
    "- 転置\n",
    "- 行列積\n",
    "- 逆行列\n",
    "\n",
    "具体的に、以下のようなデータセットが与えられているケースを想定してみましょう。\n",
    "\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "1 & 2 & 5 \\\\\n",
    "1 & 3 & 4 \\\\  \n",
    "1 & 5 & 9 \n",
    "\\end{bmatrix}, \\\n",
    "t = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 5 \\\\ 6 \\\\ 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "それぞれの実装について、見ていきましょう。まずは、Numpyの読み込みから始めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベクトルの定義は以下のように行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([[1], [5], [6], [8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [5]\n",
      " [6]\n",
      " [8]]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つぎに、行列の定義も行いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 5],\n",
    "    [1, 3, 4],\n",
    "    [1, 5, 9]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 5]\n",
      " [1 3 4]\n",
      " [1 5 9]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それで、Xの転置を行おう。Numpyの`array`で定義されている場合、`.T`をつけるだけで転置ができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [2 2 3 5]\n",
      " [3 5 4 9]]\n"
     ]
    }
   ],
   "source": [
    "print(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "縦と横が入れ替わっていることを確認できた。\n",
    "\n",
    "次に、行列積は以下のように `np.dot` によって実現できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.dot(X.T, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4  12  21]\n",
      " [ 12  42  73]\n",
      " [ 21  73 131]]\n"
     ]
    }
   ],
   "source": [
    "print(XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つぎに、この逆行列を求めるには、`np.linalg.inv` を用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_inv = np.linalg.inv(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76530612 -0.39795918 -0.06122449]\n",
      " [-0.39795918  0.84693878 -0.40816327]\n",
      " [-0.06122449 -0.40816327  0.24489796]]\n"
     ]
    }
   ],
   "source": [
    "print(XX_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで重回帰分析のために必要な演算がそろった。最適なパラメータを求めると、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.dot(X.T, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20]\n",
      " [ 70]\n",
      " [124]]\n"
     ]
    }
   ],
   "source": [
    "print(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.dot(XX_inv, Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14285714]\n",
      " [ 0.71428571]\n",
      " [ 0.57142857]]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように求まる。Numpyを使うことで、数式とプログラミングの間にあったギャップを簡単に埋めることができるのである。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learnによる本格的な実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重回帰分析であればNumpyで簡単に実装することができたが、本格的に使用していくアルゴリズムは複雑なことが多く、初学者が一から書くには難しいことが多い。PythonではScikit-learnと呼ばれる機械学習用のフレームワークが公開されており、初学者でも簡単に扱うことができる。\n",
    "\n",
    "まずは重回帰分析をScikit-learnによって実装してみよう。\n",
    "\n",
    "### Scikit-learn基礎編\n",
    "\n",
    "Scikit-learnは`sklearn`という名前で呼び出すことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "たとえば、重回帰分析を使用する場合は以下のように呼び出す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは[公式のリファレンス](http://scikit-learn.org/)を見ながらどこに格納されているか調べても良いが、「重回帰分析 Scikit-learn」と検索して、実例のソースコードを見るほうが早い場合が多い。\n",
    "\n",
    "アルゴリズムがクラスとして定義されており、まずはインスタンス化を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この一行で重回帰分析を使用するための準備が完了である。そして、パラメータの学習も以下のように行える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後にどのような結果が得られたかの検証も一行で行える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076926"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回帰では**決定係数**と呼ばれる指標で、分類の場合は**精度**が自動的に計算されるようになっている。\n",
    "このように、非常に簡単なインターフェースでやり取りができるようになっている。Scikit-learnの良い点は最初にアルゴリズムを決めてしまえば、一からの実装が難しいアルゴリズムでも、`.fit`で学習、`.score`で検証が行える点である。\n",
    "\n",
    "また、アルゴリズムによって内容は多少異なるが、パラメータもインスタンス変数として格納されているため、学習後に確認することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.71428571, 0.57142857]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パラメータw\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14285714])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# バイアスb\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この例からわかるように、Scikit-learnでは、パラメータとバイアスがそれぞれ準備されているため、入力変数$X$の左端の列に1を格納した変数を入れる必要がない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn応用編\n",
    "\n",
    "Scikit-learnは機械学習の実装を支援する多くの機能を兼ね備えており、基礎編では紹介していなかったが、実務では必ず使う機能を紹介する。\n",
    "\n",
    "まず最初にサンプルのデータセットの取り扱いを紹介する。Scikit-learnには学び始めでテストするために、データセットがいくつか提供されている。今回は、この提供されているデータセットで話を進めていく。今回は`load_boston`というボストン近郊の家賃に関するデータセットである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数の`boston`には辞書と同じ形式で格納されており、変数の中身を見ながら入力変数と教師データに対応するものを見つけていく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston['data']\n",
    "t = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpyの形式で入力変数と教師データが格納されており、`.shape`を使うことで行と列の数を確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つぎに、訓練データと検証データの分割である。先ほどは、すべてのデータを訓練に使って、すべてのデータを検証に使った。しかし、応用を考えた場合、これで良いだろうか。たとえば、受験勉強のために10年分の過去問を購入した場合、10年分を使って勉強して、実力試し用にまた同じ10年分を使うだろうか。そうではなく、例えば7年分を勉強用に使って、残りの3年分を実力試し用に置いておくはずである。機械学習もこの考え方と全く同じで、勉強用を訓練データ、実力試しを検証データとして分けて用いる。このように分割して検証することを**ホールドアウト法**という。\n",
    "\n",
    "Scikit-learnではもちろんこの訓練用と検証用を分割する機能が準備されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 13)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 13)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数の`test_size`は検証用に使うデータの比率であり、0.3と指定すると全体の30%が検証データとなる。また、`random_state`は乱数のシードであり、再現性を確保するためのものである。なぜ乱数が登場するかというと、前から70%を訓練用、残りを検証用とするのではなく、全体からランダムに選択した70%を訓練用、残り30%を検証用と並びにかかわらず選択できるようになっているためである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして、パラメータの学習には訓練データを用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "検証を行う場合は、訓練データと検証データの両方に対してチェックしておくと良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7644563391821222"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データ\n",
    "model.score(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673528086534723"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証データ\n",
    "model.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "検証データだけでなく、訓練データでも検証することに意味はある。\n",
    "実務を行うときには、以下のような結果のどれかが得られる。\n",
    "\n",
    "|訓練データ|検証データ|結果|\n",
    "|:--|:--|:--|\n",
    "|×|×|アンダーフィッティング|\n",
    "|〇|×|オーバーフィッティング|\n",
    "|〇|〇|ＯＫ|\n",
    "\n",
    "訓練データに対して悪く、検証データで良好な結果が得られている場合はたまたまであり、再現性が低いため考えていない。\n",
    "\n",
    "**アンダーフィッティング**の場合は、現状の機械学習アルゴリズムでうまくデータの特徴を捉えられていないと考えられ、アルゴリズムを変更したり、入力となるデータの特徴を表せるような変換を考える。逆に**オーバーフィッティング**の時は、そのアルゴリズムで特徴を捉えられていることはわかっているため、**ハイパーパラメータ**と呼ばれる各アルゴリズムに固有の値を調整していくことで解決できることがある。このハイパーパラメータの調整は後述するが、望ましい結果が得られない中にも、それぞれの状況を把握し、次に打つべき対策が変わってくるため、訓練データと検証データの両方に対する検証を行うことは重要である。\n",
    "\n",
    "また、Scikit-learnでは、スケーリングも行うことができる。例えば、平均0、標準偏差1に変換するデータの正規化を行う場合は以下のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インスタンス化\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平均の分散（標準偏差）を学習\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変換\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.20416267 -0.49997924  1.54801583 ...  1.2272573   0.42454294\n",
      "   3.10807269]\n",
      " [-0.38584317  0.34677427 -0.58974728 ...  0.05696346  0.40185312\n",
      "  -0.66643035]\n",
      " [-0.33266283 -0.49997924  1.54801583 ...  1.2272573   0.39846135\n",
      "   0.63936662]\n",
      " ...\n",
      " [-0.38147768 -0.49997924 -0.15303077 ... -0.30312696  0.39659002\n",
      "  -0.30284441]\n",
      " [-0.3720831  -0.49997924 -0.59690657 ... -0.25811566  0.37588849\n",
      "   0.89967717]\n",
      " [-0.38289844 -0.49997924 -1.00641779 ... -0.84326258  0.42454294\n",
      "   0.31822262]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39152624 -0.49997924 -1.12239824 ... -0.70822867  0.17086147\n",
      "  -0.72160487]\n",
      " [ 0.70825498 -0.49997924  1.00534187 ...  0.77714428  0.0648977\n",
      "  -0.41177872]\n",
      " [-0.38588517 -0.49997924  0.4025299  ... -0.93328518  0.38758427\n",
      "  -0.27454978]\n",
      " ...\n",
      " [ 1.6177735  -0.49997924  1.00534187 ...  0.77714428  0.42454294\n",
      "   2.59876943]\n",
      " [-0.34043865 -0.49997924 -0.1687812  ... -0.03305915  0.42454294\n",
      "  -1.11772962]\n",
      " [-0.39601293 -0.49997924 -1.27417512 ...  0.10197476  0.39202867\n",
      "  -1.02294263]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実用的な機械学習アルゴリズムの紹介\n",
    "\n",
    "これまでは重回帰分析の紹介にとどまっていたが、ここからは実務でもよく用いられる機械学習アルゴリズムについて特徴とともに紹介していく。数式を詳細に紹介していくと長くなりすぎてしまうため、気になったアルゴリズムがあれば、参考図書を見て学びを深めてほしい。\n",
    "\n",
    "Scikit-learnを使うことによって実装は非常に手軽に行うことができるが、数式を理解していないがゆえに、うまくいかないときの対処法がわからないという問題がある。この問題につまずかないように、実務でチューニングを行うハイパーパラメータとその探索する値の相場も併せて紹介する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "\n",
    "SVMは実用的によく使われる手法の一つであり、入出力間の非線形性も捉えることができる。$y=x^2$ や $y = \\sin(x)$ のように、$y=wx + b$ の直線ではないモデル化を行うことができる。ただし、非線形なモデルの定式化は非常に難しい。なぜなら、$y=wx^2$ が良いのか、$y=w\\sin(x)$ が良いのか、それともその重ね合わせが良いのかと組み合わせの候補が無限に存在するためである。物理現象に基づいて入出力間の関係性が把握できていれば定式化のアイディアも存在するが、そのような事前知識がある場合は多くない。そこで、SVMでは**カーネルトリック**と呼ばれるテクニックを駆使して、入出力間の関係性が非線形な場合の定式化も可能にしている。この数学は非常に興味深いが、難易度が高いため、ある程度機械学習の数学に慣れてから取り組んでほしい。\n",
    "\n",
    "SVMには連続値を予測する**回帰 (Regression)** とカテゴリを予測する**分類 (Classification)** の両方に対応した手法を持っている。それぞれ、Support Vector Regression (SVR) と Support Vector Classification (SVC) と呼ぶ。まずは回帰の問題設定で紹介していき、前回のボストン近郊の家賃の予測の例題を取り扱う。\n",
    "\n",
    "#### Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの準備\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston['data']\n",
    "t = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練と検証データの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのインスタンス化、学習\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR()\n",
    "model.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14680479454958428"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01018093344367077"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように数式は非常に難しいとされるSVRでも、重回帰分析のケースとほとんど同じように実装できる。\n",
    "\n",
    "ここで、結果に着目すると、訓練データに対しても検証データに対しても良い結果が得られているとは言い難い。\n",
    "話題に上がっていたハイパーパラメータを調整すれば良くなるのか、それともSVRではそもそもダメなのかと迷うところである。\n",
    "実はハイパーパラメータの調整の前に、スケーリングを行うことで改善ができることが多い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スケーリング後のデータを使って学習\n",
    "model.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.697669153907031"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5540391127752358"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、大幅に結果を改善することができた。理由は数式を理解しておかないと説明が難しいが、スケーリングの影響を大きく受けるアルゴリズムと受けないアルゴリズムがあり、SVRを含むSVMは影響を受けるアルゴリズムである。\n",
    "\n",
    "最後に、さらに精度を高められないかとハイパーパラメータの調整を行う。ハイパーパラメータの調整を行うときにはひとつ注意すべき点がある。訓練データ（train）はパラメータの調整に用いるが、検証データ（test）を見ながらハイパーパラーメータの調整を行うべきだろうか。検証データはあくまで未知の状態に対する推論能力の検証を行うためのものであるため、ハイパーパラメータの調整に使用してしまうとそれは学習に使ってしまうことになる。\n",
    "\n",
    "そこで、ハイパーパラメータの調整用にバリデーションデータ （val）を追加することが一般的である。\n",
    "\n",
    "![](images/3/01.png)\n",
    "\n",
    "また、このバリデーションデータの追加と一緒に導入されるものとして、**交差検証法（クロスバリデーション）**がある。話の始まりとしては、trainとtestを分けた時点で学習に使えるサンプル数が少なくなってしまっている中、さらにvalも分けると学習に使えるサンプル数がさらに減ってしまう。そうなると、valのサンプル数を少なくしたいが、バリデーションに使うサンプル数が少ないと、たまたまうまくいっているのか、どのサンプルに対してもうまくいくのかがわからなくなる。そこで、下図に示すような交差検証法が用いられる。\n",
    "\n",
    "![](images/3/02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainとvalの分割を1パターンだけでなく、複数パターン分けて行い、その平均をとる方法である。この分割数 $K$ として、K-fold Cross Validation (CV)と呼ばれることが多いため、この名称も覚えてほしい。上記の例だと $K=3$ である。\n",
    "\n",
    "それでは、SVRのハイパーパラメータ調整を交差検証法も使いながら行う。Scikit-learnではハイパーパラメータ調整のための機能も`GridSearchCV`という名前で準備されている。グリッドサーチとは各組合せをすべて試す探索方法である。それ以外の方法として、ランダムサーチとベイズ最適化による探索があるが、ここは余裕がでてきた段階でさらに深める内容のひとつとしてほしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整を行うハイパーパラメータの値の候補\n",
    "param_grid = [\n",
    "    {'C': [1, 10, 100], 'gamma': [0.01, 0.1, 1, 10]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [1, 10, 100], 'gamma': [0.01, 0.1, 1, 10]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交差検証法を使用したハイパーパラメータの各組合せでの学習\n",
    "model_cv = GridSearchCV(SVR(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "model_cv.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交差検証法とハイパーパラメータのグリッドサーチもこれだけで完了である。各ハイパーパラメータでの結果ももちろん確認することができ、最も結果の良かったハイパーパラメータの値を引き継いだモデルの選択もできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryosu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: -40.88957, std: 12.03388, params: {'C': 1, 'gamma': 0.01},\n",
       " mean: -34.94548, std: 12.18057, params: {'C': 1, 'gamma': 0.1},\n",
       " mean: -72.62060, std: 15.99632, params: {'C': 1, 'gamma': 1},\n",
       " mean: -86.25200, std: 16.38372, params: {'C': 1, 'gamma': 10},\n",
       " mean: -17.67763, std: 6.48783, params: {'C': 10, 'gamma': 0.01},\n",
       " mean: -16.46703, std: 7.03969, params: {'C': 10, 'gamma': 0.1},\n",
       " mean: -43.71719, std: 13.22953, params: {'C': 10, 'gamma': 1},\n",
       " mean: -81.13324, std: 15.21847, params: {'C': 10, 'gamma': 10},\n",
       " mean: -13.83363, std: 3.54540, params: {'C': 100, 'gamma': 0.01},\n",
       " mean: -14.61609, std: 7.20850, params: {'C': 100, 'gamma': 0.1},\n",
       " mean: -37.47299, std: 9.87515, params: {'C': 100, 'gamma': 1},\n",
       " mean: -77.95797, std: 12.36436, params: {'C': 100, 'gamma': 10}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果の確認 (valの対する結果)\n",
    "model_cv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最も結果が良かったハイパーパラメータ\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最も結果が良かったハイパーパラメータの値を設定したモデル\n",
    "model = model_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685336670918761"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでがアルゴリズムの調整である。実際には特徴量の選択や外れ値除去など前処理も込みで行うため、ここまでシンプルに完了できるものではないが、まずはこの流れを覚えていただきたい。\n",
    "\n",
    "1. スケーリング無　score:0.010\n",
    "2. スケーリング有　score:0.554\n",
    "3. スケーリング＋ハイパーパラメータの調整有　0.7685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classification (SVC)\n",
    "\n",
    "次に、SVMの分類であるSVCも同様にスケーリングからハイパーパラメータの調整まで行う。分類の例題では、乳がんの患者か否かといったこれもScikit-learn側で準備されているデータセットを使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの準備\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer['data']\n",
    "t = breast_cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記からわかるように、入力変数のスケールは統一されていないことがわかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データと検証データに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スケーリング無で学習\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類では精度 (Accuracy) と呼ばれる指標の結果が得られる。例えば、100問中3問間違えると、Accuracyは0.97となる。\n",
    "\n",
    "次にスケーリングを行った後に学習させる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スケーリング\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スケーリングしたデータを用いて学習\n",
    "model.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824120603015075"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように精度が大幅に高まったことがわかる。最後にハイパーパラメータのチューニングを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整を行うハイパーパラメータの値の候補\n",
    "param_grid = [\n",
    "    {'C': [1, 10, 100], 'gamma': [0.01, 0.1, 1, 10]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [1, 10, 100], 'gamma': [0.01, 0.1, 1, 10]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交差検証法を使用したハイパーパラメータの各組合せでの学習\n",
    "model_cv = GridSearchCV(SVC(), param_grid, cv=3)\n",
    "model_cv.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryosu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.96482, std: 0.01272, params: {'C': 1, 'gamma': 0.01},\n",
       " mean: 0.95226, std: 0.01543, params: {'C': 1, 'gamma': 0.1},\n",
       " mean: 0.62814, std: 0.00310, params: {'C': 1, 'gamma': 1},\n",
       " mean: 0.62563, std: 0.00223, params: {'C': 1, 'gamma': 10},\n",
       " mean: 0.97487, std: 0.01972, params: {'C': 10, 'gamma': 0.01},\n",
       " mean: 0.94472, std: 0.02474, params: {'C': 10, 'gamma': 0.1},\n",
       " mean: 0.63065, std: 0.00132, params: {'C': 10, 'gamma': 1},\n",
       " mean: 0.62563, std: 0.00223, params: {'C': 10, 'gamma': 10},\n",
       " mean: 0.94975, std: 0.01981, params: {'C': 100, 'gamma': 0.01},\n",
       " mean: 0.94472, std: 0.02474, params: {'C': 100, 'gamma': 0.1},\n",
       " mean: 0.63065, std: 0.00132, params: {'C': 100, 'gamma': 1},\n",
       " mean: 0.62563, std: 0.00223, params: {'C': 100, 'gamma': 10}]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果の確認 (valの対する結果)\n",
    "model_cv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最も結果が良かったハイパーパラメータ\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最も結果が良かったハイパーパラメータの値を設定したモデル\n",
    "model = model_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883040935672515"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハイパーパラメータの調整により、多少であるが改善することができた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "つぎに、決定木 (Dicision Tree) のアンサンブル学習であるランダムフォレストを紹介する。こちらも実用上良く使われる手法である。ランダムフォレスト含めた決定木系の手法では入力変数のスケールの違いによる影響はほとんど受けない。また、**カテゴリカル変数**と呼ばれる定量評価を行うことが難しい変数（例えば、男性 or 女性）も定量化を気にすることなく扱うことができるメリットがある。回帰と分類と両方準備されているため、それぞれについて紹介する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回帰 (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの準備\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston['data']\n",
    "t = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練と検証データの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのインスタンス化、学習\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9683509759630142"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8244110898822086"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スケーリング後のデータを使って学習\n",
    "model.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.980773304078463"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7568763837538154"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、スケーリングによる影響はほとんどないことが経験的にもわかる。\n",
    "また、Random Forest含めた決定木系の手法では、まずは条件分岐させる数である `max_depth` をハイパーパラメータとして調整することが多い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整を行うハイパーパラメータの値の候補\n",
    "param_grid = [\n",
    "    {'max_depth': [1, 2, 3, 4, 5, 6]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交差検証法を使用したハイパーパラメータの各組合せでの学習\n",
    "model_cv = GridSearchCV(RandomForestRegressor(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "model_cv.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryosu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: -41.89307, std: 9.40057, params: {'max_depth': 1},\n",
       " mean: -25.95305, std: 8.05238, params: {'max_depth': 2},\n",
       " mean: -23.11041, std: 4.68079, params: {'max_depth': 3},\n",
       " mean: -17.92487, std: 4.42161, params: {'max_depth': 4},\n",
       " mean: -19.30415, std: 7.51230, params: {'max_depth': 5},\n",
       " mean: -17.16534, std: 8.32303, params: {'max_depth': 6}]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果の確認 (valの対する結果)\n",
    "model_cv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最も結果が良かったハイパーパラメータ\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最も結果が良かったハイパーパラメータの値を設定したモデル\n",
    "model = model_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065343207878718"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はもともとオーバーフィッティングしていなかったため、ハイパーパラメータの調整によって改善することはなかったが、もちろんオーバーフィッティングしているケースには有効な施策である。\n",
    "\n",
    "またランダムフォレストを含めた決定木系の手法の大きなメリットとして、各入力変数がどの程度重要であるかを定量評価した値が得られる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03498355, 0.00122218, 0.00721576, 0.00092089, 0.00898805,\n",
       "       0.39898526, 0.01894469, 0.04598164, 0.00571163, 0.01607173,\n",
       "       0.01889314, 0.00701622, 0.43506524])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各入力変数の重要度\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重要度の総和が1になっており、この値を使って考察したり説明できるため、実務でよく見るポイントの一つである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分類 (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの準備\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer['data']\n",
    "t = breast_cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練と検証データの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのインスタンス化、学習\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949748743718593"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415204678362573"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スケーリング後のデータを使って学習\n",
    "model.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整を行うハイパーパラメータの値の候補\n",
    "param_grid = [\n",
    "    {'max_depth': [1, 2, 3, 4, 5, 6]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交差検証法を使用したハイパーパラメータの各組合せでの学習\n",
    "model_cv = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
    "model_cv.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryosu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.91206, std: 0.01259, params: {'max_depth': 1},\n",
       " mean: 0.93467, std: 0.01763, params: {'max_depth': 2},\n",
       " mean: 0.93467, std: 0.01265, params: {'max_depth': 3},\n",
       " mean: 0.95226, std: 0.01543, params: {'max_depth': 4},\n",
       " mean: 0.93970, std: 0.02119, params: {'max_depth': 5},\n",
       " mean: 0.93970, std: 0.01632, params: {'max_depth': 6}]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果の確認 (valの対する結果)\n",
    "model_cv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最も結果が良かったハイパーパラメータ\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最も結果が良かったハイパーパラメータの値を設定したモデル\n",
    "model = model_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.55728165e-03, 4.80674523e-03, 7.04751333e-02, 6.67175039e-02,\n",
       "       0.00000000e+00, 6.38391868e-03, 1.44783793e-01, 2.56851226e-02,\n",
       "       1.01592678e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.17633429e-03, 3.57428435e-02, 5.48903143e-05, 7.63635594e-03,\n",
       "       8.65354259e-03, 3.50041088e-03, 4.29368206e-03, 4.42019691e-03,\n",
       "       8.32478506e-02, 1.93259510e-02, 1.79759936e-01, 8.96864960e-02,\n",
       "       4.76915506e-03, 2.20744844e-02, 6.78042092e-02, 1.24987366e-01,\n",
       "       4.10480850e-03, 8.33606129e-03])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各入力変数の重要度\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ロジスティック回帰\n",
    "\n",
    "シンプルであるが良く使われる手法のひとつである。回帰という名前がついているが、問題設定としては分類に使用する点に注意されたい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの準備\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer['data']\n",
    "t = breast_cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練と検証データの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのインスタンス化、学習\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957286432160804"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スケーリング後のデータを使って学習\n",
    "model.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9899497487437185"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（訓練データ）\n",
    "model.score(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整を行うハイパーパラメータの値の候補\n",
    "param_grid = [\n",
    "    {'C': [0.01, 0.1, 1, 10]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.01, 0.1, 1, 10]}], pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交差検証法を使用したハイパーパラメータの各組合せでの学習\n",
    "model_cv = GridSearchCV(LogisticRegression(), param_grid, cv=3)\n",
    "model_cv.fit(X_train_s, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryosu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.96985, std: 0.01223, params: {'C': 0.01},\n",
       " mean: 0.97990, std: 0.00935, params: {'C': 0.1},\n",
       " mean: 0.98492, std: 0.01624, params: {'C': 1},\n",
       " mean: 0.97236, std: 0.02323, params: {'C': 10}]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果の確認 (valの対する結果)\n",
    "model_cv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最も結果が良かったハイパーパラメータ\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最も結果が良かったハイパーパラメータの値を設定したモデル\n",
    "model = model_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証（検証データ）\n",
    "model.score(X_test_s, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰の特徴は推論の時に出てくる。これまでの分類の手法であれば、新しいサンプルが得られた際の予測値は0か1かのカテゴリの値が得られる。Scikit-learnでは推論には`predict`を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データの一番最初のサンプルで試しに推論\n",
    "x_pred = [X_train_s[0]]\n",
    "y = model.predict(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この結果はどの手法でも同じであるが、ロジスティック回帰を含めた**識別モデル**系の手法では、各カテゴリに属する確率まで求めることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict_proba(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00160119 0.99839881]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "総和が1となっており、確率が大きいほうのカテゴリ1が選ばれたことがわかる。異常か異常でないかといった分類の場合、異常or異常でないだけでなく、どのくらい異常そうであるかの確率までわかることで、閾値を設けやすくなる。この特性は次の章で紹介するニューラルネットワークでも同じである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means\n",
    "\n",
    "最後は教師なし学習である**クラスタリング**の手法として有名なk-meansを紹介する。分類では教師データとしてどのカテゴリに属しているかがわかっていたが、クラスタリングではその教師データがない状況で学習を行う。基本的には距離的に近いものをまとめる。\n",
    "\n",
    "例題では2つのクラスターをあらかじめ用意しておき、正しく分けられるかを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.randn(50, 2) - 3\n",
    "X2 = np.random.randn(50, 2) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合\n",
    "X = np.r_[X1, X2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x28640957438>"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、k-meansを用いてクラスタリングを行う。クラスタリングでは基本的にはわけるクラスターの数がハイパーパラメータとして必要である。`n_clusters`で指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans(n_clusters=2)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測した結果をもとにクラスタリングを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpyをうまく使うと、条件に当てはまるサンプルだけを抽出できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = X[y==0]\n",
    "X1 = X[y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x28640b6c8d0>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X0[:, 0], X0[:, 1], color='red')\n",
    "plt.scatter(X1[:, 0], X1[:,1 ], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
