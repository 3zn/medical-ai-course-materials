{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basenji",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yoiTUC_zXAb9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[![colab-logo](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/japan-medical-ai/medical-ai-course-materials/blob/master/notebooks/Basenji.ipynb)\n",
        "\n",
        "# 実践編：ディープラーニングを使った配列解析\n",
        "\n",
        "近年，次世代シーケンサ（NGS; Next Generation Sequencer）の発展により，遺伝子の塩基配列を高速，大量，安価に読み取ることができるようになってきました．\n",
        "\n",
        "ここではディープラーニングを用いて，DNA配列からエピジェネティックな影響や転写制御を予測する問題に取り組みます．この予測モデルを使うことで，ある遺伝子変異が遺伝子発現にどのような影響を与えるのかを予測することができるようになります．\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CkqRZHc8crS4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 環境\n",
        "\n",
        "ここで用いるライブラリは\n",
        "\n",
        "\n",
        "*  Chainer\n",
        "*  Cupy\n",
        "*  matplotlib\n",
        "\n",
        "です．Google Colab上では，以下のようにしてインストールすることができます．以下のセルを実行（Shit+Enter）してください．\n"
      ]
    },
    {
      "metadata": {
        "id": "muhQoVk7c9y1",
        "colab_type": "code",
        "outputId": "e8ee1f96-f8d9-4b7e-a793-0d6199a4d720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "!set -ex\n",
        "!apt -y -q install cuda-libraries-dev-9-2\n",
        "!pip install cupy-cuda92 --pre\n",
        "!pip install chainer --pre"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  cuda-cublas-dev-9-2 cuda-cufft-dev-9-2 cuda-curand-dev-9-2\n",
            "  cuda-cusolver-dev-9-2 cuda-cusparse-dev-9-2 cuda-npp-dev-9-2\n",
            "  cuda-nvgraph-dev-9-2 cuda-nvrtc-dev-9-2\n",
            "The following NEW packages will be installed:\n",
            "  cuda-cublas-dev-9-2 cuda-cufft-dev-9-2 cuda-curand-dev-9-2\n",
            "  cuda-cusolver-dev-9-2 cuda-cusparse-dev-9-2 cuda-libraries-dev-9-2\n",
            "  cuda-npp-dev-9-2 cuda-nvgraph-dev-9-2 cuda-nvrtc-dev-9-2\n",
            "0 upgraded, 9 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 332 MB of archives.\n",
            "After this operation, 972 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cublas-dev-9-2 9.2.148.1-1 [50.4 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cufft-dev-9-2 9.2.148-1 [106 MB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-curand-dev-9-2 9.2.148-1 [57.8 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cusolver-dev-9-2 9.2.148-1 [8,184 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cusparse-dev-9-2 9.2.148-1 [27.8 MB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-nvrtc-dev-9-2 9.2.148-1 [9,348 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-nvgraph-dev-9-2 9.2.148-1 [30.1 MB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-npp-dev-9-2 9.2.148-1 [52.0 MB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-libraries-dev-9-2 9.2.148-1 [2,598 B]\n",
            "Fetched 332 MB in 7s (47.0 MB/s)\n",
            "Selecting previously unselected package cuda-cublas-dev-9-2.\n",
            "(Reading database ... 22280 files and directories currently installed.)\n",
            "Preparing to unpack .../0-cuda-cublas-dev-9-2_9.2.148.1-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-dev-9-2 (9.2.148.1-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-9-2.\n",
            "Preparing to unpack .../1-cuda-cufft-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-9-2.\n",
            "Preparing to unpack .../2-cuda-curand-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-9-2.\n",
            "Preparing to unpack .../3-cuda-cusolver-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-9-2.\n",
            "Preparing to unpack .../4-cuda-cusparse-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-9-2.\n",
            "Preparing to unpack .../5-cuda-nvrtc-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-9-2.\n",
            "Preparing to unpack .../6-cuda-nvgraph-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-9-2.\n",
            "Preparing to unpack .../7-cuda-npp-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-9-2 (9.2.148-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-9-2.\n",
            "Preparing to unpack .../8-cuda-libraries-dev-9-2_9.2.148-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-npp-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-curand-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-nvrtc-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cusolver-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cufft-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cusparse-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-cublas-dev-9-2 (9.2.148.1-1) ...\n",
            "Setting up cuda-nvgraph-dev-9-2 (9.2.148-1) ...\n",
            "Setting up cuda-libraries-dev-9-2 (9.2.148-1) ...\n",
            "Collecting cupy-cuda92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/8a/b18c425488fb7ed3a42662767363b822de697f9bcfca19eb3fa980e07817/cupy_cuda92-6.0.0a1-cp27-cp27mu-manylinux1_x86_64.whl (260.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 260.4MB 65kB/s \n",
            "\u001b[?25hCollecting fastrlock>=0.3 (from cupy-cuda92)\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/e6/6d198d91ae20353140563ba32eac2efba236446aa6cf73b2d652d9d9d038/fastrlock-0.4-cp27-cp27mu-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from cupy-cuda92) (1.14.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from cupy-cuda92) (1.11.0)\n",
            "Installing collected packages: fastrlock, cupy-cuda92\n",
            "Successfully installed cupy-cuda92-6.0.0a1 fastrlock-0.4\n",
            "Collecting chainer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/53/970152ecb9684a96950b81323b6511bfcc169b5c3981c2c2611579179955/chainer-6.0.0a1.tar.gz (517kB)\n",
            "\u001b[K    100% |████████████████████████████████| 522kB 7.4MB/s \n",
            "\u001b[?25hCollecting filelock (from chainer)\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/bd/6a87635dba4906ae56377b22f64805b2f00d8cafb26e411caaf3559a5475/filelock-3.0.10.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from chainer) (1.14.6)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from chainer) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from chainer) (1.14.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from chainer) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.0.0->chainer) (40.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mEPaj4MfdEyh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "インストールが完了したら，以下のセルを実行して，各ライブラリのバージョンを確認してください．\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "p4X-dmKrdDhd",
        "colab_type": "code",
        "outputId": "ff0b8aa3-ac61-4233-95e6-451be60781b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import cupy\n",
        "import matplotlib\n",
        "\n",
        "chainer.print_runtime_info()\n",
        "print('matplotlib:', matplotlib.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Platform: Linux-4.14.65+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Chainer: 6.0.0a1\n",
            "NumPy: 1.14.6\n",
            "CuPy:\n",
            "  CuPy Version          : 6.0.0a1\n",
            "  CUDA Root             : /usr/local/cuda\n",
            "  CUDA Build Version    : 9020\n",
            "  CUDA Driver Version   : 9020\n",
            "  CUDA Runtime Version  : 9020\n",
            "  cuDNN Build Version   : 7201\n",
            "  cuDNN Version         : 7201\n",
            "  NCCL Build Version    : 2213\n",
            "iDeep: Not Available\n",
            "('matplotlib:', '2.1.2')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RFQWV3U_dzQP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "MzdDwd7aeYmT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 配列解析について\n",
        "\n",
        "次世代シーケンサの発展・普及とともに，大量の遺伝子配列が読み取られるようになりました．そうした中で，塩基配列で表現された遺伝子型と病気や形態などの表現型との関係を推定するようなGWAS（Genome Wide Association Study; ゲノムワイド関連解析）がされてきましたが，遺伝子変異だけでは全ての表現型の変化を説明できないことがわかってきています．特に，非翻訳領域が遺伝子発現に影響を与え，表現型の変化を生じさせていることが様々な実験結果からわかってきています．遺伝子発現時に周辺領域がどのように影響を与えているのかを調べるために様々な手法が提案されています．（以下図）\n",
        "\n",
        "![代替テキスト](https://www.encodeproject.org/images/c45f4d8c-0340-4fcb-abe3-e4ff0bb919be/@@download/attachment/EncodeDatatypes2013-7.png)[Encode Projectより引用]\n",
        "\n",
        "例えば，ChIP-Seq（クロマチン免疫沈降）は，転写調節因子やそのほかのタンパク質が直接の相互作用を起こすDNAの特定部位を分離し，それらをシーケンシングして同定し，どの程度出現していたかを定量化します．これにより，タンパク質のDNA中の結合部位を正確かつ効率的に同定することができます．\n",
        "\n",
        "このような技術で抽出された配列を学習データとして利用し，DNA配列のみからそこが結合部位かどうかだけでなく，どの程度，出現していたのかというカバレッチ値を推定することで，DNA配列のみから，転写因子，クロマチンアクセシビリティ，ヒストン修飾を予測することができるようになり，様々な遺伝子変異に対する有益な洞察を与えてくれます．\n",
        "\n",
        "一方で，DNA配列中のどの領域がそのような特徴を持つのかを調べるためには非常に遠距離のDNA配列もいる必要があり，これが機械学習による解析を困難としていました．今回紹介する手法はこのような遠距離の関係を捉えるため，10万超の長さのDNA配列を入力として受け取り，128bpごとにその領域がどの程度各手法で発現していたのか，カバレッジ値を予測するタスクを考えます．"
      ]
    },
    {
      "metadata": {
        "id": "db3ngEYHgSmd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## データセット\n",
        "\n",
        "ここでは，データセットとして[FANTOM5](http://fantom.gsc.riken.jp/5/)のCAGEデータセットを利用します．ここでは前処理が既に終わって配列と，各位置ごとの推定カバレッジ値が記録されたデータを利用します．下のセルを実行してデータをダウンロードしてください．（TODO: 公開の場所においてcurlで取得するようにする）\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "LjxWi_2chwkX",
        "colab_type": "code",
        "outputId": "e65288a2-0bec-43cc-9946-e2d3c6263514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-19 10:08:09--  https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5\n",
            "Resolving github.com (github.com)... 140.82.118.3, 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2018-11-19 10:08:09 ERROR 404: Not Found.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ugaOOp_KcYT_",
        "colab_type": "code",
        "outputId": "20b72ecc-5877-4800-8f93-fa9e55e00133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "file_id = \"1lQk10NsD_NRELz5L0v76TngTPZowHlMB\"\n",
        "\n",
        "drive_file = drive.CreateFile({'id': file_id})\n",
        "\n",
        "\n",
        "drive_file.GetContentFile(\"data.h5\")\n",
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 575032\n",
            "-rw-r--r-- 1 root root      2568 Nov 20 03:56 adc.json\n",
            "drwxr-xr-x 2 root root      4096 Nov 16 17:41 sample_data\n",
            "-rw-r--r-- 1 root root 588818546 Nov 20 03:56 seq.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q4E1tMn3inf1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "total 3640080\n",
        "-rw-r--r-- 1 root root       2597 Oct 17 05:38 adc.json\n",
        "-rw-r--r-- 1 root root 3727429632 Oct 17 05:39 data.h5\n",
        "drwxr-xr-x 2 root root       4096 Oct 15 20:47 sample_data\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "l8NsMudgiHBI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "data.h5というファイルが正しくダウンロードされているかを確認してください．\n",
        "\n",
        "data.h5はHDF5形式でデータを格納したファイルです．HDF5ファイルは，ファイルシステムと同様に，階層的にデータを格納することができ，行列やテンソルデータをそれぞれの位置で名前付きで格納することができます．\n",
        "\n",
        "HDF5形式のファイルを操作するためにh5pyというライブラリがあります．h5pyのFile()でファイルを開き，keys()というAPIでその中に含まれているキーを列挙します．取得したキーを使って格納されている各データを参照することができます．\n",
        "\n",
        "テンソルデータはnumpyと同様にshapeという属性でそのサイズを取得することができます．\n",
        "\n",
        "以下のセルを実行して格納されているデータを確認してください．"
      ]
    },
    {
      "metadata": {
        "id": "bBQVPyKxi-uE",
        "colab_type": "code",
        "outputId": "7aeba4fa-53be-4aaa-b229-be81a208f4e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "with h5py.File('data.h5', 'r') as hf:\n",
        "  for key in hf.keys():\n",
        "    print(key, hf[key].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(u'pool_width', ())\n",
            "(u'target_ids', (3,))\n",
            "(u'target_labels', (3,))\n",
            "(u'target_strands', (3,))\n",
            "(u'test_in', (444, 131072, 4))\n",
            "(u'test_out', (444, 1024, 3))\n",
            "(u'test_out_full', (444, 1024, 3))\n",
            "(u'train_in', (6240, 131072, 4))\n",
            "(u'train_out', (6240, 1024, 3))\n",
            "(u'valid_in', (338, 131072, 4))\n",
            "(u'valid_out', (338, 1024, 3))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T7OkqzE-jXlq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "(u'pool_width', ())\n",
        "(u'target_ids', (3,))\n",
        "(u'target_labels', (3,))\n",
        "(u'target_strands', (3,))\n",
        "(u'test_in', (444, 131072, 4))\n",
        "(u'test_out', (444, 1024, 3))\n",
        "(u'test_out_full', (444, 1024, 3))\n",
        "(u'train_in', (6240, 131072, 4))\n",
        "(u'train_out', (6240, 1024, 3))\n",
        "(u'valid_in', (338, 131072, 4))\n",
        "(u'valid_out', (338, 1024, 3))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OjWa9hSxv3Cv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NkAYTB2ZkEXr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "h5py形式のファイルをnumpyデータとして扱うには，コピーする必要があります．以下のコードは'train_in'というキーに対応するテンソルデータをnumpyデータとして読み出し，そのデータを一部を表示します．"
      ]
    },
    {
      "metadata": {
        "id": "7c3LBQGhja4E",
        "colab_type": "code",
        "outputId": "b6de9573-75fe-469c-b119-a642acb53b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "cell_type": "code",
      "source": [
        "with h5py.File('data.h5') as hf:\n",
        "  x = hf['train_in'][:100]\n",
        "  print(x.shape, x.dtype)\n",
        "  print(x[0, 0:10])\n",
        "  y = hf['train_out'][:100]\n",
        "  print(y.shape)\n",
        "  print(y.shape, y.dtype)\n",
        "  print(y[0, 0:10])"
      ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9dB69Y47k-y_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dilated Convolutionを用いた解析\n",
        "\n",
        "### 配列解析の戦略\n",
        "\n",
        "配列データを扱うためには大きく３つの戦略があります．\n",
        "\n",
        "一つ目は，配列中の順序情報は捨てて，配列をその特徴の集合とみなすことです．これはBag of Words（BoW）表現とよびます．このBoW表現は特徴に十分情報が含まれていれば強力な手法ですがDNA配列のような4種類の文字からなる配列やその部分配列だけではその特徴を捉えることは困難です．\n",
        "\n",
        "二つ目は配列中の要素を左から右に順に読み込んでいき計算していく手法です．これはRNNを用いて解析します．このRNNの問題点はその計算が逐次的であり計算量が配列長に比例するという点です．現在の計算機は計算を並列化することで高速化を達成していますがRNNは計算を並列化することが困難です．もう一つの問題は遠距離間の関係を捉えることが難しいという点です．RNNはその計算方式から，計算の途中結果を全て状態ベクトルに格納する必要があります．遠距離間の関係を捉えようとすると，多くの情報を覚えておかなければなりませんが状態ベクトルサイズは有限なので，多くの情報を忘れなければなりません．\n",
        "\n",
        "三つ目は配列データを1次元の画像とみなし，画像処理の時と同様にCNNを用いて解析する手法です．CNNはRNNの場合と違って各位置の処理を独立に実行できるため並列に処理することができます．また，後述するDilated Convolutionを使うことで各位置の処理は遠距離にある情報を直接読み取ることができます．次の章でDilated Convolutionについてさらに詳しくみていきます．\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RWl4yYm_nqg7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dilated Convolution\n",
        "\n",
        "従来の畳み込み層を使って配列解析をする場合を考えてみます．\n",
        "以下の図のようにある位置の入力の情報は各層で隣接する位置からしか読み込まれません．どのくらい離れた位置から情報を取得するかはカーネルサイズによって決定され，カーネルサイズがKの時，Dだけ離れた距離にある情報を取得するためにはD/K層必要となります．今回の問題の場合Dは数百から数万，Kは3や5といった値ですので必要な層数も百から万といった数になってしまい現実的ではありません．"
      ]
    },
    {
      "metadata": {
        "id": "gJ2MdbaHneLk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![convolution](http://musyoku.github.io/images/post/2016-09-17/naive_conv.png)"
      ]
    },
    {
      "metadata": {
        "id": "Gazys1FUoV4m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それに対し，Dilated Convolution（atrous convolutionやconvolution weith holesともよばれます）は読み取る場所をずらしたところからうけとります．例えばDilation=4の場合，4だけ離れた位置から情報を受け取ります．このDilatedを倍々にしていき，カーネルサイズを2とした場合，Dだけ離れた位置の情報を受取るには log_2 D層だけ必要になります．今回のDが数百から数万の場合，10から20層程度あれば済むことになります．\n",
        "\n",
        "今回はこのDilated Convolutionを使うことで遠距離にある情報を考慮できるモデルを作成します．"
      ]
    },
    {
      "metadata": {
        "id": "Vl5f4eonQGU9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![dilated convolution](http://musyoku.github.io/images/post/2016-09-17/dilated_conv.png)"
      ]
    },
    {
      "metadata": {
        "id": "p0bcCznko_wD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ブロック\n",
        "\n",
        "それでは最初に，ネットワークの全体を設計します．\n",
        "このネットワークは二つのブロックから構成されます．\n",
        "\n",
        "１つ目のブロックは長さが2^17から配列を長さが2^10のベクトル列まで圧縮し，128bpにつき1つのベクトルが対応するにします．この圧縮はRootBlockが担当します．\n",
        "\n",
        "二つ目のブロックは遠距離にある情報を考慮して各ベクトルの値を計算する部分を担当します．\n",
        "\n",
        "以下のコードを実行してみましょう．\n"
      ]
    },
    {
      "metadata": {
        "id": "5M6BDmVdpLkE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import cupy as cp\n",
        "\n",
        "\n",
        "default_squeeze_params = [\n",
        "  # out_ch, kernel, pool\n",
        "  [32, 21, 2], #1 128 -> 64\n",
        "  [32, 7, 4], #2 64 -> 16\n",
        "  [48, 7, 4], #3 16 -> 4\n",
        "  [64, 7, 4]  #4 4 -> 1\n",
        "]\n",
        "\n",
        "\n",
        "default_dilated_params = [\n",
        "# out_ch, kernel, dilated\n",
        "  [8, 3, 1],\n",
        "  [8, 3, 2], \n",
        "  [8, 3, 4], \n",
        "  [8, 3, 8], \n",
        "  [8, 3, 16], \n",
        "  [8, 3, 32],\n",
        "  [8, 3, 64]\n",
        "]\n",
        "\n",
        "class Net(chainer.Chain):\n",
        "    \n",
        "  def __init__(self, squeeze_params=default_squeeze_params, dilated_params=default_dilated_params, n_targets=3):\n",
        "    super(Net, self).__init__()\n",
        "    self._n_squeeze = len(squeeze_params)\n",
        "    self._n_dilated = len(dilated_params)\n",
        "    with self.init_scope():\n",
        "      for i, param in enumerate(squeeze_params):\n",
        "        out_ch, kernel, pool = param\n",
        "        setattr(self, \"s_{}\".format(i), SqueezeBlock(out_ch, kernel, pool))\n",
        "      for i, param in enumerate(dilated_params):\n",
        "        out_ch, kernel, dilated = param\n",
        "        setattr(self, \"d_{}\".format(i), DilatedBlock(out_ch, kernel, dilated))\n",
        "      self.l = L.ConvolutionND(1, None, n_targets, 1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # x : (B, X, 4)    \n",
        "    xp = cp.get_array_module(x)\n",
        "    h = xp.transpose(x, (0, 2, 1))\n",
        "    h = h[:, :, :]\n",
        "    h = h.astype(xp.float32)\n",
        "                \n",
        "    for i in range(self._n_squeeze):\n",
        "      h = self[\"s_{}\".format(i)](h)\n",
        "    \n",
        "    hs = [h]\n",
        "    for i in range(self._n_dilated):\n",
        "      h = self[\"d_{}\".format(i)](hs)\n",
        "      hs.append(h)\n",
        "\n",
        "    h = self.l(F.concat(hs))\n",
        "    h = xp.transpose(h, (0, 2, 1))\n",
        "    return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kc3RNwK_qHzS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このネットワークは初期化時の引数としてRootBlockに関するパラメータと，DilatedBlockに関するパラメータを受け取ります．\n",
        "\n",
        "それぞれ，出力チャンネル，カーネルサイズ，プーリングの三つ組からなるリストと，出力チャンネル，カーネルサイズ，dilatedサイズの三つ組からなるリストを受け取ります．"
      ]
    },
    {
      "metadata": {
        "id": "s3T5pRubrlba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次に，ブロックの定義をします．"
      ]
    },
    {
      "metadata": {
        "id": "shOuWcBkrpOE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import cupy as cp\n",
        "\n",
        "class SqueezeBlock(chainer.Chain):  \n",
        "  def __init__(self, out_ch, kernel, pool):\n",
        "    super(SqueezeBlock, self).__init__()\n",
        "    \n",
        "    self.pool = pool\n",
        "    with self.init_scope():\n",
        "        pad = kernel // 2\n",
        "        self.conv = L.ConvolutionND(1, None, out_ch, kernel, pad=pad, nobias=True)\n",
        "        self.bn = L.BatchNormalization(out_ch)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    h = self.conv(x)\n",
        "    h = self.bn(h)\n",
        "    h = F.max_pooling_nd(h, self.pool, self.pool, 0, cover_all=False)\n",
        "    return F.relu(h)\n",
        "\n",
        "class DilatedBlock(chainer.Chain):\n",
        "  def __init__(self, out_ch, kernel, dilate):\n",
        "    super(DilatedBlock, self).__init__()\n",
        "    with self.init_scope():\n",
        "      self.conv = L.ConvolutionND(1, None, out_ch, kernel, pad=dilate, nobias=True, dilate=dilate)\n",
        "      self.bn = L.BatchNormalization(out_ch)\n",
        "      \n",
        "  def forward(self, xs):\n",
        "    h = self.conv(F.concat(xs))\n",
        "    h = self.bn(h)    \n",
        "    return F.relu(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-ZdRuhSq2Rq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは，試しにネットワークを構築して，そこにサンプルデータを流してみましょう．\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DARrKIMurGiH",
        "colab_type": "code",
        "outputId": "7b0d204c-817c-4006-d143-f38274594489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n = Net()\n",
        "size = 131072 # 128 * 1024\n",
        "batchsize = 4\n",
        "x = np.empty((batchsize, size, 4), dtype=np.bool)\n",
        "y = n.forward(x)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 1024, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ydR6gwYCsATQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "(4, 1024, 3)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OyJ8lu_psGlk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここで，もともとB= 4, L=131072, C=4だった配列が計算後はB=4, L=1024, C=3の配列となりました．"
      ]
    },
    {
      "metadata": {
        "id": "vLNgEVh0vjOt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "今回の学習では対数ポアソン損失関数を利用します．これはモデルはポアソン分布の唯一のパラメータである平均を出力し，そのポアソン分布を学習データを使った最尤推定をします．この際，学習対象パラメータ以外は無視しています．性能評価する際には，比較がしやすいように学習パラメータに依存しない項も含めた式を利用しています．"
      ]
    },
    {
      "metadata": {
        "id": "rgQmu0Pgvh0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer.functions as F\n",
        "import math\n",
        "import sklearn\n",
        "\n",
        "def log_poisson_loss(log_x, t):\n",
        "  return F.mean(F.exp(log_x) - t * log_x)\n",
        "  \n",
        "\n",
        "def log_poisson_acc(log_x, t):\n",
        "  xp = cp.get_array_module(t)\n",
        "  t = t.astype(xp.float32)\n",
        "  zeros = xp.zeros_like(t, dtype=t.dtype)\n",
        "  ones = xp.ones_like(t, dtype=t.dtype)\n",
        "  cond = xp.logical_and(t >= zeros, t <= ones)\n",
        "  stirling_approx = t * F.log(t) - t + 0.5 * F.log(2.0 * math.pi * t)\n",
        "  ret = F.exp(log_x) - t * log_x + F.where(cond, zeros, stirling_approx)\n",
        "  return F.mean(ret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9RCVvBw0v9i-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "これで全部準備ができました．残りはchainerのtrainerを改造して学習するだけです．以下のコードを実行してください．30分程度で学習が完了します．"
      ]
    },
    {
      "metadata": {
        "id": "b1_e0bE7wB48",
        "colab_type": "code",
        "outputId": "a9656a46-3dc0-41c6-8dd4-b019f0e1df33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import numpy as np\n",
        "from chainer.training import extensions\n",
        "from chainer import training\n",
        "import h5py\n",
        "\n",
        "ml_h5 = h5py.File('data.h5')\n",
        "print(list(ml_h5.keys()))\n",
        "\n",
        "train_x = ml_h5['train_in']\n",
        "train_y = ml_h5['train_out']\n",
        "\n",
        "valid_x = ml_h5['valid_in']\n",
        "valid_y = ml_h5['valid_out']\n",
        "\n",
        "test_x = ml_h5['test_in']\n",
        "test_y = ml_h5['test_out']\n",
        "\n",
        "train = chainer.datasets.TupleDataset(train_x, train_y)\n",
        "val = chainer.datasets.TupleDataset(valid_x, valid_y)\n",
        "\n",
        "train = train[:len(train)//10]\n",
        "val = val[:len(val)//10]\n",
        "\n",
        "batchsize = 8\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "val_iter = chainer.iterators.SerialIterator(val, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "model = L.Classifier(Net(), lossfun=log_poisson_loss, accfun=log_poisson_acc)\n",
        "\n",
        "\n",
        "optimizer = chainer.optimizers.Adam(alpha=0.002, beta1=0.97, beta2=0.98)\n",
        "optimizer.setup(model)\n",
        "\n",
        "\n",
        "updater = training.updaters.StandardUpdater(\n",
        "  train_iter, optimizer, device=0)\n",
        "\n",
        "epoch = 4\n",
        "out = \"out\"\n",
        "trainer = training.Trainer(updater, (epoch, 'epoch'), out=out)\n",
        "\n",
        "trainer.extend(extensions.Evaluator(val_iter, model, device = 0))\n",
        "trainer.extend(extensions.LogReport())\n",
        "trainer.extend(extensions.snapshot_object(model, 'model_iter_{.updater.iteration}'), trigger=(100, 'iteration'))\n",
        "\n",
        "trainer.extend(extensions.PrintReport(\n",
        "    ['epoch', 'main/loss', 'validation/main/loss', 'main/true_loss', 'validation/main/true_loss', 'elapsed_time']), trigger = (0.1, 'epoch'))\n",
        "\n",
        "trainer.extend(extensions.ProgressBar())\n",
        "     \n",
        "trainer.run()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[u'pool_width', u'target_ids', u'target_labels', u'target_strands', u'test_in', u'test_out', u'test_out_full', u'train_in', u'train_out', u'valid_in', u'valid_out']\n"
        　]
        }
      ]
    },
    {
      "metadata": {
        "id": "raELQ_Rm_74A",
        "colab_type": "code",
        "outputId": "e2facbd7-4988-4e25-88ff-0ec7d330e904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.links as L\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_iter = 300\n",
        "out_dir = 'out'\n",
        "model = L.Classifier(Net(), lossfun=log_poisson_loss, accfun=log_poisson_acc)\n",
        "chainer.serializers.load_npz('{}/model_iter_{}'.format(out_dir, model_iter), model)\n",
        "predictor = model.predictor\n",
        "\n",
        "print(len(test_x))\n",
        "with chainer.no_backprop_mode():\n",
        "  test_y_estimated = predictor(test_x[:1])\n",
        "print(test_y_estimated.shape)  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "444\n",
            "(1, 1024, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MQ3ylNJXIhH3",
        "colab_type": "code",
        "outputId": "00e9723e-0f16-4c11-83cf-7693f9e4e3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1678
        }
      },
      "cell_type": "code",
      "source": [
        "def plot(y):\n",
        "  print(y.shape)\n",
        "  ret = np.reshape(np.transpose(y, (2, 1, 0)), (3, -1))\n",
        "  for i in range(3):\n",
        "    print(ret[i].shape, type(ret[i]))\n",
        "    plt.plot(range(len(ret[i])), ret[i])\n",
        "    \n",
        "plot(test_y_estimated)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1024, 3)\n",
            "((1024,), <type 'numpy.ndarray'>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-a24fdc71649d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y_estimated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-a24fdc71649d>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y_estimated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3259\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3260\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3261\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1777\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1799\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \"\"\"\n\u001b[0;32m-> 1801\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1802\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/lines.pyc\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \"\"\"\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/lines.pyc\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0myconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/cbook/__init__.pyc\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM+QlqTBDXpIK+z9jielfGVNHLAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3ffcfefcd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pmaz68ZrsFOb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}
