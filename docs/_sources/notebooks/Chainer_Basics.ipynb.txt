{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chainer_Basics.ipynb のコピー",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitmul/medical-ai-course-materials/blob/master/notebooks/Chainer_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ar0F7XXRJW2K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "変更テスト\n",
        "\n",
        "# Chainer入門\n",
        "\n",
        "## Chainerとは？\n",
        "\n",
        "![](https://github.com/mitmul/medical-ai-course-materials/blob/master/notebooks/images/3-4/img01.png?raw=1)\n",
        "\n",
        "[Chainer](https://chainer.org/)は、日本企業の[Preferred Networks社](https://www.preferred-networks.jp/ja/)が開発を進めています。\n",
        "ディープラーニング（ニューラルネットワーク）に特化した、Pythonで使用できるフレームワークです。\n",
        "\n",
        "Chainerの魅力は次の２点。\n",
        "\n",
        "- 習得が簡単なインターフェースで作られている\n",
        "- ディープラーニングの開発を論文レベルにカスタマイズする際とても柔軟に対応できる\n",
        "\n",
        "Chainerの大きな特徴である**Define by Run**と呼ばれる仕組みが、GoogleのTensorFlowなど他のフレームワークとの大きな違いです。\n",
        "初心者にとって**学習途中に数値やサイズの確認が出来る**という**デバックの容易さ**がメリットです。\n",
        "\n",
        "Chainerでわからないことがあれば、Slackで質問できます。\n",
        "PFNの開発者へ直接質問できるSlackがあり、[こちらのChainer Slack受付フォーム](https://docs.google.com/forms/d/e/1FAIpQLSfqL9XjnqZUIwLOz4K9Oxm8-Ce246IRP51-vZa7HOrofJT9rA/viewform)からメールアドレスを登録して、Slackに招待してもらいましょう。"
      ]
    },
    {
      "metadata": {
        "id": "zsLG_rTgJW2N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Chainerの基礎\n",
        "\n",
        "### Chainerの読み込み\n",
        "\n",
        "Chainerの読み込みは、Pythonの他のモジュールと全く同じです。"
      ]
    },
    {
      "metadata": {
        "id": "Tq00TUItJW2O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WapuwbgoJW2T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "使用しているChainerのバージョンも確認しておきましょう。"
      ]
    },
    {
      "metadata": {
        "id": "3_qpMg6oJW2U",
        "colab_type": "code",
        "outputId": "1aeacad3-c6f2-49d5-f599-2c714efaa610",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chainer.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "HISir1zDJW2b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2018年11月時点で最新版がChainerのバージョンが5系となっています。"
      ]
    },
    {
      "metadata": {
        "id": "rvaoPMx5JW2b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### リンクの定義"
      ]
    },
    {
      "metadata": {
        "id": "ePqzARxoJW2c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "数学においてもプログラミングにおいても、全結合層（fully-connected layer）では、2層で1セットとして扱います。\n",
        "まずは、３ノードの入力層と２ノードの出力層の部分を表現していきましょう。\n",
        "\n",
        "![](https://github.com/mitmul/medical-ai-course-materials/blob/master/notebooks/images/3-4/img02.png?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "PAURIIpZJW2d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer.links as L"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ny89YkCIJW2j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3 → 2 のリンクを`fc`（fully-connected layerの略）として、以下のように宣言します。"
      ]
    },
    {
      "metadata": {
        "id": "DAqRTBk-JW2l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fc = L.Linear(3, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "URq4w2NuJW2o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "これだけで完了です。\n",
        "`L.Linear`は、みなさんが勉強された重回帰分析の**線形結合**という意味です。\n",
        "\n",
        "宣言したリンクの**重み（W）**と**バイアス（b）**はランダムに初期化されています。"
      ]
    },
    {
      "metadata": {
        "id": "DzOWbGOqJW2p",
        "colab_type": "code",
        "outputId": "ce949461-31a0-4ce4-b17c-27d66a2fc8a6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fc.W"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable W([[-1.4219915 ,  0.40851608,  0.13933963],\n",
              "            [-0.11678611,  0.13321629,  1.0833248 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "OvHwtpN8JW2u",
        "colab_type": "code",
        "outputId": "8c27b31f-70eb-4b3c-b565-0af54366d4dc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fc.b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable b([0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Wg3tRoV0JW2x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このパラメータを最適化の初期値に使用します。"
      ]
    },
    {
      "metadata": {
        "id": "p48f01_NJW2y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 乱数のシードを固定して再現性を確保\n",
        "\n",
        "ここで１つ問題があります。\n",
        "重みやバイアスのパラメータの値がランダムに初期化されるため、実行する毎に結果が異なってしまうことです。\n",
        "これでは、今日と明日でも結果が異なり、チーム間でも結果が異なってしまいます。\n",
        "\n",
        "そこで、**乱数のシードを固定**するという方法を使います。\n",
        "これにより**再現性の確保**ができます。\n",
        "\n",
        "実際に、乱数のシードを固定してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "zB2-2PbIJW2z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ehXvdopaJW22",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ONAyuxqKJW25",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Chainerは**Numpy**と呼ばれる数値計算用のライブラリをベースに作られているため、Numpy上で乱数のシードを固定することにより、**再現性の確保**を実現できます。\n",
        "\n",
        "※GPUを使用する場合は、Numpyではなく**Cupy**をベースに計算しているため、Cupyで乱数のシードを固定する必要があります。\n",
        "\n",
        "乱数のシードを固定した後で重みを確認してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "hF6enRKJJW26",
        "colab_type": "code",
        "outputId": "385c7c27-96d2-45e8-ed1c-ae1a0d6bf66f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fc.W"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable W([[-1.4219915 ,  0.40851608,  0.13933963],\n",
              "            [-0.11678611,  0.13321629,  1.0833248 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "UrXspDBoJW2_",
        "colab_type": "code",
        "outputId": "5cb03662-71a9-476e-c22e-21852ea559d6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fc.b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable b([0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "1d6UtmLxJW3B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "この値と同じになっていれば、乱数のシードがうまく固定できていることがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "MC4mpxEFJW3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 線形変換の値を計算しよう\n",
        "\n",
        "手計算で練習した、uの値を計算してみましょう。\n",
        "uの値は`chainer.links.Linear`の中に準備されているため、以下のようにNumpyの形式で渡すことで計算が完了します。"
      ]
    },
    {
      "metadata": {
        "id": "bdS-0RKLJW3D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2, 3]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pWg5Z-l8JW3G",
        "colab_type": "code",
        "outputId": "01978502-cd61-4a00-f314-7319eb32f3c8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "u = fc(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidType",
          "evalue": "\nInvalid operation is performed in: LinearFunction (Forward)\n\nExpect: x.dtype.kind == f\nActual: i != f",
          "traceback": [
            "\u001b[1;31m-----------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidType\u001b[0m               Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-12-d2620a228d16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\link.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforward\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mforward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;31m# Call forward_postprocess hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\links\\connection\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, n_batch_axes)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0min_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_batch_axes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_batch_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\functions\\connection\\linear.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(x, W, b, n_batch_axes)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_batch_axes\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\function_node.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data_type_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mhooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_function_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\function_node.py\u001b[0m in \u001b[0;36m_check_data_type_forward\u001b[1;34m(self, in_data)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0min_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in_types'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_function_check_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_type_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_type_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\functions\\connection\\linear.py\u001b[0m in \u001b[0;36mcheck_type_forward\u001b[1;34m(self, in_types)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mx_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mw_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mx_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mw_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         )\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\utils\\type_check.py\u001b[0m in \u001b[0;36mexpect\u001b[1;34m(*bool_exprs)\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mexpr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbool_exprs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTestable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m             \u001b[0mexpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\utils\\type_check.py\u001b[0m in \u001b[0;36mexpect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    481\u001b[0m             raise InvalidType(\n\u001b[0;32m    482\u001b[0m                 \u001b[1;34m'{0} {1} {2}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m                 '{0} {1} {2}'.format(left, self.inv, right))\n\u001b[0m\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInvalidType\u001b[0m: \nInvalid operation is performed in: LinearFunction (Forward)\n\nExpect: x.dtype.kind == f\nActual: i != f"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jR0ZnJ7ZJW3M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "本来であれば、このように計算できます。\n",
        "これは`chainer.links.Linear`というクラスの`call`関数を呼び出しているわけです。\n",
        "これで計算ができることを、今は覚えておいてください。\n",
        "\n",
        "しかし、多くの方はこれでエラーが起きます。\n",
        "エラーの原因は一番下に書いてあるため、まずは原因の確認を行いましょう。\n",
        "\n",
        "Chainerが初めての方には、非常にわかりにくく、一番最初に悩むエラーです。\n",
        "これは「int型（i）ではなく、float型（f）で宣言しないといけない」という内容を示しています。\n",
        "\n",
        "そこで、入力するデータをfloat型で宣言して使用しましょう。"
      ]
    },
    {
      "metadata": {
        "id": "0STHa6ExJW3N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.array([[1,2,3]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BIwLIDmsJW3S",
        "colab_type": "code",
        "outputId": "e0546a8d-c5ce-41cb-80a4-7b90bfe9e9e0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "1tSBejAhJW3V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Numpyでのデータ型は `.dtype` で確認を行うことができます。\n",
        "初期状態だと整数を扱うint型の32bitで定義されていることがわかります。\n",
        "\n",
        "こちらをfloat型で定義しなおしましょう。"
      ]
    },
    {
      "metadata": {
        "id": "rSatRnRPJW3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.array([[1,2,3]], dtype=np.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2lGhbKkJW3Z",
        "colab_type": "code",
        "outputId": "087e9ded-06de-4b80-feb8-67b26aa01421",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "YyQtRxG4JW3c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは計算しなおしてみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "lIM1fxWPJW3c",
        "colab_type": "code",
        "outputId": "29cd35be-cc57-4fb5-ce48-46c6c01fc584",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "u = fc(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidType",
          "evalue": "\nInvalid operation is performed in: LinearFunction (Forward)\n\nExpect: b.dtype == x.dtype\nActual: float32 != float64",
          "traceback": [
            "\u001b[1;31m-----------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidType\u001b[0m               Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-17-d2620a228d16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\link.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforward\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mforward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;31m# Call forward_postprocess hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\links\\connection\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, n_batch_axes)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0min_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_batch_axes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_batch_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\functions\\connection\\linear.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(x, W, b, n_batch_axes)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_batch_axes\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\function_node.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data_type_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mhooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_function_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\function_node.py\u001b[0m in \u001b[0;36m_check_data_type_forward\u001b[1;34m(self, in_data)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0min_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in_types'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_function_check_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_type_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_type_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\functions\\connection\\linear.py\u001b[0m in \u001b[0;36mcheck_type_forward\u001b[1;34m(self, in_types)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mb_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mx_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mb_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mb_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mw_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             )\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\utils\\type_check.py\u001b[0m in \u001b[0;36mexpect\u001b[1;34m(*bool_exprs)\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mexpr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbool_exprs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTestable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m             \u001b[0mexpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\chainer\\utils\\type_check.py\u001b[0m in \u001b[0;36mexpect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    481\u001b[0m             raise InvalidType(\n\u001b[0;32m    482\u001b[0m                 \u001b[1;34m'{0} {1} {2}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m                 '{0} {1} {2}'.format(left, self.inv, right))\n\u001b[0m\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInvalidType\u001b[0m: \nInvalid operation is performed in: LinearFunction (Forward)\n\nExpect: b.dtype == x.dtype\nActual: float32 != float64"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "W1xGW3GWJW3f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "しかし、float型に変換しても、またエラーが起きてしまいました。\n",
        "今度のエラーの内容としては、`float64`ではなく、`float32`が望まれると記載されています。\n",
        "\n",
        "Chainerではデフォルトで32bitを扱うことになっているため、覚えておきましょう。"
      ]
    },
    {
      "metadata": {
        "id": "unWQYPf7JW3f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2, 3]], dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ISsCqXBWJW3h",
        "colab_type": "code",
        "outputId": "cf397a88-610a-4491-ea57-088c32e15948",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "ghOWuq5MJW3m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "また、Chainerのサンプルコードにも出てくるのですが、以下のように省略形で記述することができます。"
      ]
    },
    {
      "metadata": {
        "id": "qgcA02UaJW3o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2, 3]], 'f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "94JN6aNdJW3r",
        "colab_type": "code",
        "outputId": "90eac964-9641-44d3-c77a-5195b21a6e0f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "INCOhg3kJW3u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "これで線形変換を計算してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "m08_lb8LJW3v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "u = fc(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQ44eVFEJW3y",
        "colab_type": "code",
        "outputId": "21fb8b15-3992-48fa-bb3a-0b94dec32650",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "u"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable([[-0.18694043,  3.3996208 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "z6wYsLyFJW32",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 非線形変換の計算\n",
        "\n",
        "先ほど勉強した活性化関数として、**Relu関数**をかける場合は以下のように記述します。\n",
        "chainerで使用する関数は全てfunctionsにあります"
      ]
    },
    {
      "metadata": {
        "id": "6jUDvFd3JW33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer.functions as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QmdH85u-JW35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = F.relu(u)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JXB_l9FFJW37",
        "colab_type": "code",
        "outputId": "8dc0008a-ea71-4c0f-95f8-45cb49576412",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable([[0.       , 3.3996208]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "UudIcRDBJW3-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このように、正の値はそのままで負の値は0となるRelu関数が、正しく適用できていることがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "ffbkhH3aJW3_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 実践課題\n",
        "\n",
        "#### 問題設定\n",
        "\n",
        "先の知見を活かし、手書きのノートで紹介した「3 → 2 → 1」のニューラルネットワークにおいて、入力`[1, 2, 3]`に対する出力`y`の値を計算してください。\n",
        "\n",
        "以下の構成で計算してみましょう。\n",
        "\n",
        "*   左側のリンク：fc1 → (3, 2)\n",
        "*   右側のリンク：fc2 → (2, 1)\n",
        "*   fc1の線形変換 → u1\n",
        "*   fc1の非線形変換（Relu）→ z1\n",
        "*   fc2の線形変換 → 出力y\n",
        "\n",
        "なお、計算する前に**シードの固定**（`np.random.seed(3)`）を忘れないようにしてください。\n",
        "\n",
        "#### 解答"
      ]
    },
    {
      "metadata": {
        "id": "grlehwjwJW3_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#シードの固定\n",
        "np.random.seed(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IxwW2BjoJW4B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# リンクの宣言\n",
        "fc1 = L.Linear(3, 2)\n",
        "fc2 = L.Linear(2, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GDnyFeJwJW4D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 入力変数\n",
        "x = np.array([[1, 2, 3]], 'f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0mEOsIOsJW4F",
        "colab_type": "code",
        "outputId": "04249fe4-b175-4739-e0d1-d6d94892db8a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "u1 = fc1(x)\n",
        "u1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable([[ 1.7038419, -2.010649 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "DBaKU2HDJW4J",
        "colab_type": "code",
        "outputId": "e9d10a60-eff4-4f07-a49b-7eb5fcdd89a6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z1 = F.relu(u1)\n",
        "z1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable([[1.7038419, 0.       ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "olqfxwBAJW4N",
        "colab_type": "code",
        "outputId": "10935c7c-b251-4feb-c2b2-1bdc6c87a681",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = fc2(z1)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable([[-0.09968679]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "0IZA9_ZbJW4R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "この値が計算できれば正解です。"
      ]
    },
    {
      "metadata": {
        "id": "wAdM2MR_JW4S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 損失関数（loss function）の値を計算しよう\n",
        "\n",
        "出力の予測値が計算できたので、損失関数の値も計算してみましょう。\n",
        "先の入力に対する教師データが`t=3`だとすると、以下のように計算できます。"
      ]
    },
    {
      "metadata": {
        "id": "huVrTbE8JW4T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 教師データ\n",
        "t = np.array([[3]], 'f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xk50BJb8JW4W",
        "colab_type": "code",
        "outputId": "8cd663cb-45f8-4ab8-9db5-9e5772393135",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 平均二乗誤差の計算\n",
        "loss = F.mean_squared_error(t, y)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable(9.608059)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "NsrWGp68JW4Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "こちらのように評価関数に関しても、Chainerではchainer.functions（F）の中に定義されているため、特別発展的な内容でない限りはこちらを使用して進めていくと良いでしょう。"
      ]
    },
    {
      "metadata": {
        "id": "52y4R59-JW4a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### chainer.links（L）とchainer.functions（F）の違い\n",
        "\n",
        "これまで、Chainerの機能である`L`と`F`が何回か登場しましたが、どのように使い分けているかは以下の通りです。\n",
        "\n",
        "- chainer.links（L）：調整すべきパラメータを持つ関数\n",
        "- chainer.functions（F）：調整すべきパラメータを持たない関数\n",
        "\n",
        "具体的には、`L.Linear`のように内部で重み`W`やバイアス`b`のパラメータを持つ場合はchainer.linksで用意されています。\n",
        "逆にRelu関数では、$f(u) = \\max(0, u)$ のように、内部でパラメータを持たないため、chainer.functionsで用意されています。"
      ]
    },
    {
      "metadata": {
        "id": "Z6cVGbglJW4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Chainerでクラス分類\n",
        "\n",
        "### データの読み込み\n",
        "\n",
        "今回はdataフォルダに格納されている`wine_class.csv`を使用してクラス分類の実装を練習してみましょう。\n",
        "どのような形式でデータを準備しておくと良いのかといった参考になるため、格納されている生のデータも確認しておきましょう。\n",
        "\n",
        "今回はCSVファイルで用意されているため、データの取り扱いはPythonのデータ操作で一般的な**Pandas**を使って行いましょう。"
      ]
    },
    {
      "metadata": {
        "id": "2HEJZMtKJW4b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8yXGb2G5JW4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# データの読み込み（df: data frame）\n",
        "df = pd.read_csv('data/wine_class.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Tjn88ogJW4f",
        "colab_type": "code",
        "outputId": "3e7fc34f-1cbe-4c74-a221-60dea4289d02",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# データの表示（先頭の３件）\n",
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Class  Alcohol   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
              "0      1    14.23  2.43               15.6        127           2.80   \n",
              "1      1    13.20  2.14               11.2        100           2.65   \n",
              "2      1    13.16  2.67               18.6        101           2.80   \n",
              "\n",
              "   Flavanoids  Nonflavanoid phenols  Color intensity   Hue  Proline  \n",
              "0        3.06                  0.28             5.64  1.04     1065  \n",
              "1        2.76                  0.26             4.38  1.05     1050  \n",
              "2        3.24                  0.30             5.68  1.03     1185  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "uPsGovkvJW4j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 入力変数と教師データ（出力変数）に切り分ける\n",
        "\n",
        "機械学習のプログラミングを行う上での最初のお題として、入力変数と教師データ（出力変数）の切り分けがあります。\n",
        "こちらは、毎回行うため、スムーズに出来るように練習しておくことをおすすめします。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "AjQ729jnJW4j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 教師データ（先頭のClass）\n",
        "t = df.iloc[:, 0]\n",
        " \n",
        "# 入力変数（1番目から最後まで）\n",
        "x = df.iloc[:, 1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--IIGdP4JW4p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "こちらのように、正しく切り分けられているかデータの中身を表示して確認しておきましょう。"
      ]
    },
    {
      "metadata": {
        "id": "zlXN6cw2JW4q",
        "colab_type": "code",
        "outputId": "f4d3c7e8-8d1c-4030-9dc2-46eece892208",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 表示して確認\n",
        "x.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Alcohol   Ash  Alcalinity of ash  Magnesium  Total phenols  Flavanoids  \\\n",
              "0    14.23  2.43               15.6        127           2.80        3.06   \n",
              "1    13.20  2.14               11.2        100           2.65        2.76   \n",
              "2    13.16  2.67               18.6        101           2.80        3.24   \n",
              "\n",
              "   Nonflavanoid phenols  Color intensity   Hue  Proline  \n",
              "0                  0.28             5.64  1.04     1065  \n",
              "1                  0.26             4.38  1.05     1050  \n",
              "2                  0.30             5.68  1.03     1185  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "QJJvBAwQJW4t",
        "colab_type": "code",
        "outputId": "b50a28e9-a112-4002-cef3-065b617152af",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# サイズの確認\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "ChnuXDvGJW4w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`.shape`を使うことで、サンプル数（今回は178）と入力変数の数（今回は10）を確認することができます。"
      ]
    },
    {
      "metadata": {
        "id": "m98qQRf0JW4x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Chainerで計算できるデータ形式に変換\n",
        "\n",
        "Chainerで計算を行うために、下記の３点を満たしているか確認を行っておきましょう。\n",
        "こちらが指定された形式となっていない場合、学習の際にエラーが出てしまいます。\n",
        "\n",
        "- 入力変数や教師データがNumpyで定義されているか\n",
        "- 分類の場合、ラベルが0から始まっているか\n",
        "- 入力変数が float32、教師データが回帰の場合 float32、分類の場合 int32 で定義されているか"
      ]
    },
    {
      "metadata": {
        "id": "_iI1bjl7JW4y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Numpyに変換\n",
        "\n",
        "Pandasで読み込んだ場合、Pandasの形式となっています。"
      ]
    },
    {
      "metadata": {
        "id": "Px1AxqajJW4z",
        "colab_type": "code",
        "outputId": "0313e097-0dc2-473c-a53e-e633effc6112",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "HDrA9Lo3JW42",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "そのため、こちらをNumpyの形式に変換するのは、`.values`とつければOKです。"
      ]
    },
    {
      "metadata": {
        "id": "QqlGP6CpJW44",
        "colab_type": "code",
        "outputId": "cb33f24f-52eb-46d1-e916-d2f59f2e5ff5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(x.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "TX0YcHJ_JW4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 分類で使用するラベルを0から始める\n",
        "\n",
        "今回準備されている教師データのラベルを確認してみましょう。\n",
        "`min`と`max`で確認すると良いでしょう。"
      ]
    },
    {
      "metadata": {
        "id": "pE63HYAHJW4-",
        "colab_type": "code",
        "outputId": "c4fdbe6f-73e0-4c9e-ae4b-d9e67f046bc5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t.min()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "fPtMy_aZJW5C",
        "colab_type": "code",
        "outputId": "96d69ea7-dea8-4821-9b40-392aa616ea96",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "fv-0EnJ2JW5E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "今回はラベルが`1`から始まって`3`で終わっているため、`1, 2, 3`というラベルが割り振られた3クラスの分類であることがわかります。\n",
        "0から始める必要があるため、`1, 2, 3` → `0, 1, 2` としましょう。\n",
        "\n",
        "Numpyでは、全体に対する引き算もサポートしているため、`t-1`とすればラベル全体に1が引かれ、`0, 1, 2`となります。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "bZKXG5iJJW5F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Numpyにデータ型を変換し、ラベルを0から始める\n",
        "t = t.values - 1\n",
        "x = x.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q2lApLvMJW5H",
        "colab_type": "code",
        "outputId": "e1864771-6470-44cc-de6f-4761e805719e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "GtAUBtpFJW5L",
        "colab_type": "code",
        "outputId": "c0046da1-2db6-4eee-c184-668ceea2b9b0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "PumGpKQaJW5O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### データ型を変更\n",
        "\n",
        "ここで、現状のデータ型を確認してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "nWEFbAPzJW5P",
        "colab_type": "code",
        "outputId": "250032c5-09b0-4c08-c904-8b9a17a3bd71",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "rCbAQf15JW5T",
        "colab_type": "code",
        "outputId": "01113e70-7ff6-466e-d078-f39cf5560997",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "y6TpCKmoJW5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "こちらのように、`.dtype`のコマンドで確認することができます。\n",
        "このように、本来であれば32bitで指定しないといけないところを64bit版のコンピュータであれば、デフォルトが64bitで定義されてしまうため、変更する必要がでてきます。\n",
        "\n",
        "Numpy側で準備されている`.astype()`を使用して、32bitへと変換しておきましょう。Chainer初心者でほぼ必ず遭遇するエラーですので、気をつけましょう。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "_5LFn2j6JW5W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 32bitに変換\n",
        "x = x.astype('float32')\n",
        "t = t.astype('int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "du5Cq9zbJW5a",
        "colab_type": "code",
        "outputId": "f857e2fb-0fcf-400c-9b19-f25cce68b92a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "pKY5TwkMJW5d",
        "colab_type": "code",
        "outputId": "5eec3c6e-4f70-44f2-a462-f3a03aa5e31a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "P8eBN8KvJW5f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Chainerで使用するデータセットの形式\n",
        "\n",
        "メモリに乗る程度の小規模なデータの場合は、**入力変数と教師データをタプルで１セット**にし、それを**リスト化**しておくことがChainer推奨の形式です。\n",
        "\n",
        "![](https://github.com/mitmul/medical-ai-course-materials/blob/master/notebooks/images/3-5/img02.png?raw=1)"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "vnqo6RbXJW5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Chainerで使用できるデータセットの形式\n",
        "dataset = list(zip(x, t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDqI7h28JW5h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このように、`zip(x, t)`で入力変数と教師データをタプル化した後、それを`list`でリスト化します。\n",
        "毎回同じ記述のため、このように書くと覚えればOKです。"
      ]
    },
    {
      "metadata": {
        "id": "aWp6cUkwJW5i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 訓練データと検証データを分割しよう\n",
        "\n",
        "機械学習には欠かせない訓練データと検証データの分割です。\n",
        "Chainerでは`chainer.datasets.split_dataset_random`にその機能が準備されています。\n",
        "ランダムでなく、前半の70%を訓練、後半の30%を検証といった分割が良い場合は、`chainer.datasets.split_dataset`を使用することができます。\n",
        "※ 詳しくは[こちら](https://docs.chainer.org/en/stable/reference/generated/chainer.datasets.split_dataset_random.html#chainer.datasets.split_dataset_random)のリファレンス参照\n",
        "\n",
        "![](https://github.com/mitmul/medical-ai-course-materials/blob/master/notebooks/images/3-5/img03.png?raw=1)\n",
        "\n",
        "Prameterには`dataset`（先ほど作成した形式）、`first_size`と指定されています。\n",
        "\n",
        "`first_size`では訓練データのサイズを指定するのですが、このとき全体の70%を訓練データにしようと決めておくと、記述が簡単かつ汎用性の高いプログラムになります。\n",
        "\n",
        "全体のサイズを取得する時には`len()`が便利です。"
      ]
    },
    {
      "metadata": {
        "id": "qUh5CdVrJW5i",
        "colab_type": "code",
        "outputId": "4a82c910-5cfb-44a6-df13-bf0e42145a61",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "abP0ek-dJW5l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`split_dataset_random`を使用した`train`と`test`の分割は以下のようになります。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "6408SGMgJW5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 訓練データのサンプル数\n",
        "n_train = int(len(dataset) * 0.7)\n",
        "\n",
        "# 訓練データ(train)と検証データ(test)に分割\n",
        "train, test = chainer.datasets.split_dataset_random(dataset, n_train, seed=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8m7MQ73MJW5p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`n_train`を計算する際`int`と付けていますが、サイズは整数値しか受け付けません。小数が出たときは`int`によって小数値の切り捨てを行っています。\n",
        "\n",
        "`seed=1`は、乱数のシードを1で固定しますという意味で、何度か出てきた**再現性確保**のためです。\n",
        "\n",
        "出力として得られる`train`と`test`を確認してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "VhMIwvsyJW5p",
        "colab_type": "code",
        "outputId": "ae8b0be0-9e00-4b42-85c7-9214907d3fcc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<chainer.datasets.sub_dataset.SubDataset at 0x7fdd37e7a518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "bykpAE-mJW5r",
        "colab_type": "code",
        "outputId": "f2eec77e-6828-4891-c2ee-dcea5584bc06",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<chainer.datasets.sub_dataset.SubDataset at 0x7fdd37e7a4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "ezhQuyunJW5v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "こちらのように数値が表示されず、どのような形式であるか迷いますが、`train[0]`のようにリストの要素番号を指定すると数値が表示され、リスト形式で保存されていることがわかります。\n",
        "このあたりは、なかなかリファレンスがないため、挙動を確認しながら進めていくことが必要です。"
      ]
    },
    {
      "metadata": {
        "id": "ad0VdyiLJW5w",
        "colab_type": "code",
        "outputId": "9686ab8e-76ec-445f-d170-5a5887024d6c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.369e+01, 2.540e+00, 2.000e+01, 1.070e+02, 1.830e+00, 5.600e-01,\n",
              "        5.000e-01, 5.880e+00, 9.600e-01, 6.800e+02], dtype=float32), 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "0NIAmo5MJW5y",
        "colab_type": "code",
        "outputId": "172abb36-0e8b-4fda-de30-ee20fd76c8f7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "kB0ROHp0JW50",
        "colab_type": "code",
        "outputId": "2f4fea73-63bf-4a1d-82ce-b82acc0a6a49",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "ZsXR7-LvJW52",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ニューラルネットワークのモデルを定義"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "z7_i0PKIJW53",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NN(chainer.Chain):\n",
        "\n",
        "    # モデルの構造\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        with self.init_scope():\n",
        "            self.fc1 = L.Linear(10, 5)  # 10 → 5\n",
        "            self.fc2 = L.Linear(5, 3)  # 5 → 3\n",
        "\n",
        "    # 順伝播\n",
        "    def __call__(self, x):\n",
        "        u1 = self.fc1(x)\n",
        "        z1 = F.relu(u1)\n",
        "        u2 = self.fc2(z1)\n",
        "        return u2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IFU6sUcUJW55",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "こちらのように、`__init__`にパラメータを持つリンクを宣言しておき、`__call__`の中で順伝播の計算を記述します。\n",
        "\n",
        "これが一番簡単な書き方ですが、さらに上級者向けの書き方にブラッシュアップしていきましょう。\n",
        "まずは、ノードの数を変更するためにはクラス内部を変更する必要がありますが、ここを変数で置き換えて、インスタンス化のタイミングで自由に変更できるようにしておきましょう。\n",
        "\n",
        "下記のように変数の初期値も設定しておくと、インスタンス化の際に何も指定しない場合にデフォルトの値が使用され便利です。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "w9zYbSkFJW56",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NN(chainer.Chain):\n",
        "\n",
        "    # モデルの構造\n",
        "    def __init__(self, n_mid_units=5, n_out=3):\n",
        "        super().__init__()\n",
        "        with self.init_scope():\n",
        "            self.fc1 = L.Linear(10, n_mid_units)  # 変数で置き換え\n",
        "            self.fc2 = L.Linear(5, n_out)  # 変数で置き換え\n",
        "\n",
        "    # 順伝播\n",
        "    def __call__(self, x):\n",
        "        u1 = self.fc1(x)\n",
        "        z1 = F.relu(u1)\n",
        "        u2 = self.fc2(z1)\n",
        "        return u2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FgdhL4wRJW57",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "つぎに、`L.Linear`の最初の引数は、`None`と指定することで、入力されるデータから自動的に判断することができるため、手動で入力しなくても良いです。\n",
        "今回はノードの数を簡単に把握することができるため、その恩恵は少ないのですが、この後登場する画像向けのConvolutional Neural Networkなどでは、この機能が活躍します。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "ViosTgaYJW58",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NN(chainer.Chain):\n",
        "\n",
        "    # モデルの構造\n",
        "    def __init__(self, n_mid_units=5, n_out=3):\n",
        "        super().__init__()\n",
        "        with self.init_scope():\n",
        "            self.fc1 = L.Linear(None, n_mid_units)  # 10 → None で自動推定\n",
        "            self.fc2 = L.Linear(None, n_out)  # 5 → None で自動推定\n",
        "\n",
        "    # 順伝播\n",
        "    def __call__(self, x):\n",
        "        u1 = self.fc1(x)\n",
        "        z1 = F.relu(u1)\n",
        "        u2 = self.fc2(z1)\n",
        "        return u2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HESmzfXeJW5-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "さらに、順伝播の計算は層の数がさらに増えてくると、変数名の管理が難しくなってくるため、`h`という変数で受け渡し続けると管理する部分が減ります。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "jn60XwcRJW5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NN(chainer.Chain):\n",
        "\n",
        "    # モデルの構造\n",
        "    def __init__(self, n_mid_units=5, n_out=3):\n",
        "        super().__init__()\n",
        "        with self.init_scope():\n",
        "            self.fc1 = L.Linear(None, n_mid_units)\n",
        "            self.fc2 = L.Linear(None, n_out)\n",
        "\n",
        "    # 順伝播\n",
        "    def __call__(self, x):\n",
        "        h = self.fc1(x)  # hで置きかえ\n",
        "        h = F.relu(h)  # hで置きかえ\n",
        "        h = self.fc2(h)  # hで置きかえ\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q6fkfSCEJW5_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "モデルの定義が完了したため、インスタンス化しておきましょう。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "WlLNAyPbJW6A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nn = NN()  # 引数を指定しないため、デフォルトの n_mid_units=5, n_out=3 が使用される"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efBbQFoXJW6B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "もし、引数にデフォルトの値を使用しない場合は下記のように指定します。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Of6ZttqXJW6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nn = NN(n_mid_units=10, n_out=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iUhLT-iWJW6D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "また、この後に学習を行う際、評価関数やレポーティングの機能などは `L.Classifier` で準備されているため、こちらで宣言したモデルをラップしてあげるだけで学習のための準備が完了します。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "oGlv3do5JW6E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = L.Classifier(nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtp_7ikWJW6F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここで、一点忘れてはいけないこととして、乱数のシードの固定です。\n",
        "モデルを宣言するタイミングでパラメータの値が初期化されるため、その前にシードを固定しておきましょう。\n",
        "\n",
        "厳密には一番最初のデータが投入された際に `None` で宣言した部分のノード数などが推定されて具体的なモデルが決定します。\n",
        "しかし、忘れる前にインスタンス化のタイミングでシードを固定しておくと安全です。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "lMDXh1idJW6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "uGqzGte4JW6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nn = NN()\n",
        "model = L.Classifier(nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hq_jcsXqJW6I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizerの定義\n",
        "\n",
        "Optimizerではパラメータの最適化を行うための最適化のアルゴリズムを選択します。\n",
        "各最適化のアルゴリズムには**ハイパーパラメータ**と呼ばれる定数を設定することもできますが、まだここでは触れず、後ほどしっかりと見ていきましょう。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Kc7qQHMvJW6J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = chainer.optimizers.SGD()  # 確率的勾配降下法（SGD）を使用"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MvYmv8wLJW6J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "optimizerを単体で定義するだけでは、先ほど宣言した`model`と結びつかないため、下記のように設定を行います。"
      ]
    },
    {
      "metadata": {
        "id": "2DEOtQQ-JW6J",
        "colab_type": "code",
        "outputId": "ddb00eb2-b36a-44a9-a828-bd07e5e1782b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer.setup(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<chainer.optimizers.sgd.SGD at 0x7fdd37e7aa58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "Z7LQk0L8JW6O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Iteratorの定義\n",
        "\n",
        "**Iterator**では「**バッチサイズ**」を決めることができます。\n",
        "\n",
        "順伝播で評価関数を計算するとき全てのサンプルを使用するのではなく、**ミニバッチ**と呼ばれるサンプルの一部のデータセットのみで評価関数の計算を行い、逆伝播で勾配情報を計算し、最適化アルゴリズム（SGDやAdam等）によるパラメータの学習を行います。\n",
        "\n",
        "> **ミニバッチを採用する理由**\n",
        ">\n",
        "> 例えば、10万サンプルある場合「10万回順伝播を計算しようやく1回パラメータ更新できる」というような、サンプル数が多いほどパラメータ更新にかかる時間が長くなるという問題を避けられます。\n",
        "> バッチサイズを10としておけば、ほとんど同じ計算負荷で1万回のパラメータ更新を行うことができます。（厳密には逆伝播が毎回走るため同じ計算負荷ではない）\n",
        ">\n",
        "> もう一つの理由として、ミニバッチに分けて最適化を行うことで局所最適解に陥ることを避けられると言われています。\n",
        "\n",
        "今回は**バッチサイズ**を10と設定しましょう。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "z-6e87gzJW6O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchsize = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "6Uz-dSnxJW6Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "test_iter  = chainer.iterators.SerialIterator(test,  batchsize, repeat=False, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IiyZ0Rv1JW6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Updaterの定義\n",
        "\n",
        "**Updater**では、**Optimizer**の設定や使用するデバイス（CPUやGPU）の設定を行えます。\n",
        "\n",
        "*   CPUを使用する場合には`device=-1`とオプションに指定しましょう。\n",
        "*   GPUを使用する場合には`device=0`（GPUを複数枚指している場合は`device=1`なども存在）とオプションで明示しておきましょう。\n",
        "\n",
        "`device`を指定しない場合は、CPUが使用されます。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "-WtnXcs9JW6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer import training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "ssnkYaWKJW6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "updater = training.StandardUpdater(train_iter, optimizer, device=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QHE_ZpJoJW6X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Trainerとextensionsの設定\n",
        "\n",
        "Trainerでは、**エポック（ミニバッチを全て処理して１エポック）**の回数や、そのextensionsでオプションを指定することにより、**結果をログ出力**や**標準出力**（インタラクティブに表示）できます。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "65YYr97iJW6X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer.training import extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "xcpObE9DJW6Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# エポックの数\n",
        "epoch = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "zt4BQF73JW6Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# trainerの宣言\n",
        "trainer = training.Trainer(updater, (epoch, 'epoch'), out='result/wine')\n",
        "\n",
        "# 検証データで評価\n",
        "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
        "\n",
        "# 学習の経過をtrainerのoutで指定したフォルダにlogというファイル名で記録する\n",
        "trainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n",
        "\n",
        "# １エポックごと（trigger）に、trainデータに対するlossと、testデータに対するloss、経過時間（elapsed_time）を標準出力させる\n",
        "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=(1, 'epoch'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZc95xCcJW6a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習の実行\n",
        "\n",
        "設定が完了すると、下記のコマンドで学習を実行して、その結果をレポーティングしてくれます。"
      ]
    },
    {
      "metadata": {
        "id": "88qtLX3jJW6a",
        "colab_type": "code",
        "outputId": "7ac77134-a59b-46a0-bed0-49e51655f0c8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/accuracy  validation/main/accuracy  main/loss   validation/main/loss  elapsed_time\n",
            "\u001b[J1           0.392308       0.341667                  54.0227     1.09851               0.0838952     \n",
            "\u001b[J2           0.408333       0.341667                  1.09675     1.09853               0.107586      \n",
            "\u001b[J3           0.423077       0.341667                  1.095       1.0986                0.132338      \n",
            "\u001b[J4           0.425          0.341667                  1.09292     1.09875               0.157441      \n",
            "\u001b[J5           0.416667       0.341667                  1.0927      1.0989                0.180843      \n",
            "\u001b[J6           0.438462       0.341667                  1.08944     1.09918               0.205588      \n",
            "\u001b[J7           0.391667       0.341667                  1.09269     1.09935               0.228848      \n",
            "\u001b[J8           0.438462       0.341667                  1.08715     1.09971               0.253859      \n",
            "\u001b[J9           0.4            0.341667                  1.09034     1.09996               0.277414      \n",
            "\u001b[J10          0.425          0.341667                  1.0867      1.10029               0.305134      \n",
            "\u001b[J11          0.407692       0.341667                  1.08658     1.10068               0.330089      \n",
            "\u001b[J12          0.425          0.341667                  1.0862      1.10101               0.353375      \n",
            "\u001b[J13          0.430769       0.341667                  1.08562     1.10134               0.381007      \n",
            "\u001b[J14          0.416667       0.341667                  1.08215     1.10182               0.404768      \n",
            "\u001b[J15          0.416667       0.341667                  1.08526     1.10215               0.42862       \n",
            "\u001b[J16          0.430769       0.341667                  1.08059     1.10268               0.453811      \n",
            "\u001b[J17          0.408333       0.341667                  1.08527     1.10298               0.477348      \n",
            "\u001b[J18          0.430769       0.341667                  1.07938     1.10353               0.502497      \n",
            "\u001b[J19          0.4            0.341667                  1.08684     1.10374               0.52966       \n",
            "\u001b[J20          0.425          0.341667                  1.08092     1.10415               0.55528       \n",
            "\u001b[J21          0.423077       0.341667                  1.08133     1.10457               0.582715      \n",
            "\u001b[J22          0.408333       0.341667                  1.08287     1.1049                0.607548      \n",
            "\u001b[J23          0.430769       0.341667                  1.07833     1.10539               0.633265      \n",
            "\u001b[J24          0.416667       0.341667                  1.08094     1.10576               0.657938      \n",
            "\u001b[J25          0.416667       0.341667                  1.08067     1.1061                0.682981      \n",
            "\u001b[J26          0.423077       0.341667                  1.07868     1.10655               0.708941      \n",
            "\u001b[J27          0.416667       0.341667                  1.08165     1.10683               0.735531      \n",
            "\u001b[J28          0.415385       0.341667                  1.07957     1.10722               0.76274       \n",
            "\u001b[J29          0.425          0.341667                  1.07837     1.10761               0.787045      \n",
            "\u001b[J30          0.416667       0.341667                  1.07987     1.10793               0.812019      \n",
            "\u001b[J31          0.415385       0.341667                  1.07916     1.1083                0.838868      \n",
            "\u001b[J32          0.416667       0.341667                  1.08099     1.10855               0.865626      \n",
            "\u001b[J33          0.446154       0.341667                  1.07157     1.10917               0.89501       \n",
            "\u001b[J34          0.391667       0.341667                  1.08715     1.10917               0.920375      \n",
            "\u001b[J35          0.425          0.341667                  1.07586     1.10958               0.948092      \n",
            "\u001b[J36          0.407692       0.341667                  1.08455     1.10964               0.976731      \n",
            "\u001b[J37          0.425          0.341667                  1.07591     1.11003               1.0026        \n",
            "\u001b[J38          0.430769       0.341667                  1.07522     1.11045               1.0288        \n",
            "\u001b[J39          0.425          0.341667                  1.07363     1.11089               1.05366       \n",
            "\u001b[J40          0.408333       0.341667                  1.08196     1.111                 1.08297       \n",
            "\u001b[J41          0.423077       0.341667                  1.07644     1.11134               1.11031       \n",
            "\u001b[J42          0.416667       0.341667                  1.07867     1.11157               1.13651       \n",
            "\u001b[J43          0.4            0.341667                  1.08609     1.11149               1.16737       \n",
            "\u001b[J44          0.425          0.341667                  1.07322     1.1119                1.1954        \n",
            "\u001b[J45          0.433333       0.341667                  1.07488     1.11223               1.22152       \n",
            "\u001b[J46          0.4            0.341667                  1.083       1.11226               1.24877       \n",
            "\u001b[J47          0.441667       0.341667                  1.07309     1.11264               1.27817       \n",
            "\u001b[J48          0.430769       0.341667                  1.07278     1.11306               1.30599       \n",
            "\u001b[J49          0.4            0.341667                  1.0877      1.11288               1.33153       \n",
            "\u001b[J50          0.425          0.341667                  1.07275     1.11325               1.36121       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2u1wnNbXJW6d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 結果の確認\n",
        "\n",
        "最後に今回のモデルでの予測結果を確認しておきましょう。\n",
        "Trainerを使用すると、`result/wine`というフォルダができ、この中に`log`というファイルが自動的に生成されます。\n",
        "こちらに、学習結果が全て保存されており、後で学習の状況を可視化して確認したりできます。\n",
        "\n",
        "まずは、logのファイルをPythonで読み込みましょう。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Ll0w_B-JJW6d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "HiqtmWbPJW6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# logファイルから結果の読み込み\n",
        "with open('result/wine/log') as f:\n",
        "    logs = json.load(f)\n",
        "    results = pd.DataFrame(logs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVYitflyJW6f",
        "colab_type": "code",
        "outputId": "493faf73-b410-48f5-c8df-54510e5c001e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 結果の確認\n",
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>epoch</th>\n",
              "      <th>iteration</th>\n",
              "      <th>main/accuracy</th>\n",
              "      <th>main/loss</th>\n",
              "      <th>validation/main/accuracy</th>\n",
              "      <th>validation/main/loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.083895</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>0.392308</td>\n",
              "      <td>54.022660</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.098510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.107586</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.408333</td>\n",
              "      <td>1.096746</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.098532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.132338</td>\n",
              "      <td>3</td>\n",
              "      <td>38</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>1.095000</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.098596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.157441</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.092917</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.098753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.180843</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.092705</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.098903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.205588</td>\n",
              "      <td>6</td>\n",
              "      <td>75</td>\n",
              "      <td>0.438462</td>\n",
              "      <td>1.089438</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.099179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.228848</td>\n",
              "      <td>7</td>\n",
              "      <td>87</td>\n",
              "      <td>0.391667</td>\n",
              "      <td>1.092686</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.099351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.253859</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>0.438462</td>\n",
              "      <td>1.087147</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.099714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.277414</td>\n",
              "      <td>9</td>\n",
              "      <td>112</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.090339</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.099957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.305134</td>\n",
              "      <td>10</td>\n",
              "      <td>124</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.086703</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.100286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.330089</td>\n",
              "      <td>11</td>\n",
              "      <td>137</td>\n",
              "      <td>0.407692</td>\n",
              "      <td>1.086583</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.100678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.353375</td>\n",
              "      <td>12</td>\n",
              "      <td>149</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.086195</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.101006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.381007</td>\n",
              "      <td>13</td>\n",
              "      <td>162</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>1.085618</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.101335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.404768</td>\n",
              "      <td>14</td>\n",
              "      <td>174</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.082146</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.101823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.428620</td>\n",
              "      <td>15</td>\n",
              "      <td>186</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.085265</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.102153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.453811</td>\n",
              "      <td>16</td>\n",
              "      <td>199</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>1.080586</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.102679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.477348</td>\n",
              "      <td>17</td>\n",
              "      <td>211</td>\n",
              "      <td>0.408333</td>\n",
              "      <td>1.085265</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.102984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.502497</td>\n",
              "      <td>18</td>\n",
              "      <td>224</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>1.079380</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.103525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.529660</td>\n",
              "      <td>19</td>\n",
              "      <td>236</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.086844</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.103739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.555280</td>\n",
              "      <td>20</td>\n",
              "      <td>248</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.080922</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.104153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.582715</td>\n",
              "      <td>21</td>\n",
              "      <td>261</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>1.081330</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.104570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.607548</td>\n",
              "      <td>22</td>\n",
              "      <td>273</td>\n",
              "      <td>0.408333</td>\n",
              "      <td>1.082865</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.104903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.633265</td>\n",
              "      <td>23</td>\n",
              "      <td>286</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>1.078326</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.105393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.657938</td>\n",
              "      <td>24</td>\n",
              "      <td>298</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.080940</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.105757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.682981</td>\n",
              "      <td>25</td>\n",
              "      <td>310</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.080675</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.106102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.708941</td>\n",
              "      <td>26</td>\n",
              "      <td>323</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>1.078684</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.106548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.735531</td>\n",
              "      <td>27</td>\n",
              "      <td>335</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.081647</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.106831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.762740</td>\n",
              "      <td>28</td>\n",
              "      <td>348</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>1.079566</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.107223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.787045</td>\n",
              "      <td>29</td>\n",
              "      <td>360</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.078369</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.107608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.812019</td>\n",
              "      <td>30</td>\n",
              "      <td>372</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.079872</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.107932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.838868</td>\n",
              "      <td>31</td>\n",
              "      <td>385</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>1.079161</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.108303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.865626</td>\n",
              "      <td>32</td>\n",
              "      <td>397</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.080995</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.108546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.895010</td>\n",
              "      <td>33</td>\n",
              "      <td>410</td>\n",
              "      <td>0.446154</td>\n",
              "      <td>1.071573</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.109174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.920375</td>\n",
              "      <td>34</td>\n",
              "      <td>422</td>\n",
              "      <td>0.391667</td>\n",
              "      <td>1.087154</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.109171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.948092</td>\n",
              "      <td>35</td>\n",
              "      <td>434</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.075857</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.109576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.976731</td>\n",
              "      <td>36</td>\n",
              "      <td>447</td>\n",
              "      <td>0.407692</td>\n",
              "      <td>1.084554</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.109642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1.002603</td>\n",
              "      <td>37</td>\n",
              "      <td>459</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.075910</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.110033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1.028802</td>\n",
              "      <td>38</td>\n",
              "      <td>472</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>1.075224</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.110446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1.053658</td>\n",
              "      <td>39</td>\n",
              "      <td>484</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.073628</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.110888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1.082971</td>\n",
              "      <td>40</td>\n",
              "      <td>496</td>\n",
              "      <td>0.408333</td>\n",
              "      <td>1.081960</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.111004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1.110315</td>\n",
              "      <td>41</td>\n",
              "      <td>509</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>1.076441</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.111342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1.136511</td>\n",
              "      <td>42</td>\n",
              "      <td>521</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.078673</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.111572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>1.167366</td>\n",
              "      <td>43</td>\n",
              "      <td>534</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.086085</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.111493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1.195397</td>\n",
              "      <td>44</td>\n",
              "      <td>546</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.073220</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.111902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1.221522</td>\n",
              "      <td>45</td>\n",
              "      <td>558</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>1.074877</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.112229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1.248769</td>\n",
              "      <td>46</td>\n",
              "      <td>571</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.083000</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.112259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1.278170</td>\n",
              "      <td>47</td>\n",
              "      <td>583</td>\n",
              "      <td>0.441667</td>\n",
              "      <td>1.073086</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.112637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1.305985</td>\n",
              "      <td>48</td>\n",
              "      <td>596</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>1.072776</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.113060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1.331528</td>\n",
              "      <td>49</td>\n",
              "      <td>608</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.087705</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.112877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>1.361215</td>\n",
              "      <td>50</td>\n",
              "      <td>620</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>1.072748</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>1.113252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    elapsed_time  epoch  iteration  main/accuracy  main/loss  \\\n",
              "0       0.083895      1         13       0.392308  54.022660   \n",
              "1       0.107586      2         25       0.408333   1.096746   \n",
              "2       0.132338      3         38       0.423077   1.095000   \n",
              "3       0.157441      4         50       0.425000   1.092917   \n",
              "4       0.180843      5         62       0.416667   1.092705   \n",
              "5       0.205588      6         75       0.438462   1.089438   \n",
              "6       0.228848      7         87       0.391667   1.092686   \n",
              "7       0.253859      8        100       0.438462   1.087147   \n",
              "8       0.277414      9        112       0.400000   1.090339   \n",
              "9       0.305134     10        124       0.425000   1.086703   \n",
              "10      0.330089     11        137       0.407692   1.086583   \n",
              "11      0.353375     12        149       0.425000   1.086195   \n",
              "12      0.381007     13        162       0.430769   1.085618   \n",
              "13      0.404768     14        174       0.416667   1.082146   \n",
              "14      0.428620     15        186       0.416667   1.085265   \n",
              "15      0.453811     16        199       0.430769   1.080586   \n",
              "16      0.477348     17        211       0.408333   1.085265   \n",
              "17      0.502497     18        224       0.430769   1.079380   \n",
              "18      0.529660     19        236       0.400000   1.086844   \n",
              "19      0.555280     20        248       0.425000   1.080922   \n",
              "20      0.582715     21        261       0.423077   1.081330   \n",
              "21      0.607548     22        273       0.408333   1.082865   \n",
              "22      0.633265     23        286       0.430769   1.078326   \n",
              "23      0.657938     24        298       0.416667   1.080940   \n",
              "24      0.682981     25        310       0.416667   1.080675   \n",
              "25      0.708941     26        323       0.423077   1.078684   \n",
              "26      0.735531     27        335       0.416667   1.081647   \n",
              "27      0.762740     28        348       0.415385   1.079566   \n",
              "28      0.787045     29        360       0.425000   1.078369   \n",
              "29      0.812019     30        372       0.416667   1.079872   \n",
              "30      0.838868     31        385       0.415385   1.079161   \n",
              "31      0.865626     32        397       0.416667   1.080995   \n",
              "32      0.895010     33        410       0.446154   1.071573   \n",
              "33      0.920375     34        422       0.391667   1.087154   \n",
              "34      0.948092     35        434       0.425000   1.075857   \n",
              "35      0.976731     36        447       0.407692   1.084554   \n",
              "36      1.002603     37        459       0.425000   1.075910   \n",
              "37      1.028802     38        472       0.430769   1.075224   \n",
              "38      1.053658     39        484       0.425000   1.073628   \n",
              "39      1.082971     40        496       0.408333   1.081960   \n",
              "40      1.110315     41        509       0.423077   1.076441   \n",
              "41      1.136511     42        521       0.416667   1.078673   \n",
              "42      1.167366     43        534       0.400000   1.086085   \n",
              "43      1.195397     44        546       0.425000   1.073220   \n",
              "44      1.221522     45        558       0.433333   1.074877   \n",
              "45      1.248769     46        571       0.400000   1.083000   \n",
              "46      1.278170     47        583       0.441667   1.073086   \n",
              "47      1.305985     48        596       0.430769   1.072776   \n",
              "48      1.331528     49        608       0.400000   1.087705   \n",
              "49      1.361215     50        620       0.425000   1.072748   \n",
              "\n",
              "    validation/main/accuracy  validation/main/loss  \n",
              "0                   0.341667              1.098510  \n",
              "1                   0.341667              1.098532  \n",
              "2                   0.341667              1.098596  \n",
              "3                   0.341667              1.098753  \n",
              "4                   0.341667              1.098903  \n",
              "5                   0.341667              1.099179  \n",
              "6                   0.341667              1.099351  \n",
              "7                   0.341667              1.099714  \n",
              "8                   0.341667              1.099957  \n",
              "9                   0.341667              1.100286  \n",
              "10                  0.341667              1.100678  \n",
              "11                  0.341667              1.101006  \n",
              "12                  0.341667              1.101335  \n",
              "13                  0.341667              1.101823  \n",
              "14                  0.341667              1.102153  \n",
              "15                  0.341667              1.102679  \n",
              "16                  0.341667              1.102984  \n",
              "17                  0.341667              1.103525  \n",
              "18                  0.341667              1.103739  \n",
              "19                  0.341667              1.104153  \n",
              "20                  0.341667              1.104570  \n",
              "21                  0.341667              1.104903  \n",
              "22                  0.341667              1.105393  \n",
              "23                  0.341667              1.105757  \n",
              "24                  0.341667              1.106102  \n",
              "25                  0.341667              1.106548  \n",
              "26                  0.341667              1.106831  \n",
              "27                  0.341667              1.107223  \n",
              "28                  0.341667              1.107608  \n",
              "29                  0.341667              1.107932  \n",
              "30                  0.341667              1.108303  \n",
              "31                  0.341667              1.108546  \n",
              "32                  0.341667              1.109174  \n",
              "33                  0.341667              1.109171  \n",
              "34                  0.341667              1.109576  \n",
              "35                  0.341667              1.109642  \n",
              "36                  0.341667              1.110033  \n",
              "37                  0.341667              1.110446  \n",
              "38                  0.341667              1.110888  \n",
              "39                  0.341667              1.111004  \n",
              "40                  0.341667              1.111342  \n",
              "41                  0.341667              1.111572  \n",
              "42                  0.341667              1.111493  \n",
              "43                  0.341667              1.111902  \n",
              "44                  0.341667              1.112229  \n",
              "45                  0.341667              1.112259  \n",
              "46                  0.341667              1.112637  \n",
              "47                  0.341667              1.113060  \n",
              "48                  0.341667              1.112877  \n",
              "49                  0.341667              1.113252  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "D7zifELCJW6i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pandasの機能を使って、数値だけでなく可視化も行いましょう。\n",
        "Pandasのプロットでは、Maptlotlibをベースにしており、Jupyter Notebook上でインライン表示ができるように設定しておきましょう。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "wJfRVE3xJW6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r1pit2TjJW6i",
        "colab_type": "code",
        "outputId": "87adcab3-72ae-4342-e9d7-34a1ef60b019",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# accuracy（精度）を表示\n",
        "results[['main/accuracy', 'validation/main/accuracy']].plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd362734e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXl8XNV5x/09s2m0jlZbkiVb8oY3WZYt2xhjlhiCIYQ1\nFBKggRQIaRKgbd6EJCQhhaRNywtJGt4kpIWEBAIEwtKypQ64LN5tvNtg2ZItWbaWkTTSjJbZzvvH\nzB2NpFnuaJfnfD8fPnju3LlzJN37u899zu95jpBSolAoFIrkwDDRA1AoFArF+KFEX6FQKJIIJfoK\nhUKRRCjRVygUiiRCib5CoVAkEUr0FQqFIolQoq9QKBRJhBJ9hUKhSCKU6CsUCkUSYZroAQwmPz9f\nlpWVTfQwFAqFYkqxa9euVillQbz9Jp3ol5WVsXPnzokehkKhUEwphBAn9Oyn0jsKhUKRRCjRVygU\niiRCib5CoVAkEZMup68YOzweDw0NDfT29k70UBRJitVqpaSkBLPZPNFDSVqU6CcRDQ0NZGZmUlZW\nhhBiooejSDKklNjtdhoaGigvL5/o4SQtKr2TRPT29pKXl6cEXzEhCCHIy8tTT5oTjBL9JEMJvmIi\nUeffxKNEX6FIQlx9Xnrc3okehmICUKKvmBLs3LmTe+65R9e+d999Nx9++OEYj2hqc6qjh9MOlWZJ\nRtRErmJKUF1dTXV1ta59t27dyuOPPz7GI+rH6/ViMk2tS8nj9SNMKuZLRtRfXTFu1NXVsWDBAm67\n7Tbmz5/PzTffzMaNG1m7di3z5s1j+/btbN++nTVr1lBVVcV5553Hxx9/DMCmTZu48sorAXjwwQf5\n0pe+xEUXXcTs2bP5+c9/HvqOw4cPM3/+fIxGI7/5zW9YuXIllZWVXH/99XR3dwPQ1NTEtddeS2Vl\nJZWVlWzevBmAp59+mqVLl1JZWcmtt94KwG233caLL74YOn5GRkZoPOvWreOqq65i0aJFAFxzzTWs\nWLGCxYsX88QTT4Q+89Zbb7F8+XIqKytZv349fr+fefPm0dLSAoDf72fu3Lmh12ON1+/HJyU+vxyX\n71NMLqZWeKIYNX743wc51Ng5qsdcVJzFDz67OOY+NTU1/OlPf+LJJ59k5cqVPPvss3zwwQe89tpr\n/PjHP+bpp5/m/fffx2QysXHjRr7zne/w0ksvDTnOkSNHePfdd+nq6uKcc87hK1/5CmazmTfffJMN\nGzYAcN1113HnnXcC8MADD/Bf//VffP3rX+eee+7hwgsv5OWXX8bn8+F0Ojl48CAPP/wwmzdvJj8/\nn7a2trg/7+7duzlw4EDIfvjkk0+Sm5tLT08PK1eu5Prrr8fv93PnnXfy3nvvUV5eTltbGwaDgVtu\nuYVnnnmG++67j40bN1JZWUlBQdxeWaOCx+sHwCeV6CcjSvQV40p5eTkVFRUALF68mPXr1yOEoKKi\ngrq6OhwOB1/84hc5evQoQgg8Hk/E43zmM58hJSWFlJQUpk2bRlNTEyUlJbz99ts89dRTABw4cIAH\nHniAjo4OnE4nl112GQDvvPMOTz/9NABGoxGbzcbTTz/NDTfcQH5+PgC5ublxf5ZVq1YN8Jv//Oc/\n5+WXXwagvr6eo0eP0tLSwgUXXBDaTzvul770Ja6++mruu+8+nnzySW6//faEf5fDxe0LiL3PL5FS\nKkdNkqFEP0mJF5GPFSkpKaF/GwyG0GuDwYDX6+V73/seF198MS+//DJ1dXVcdNFFcY9jNBrxer10\nd3fT0dFBcXExEEjNvPLKK1RWVvLb3/6WTZs2JTxek8mE3x+IjP1+P263O/Reenp66N+bNm1i48aN\nbNmyhbS0NC666KKYfvTS0lKmT5/OO++8w/bt23nmmWcSHttw0SJ9CAi/yahEP5lQOX3FpMLhcDBj\nxgwAfvvb3yb02XfffZeLL7449Lqrq4uioiI8Hs8AUV2/fj2//OUvAfD5fDgcDj71qU/xpz/9Cbvd\nDhBK75SVlbFr1y4AXnvttahPHg6Hg5ycHNLS0jhy5Ahbt24F4Nxzz+W9996jtrZ2wHEB7rjjDm65\n5RZuuOEGjEZjQj/rSHD7wkRfpXiSDiX6iknFN7/5Tb797W9TVVWF15uYjzw8nw/w0EMPsXr1atau\nXcuCBQtC23/2s5/x7rvvUlFRwYoVKzh06BCLFy/mu9/9LhdeeCGVlZX84z/+IwB33nkn//d//0dl\nZSVbtmwZEN2Hs2HDBrxeLwsXLuT+++/n3HPPBaCgoIAnnniC6667jsrKSm688cbQZ6666iqcTue4\npnYAPL6Bkb4iyZBSxv0P2AB8DNQA98fY73pAAtWDts8EnMA34n3XihUrpGJsOHTo0EQPYUypqqqS\nbrd7ooehmx07dsjzzz9/3L/3kzOd8kBDh9xb3y47e8b/93W2n4fxcPS45bk/3ij/7+PmUT0usFPq\n0PO4kb4Qwgg8DlwOLAI+L4RYFGG/TOBeYFuEwzwKvJnoDUmhSITdu3dPme6N//qv/8r111/Pv/zL\nv4z7d3t8fqzmQDpJRfrjz0l7N6cdvfxx+8kJ+X496Z1VQI2U8riU0g08B1wdYb+HgJ8AA2avhBDX\nALXAwRGOVaE4a7j//vs5ceIE559//rh+r88v8folqRYl+hNFq7MPgHc/bqZ7Alph6BH9GUB92OuG\n4LYQQojlQKmU8vVB2zOAbwE/HOE4FQrFKKDl80ORvprIHXfszoADrNfj550jzeP+/SOeyBVCGAik\nb/4pwtsPAo9JKZ1xjnGXEGKnEGLneFUlKhTJiDto10wxGRBCqEh/AtAi/SyriTf2nx7379fj0z8F\nlIa9Lglu08gElgCbgkUehcBrQoirgNXA54QQ/wZkA34hRK+U8hfhXyClfAJ4AqC6ulqdhQrFGKFF\n+haTAaMS/QnB7nKTYjLw2cpi/rz7FN1uL2mW8SuZ0hPp7wDmCSHKhRAW4CbgNe1NKaVDSpkvpSyT\nUpYBW4GrpJQ7pZTrwrb/FPjxYMGfjJy0d3PJo//HaUdPQp97dttJ/v6ZXWM0KoVi5Lh9foQQmAwC\no0GJ/kTQ6uwjPyOFz1QU0ePxsenj8c1uxBV9KaUX+BrwNnAYeEFKeVAI8c/BaP6sY/OxVmqanRw+\nnVhvms3HWtl4uFmzqSpGiNbcrLGxkc997nMR97nooovYuXNnzOP89Kc/DTVbA7jiiivo6OgY9ri2\nbt0a6ukzEn71q1+F2kHEY8WKFfT19Y34Oz1ePxajQAgl+hOF3ekmP8PCqvJc8tItvD7OKR5dzxRS\nyjeANwZt+36UfS+Ksv3BBMc2YRxtDkxBtLsiV19Go6Pbg9vrp7PXiy11algHpwLFxcUDOl0myk9/\n+lNuueUW0tLSAHjjjTfifCI2g4vAhsvdd9+ta7/a2lpmzJgxoPXEcHH7JGZjINYzGgTesEKtcKZi\nu+ipgt3Vx7RMKyajgcuWFPLy7lP0uH0hR9VYoypyI/BJUxcA7d3uOHsOpM0V2L+la+QR2dnI/fff\nP6DP/YMPPsjDDz/M+vXrWb58ORUVFbz66qtDPldXV8eSJUsA6Onp4aabbmLhwoVce+219PT0p+C+\n8pWvUF1dzeLFi/nBD34ABJqgNTY2cvHFF4daNJSVldHa2grAo48+ypIlS1iyZAk//elPQ9+3cOFC\n7rzzThYvXsynP/3pAd/z17/+lUsuuYTf/va3XHPNNVx66aWUlZXxi1/8gkcffZSqqirOPffcUMuF\naC2eH3zwQR555BEg8MTyrW99i1WrVjF//nzef//90Pe99dZboZtMpJ8RYMeOHZx33nlUVlayatUq\nurq68Pl8fOMb32DJkiUsXbqU//iP/8Dt83PhisW0trZiNAj2frQr1N/owQcf5NZbb2Xt2rXceuut\n1NXVsW7dOpYvX87y5ctDLagBfvKTn1BRUUFlZSX3338/x44dY/ny5aH3jx49OuC1op/WLjd56RaA\nsBTP+Ll41K08AjXBSF8Tcb1oN4mWrj7mTssY9XGNKm/eD2f2j+4xCyvg8n+N+vaNN97Ifffdx1e/\n+lUAXnjhBd5++23uuecesrKyaG1t5dxzz+Wqq66K2vnxl7/8JWlpaRw+fJh9+/YNEJYf/ehH5Obm\n4vP5WL9+Pfv27eOee+7h0Ucf5d133w110NTYtWsXTz31FNu2bUNKyerVq7nwwgvJycnh6NGj/PGP\nf+Q3v/kNf/M3f8NLL73ELbfcQmtrK2azGZvNBgQ6eX700Uf09vYyd+5cfvKTn/DRRx/xD//wDzz9\n9NPcd999UVs8D8br9bJ9+3beeOMNfvjDH7Jx40YgIPqPPfZY1J9xwYIF3HjjjTz//POsXLmSzs5O\nUlNTeeKJJ6irq2PPnj2YTCZaW+009voh+Ks1GgS+QdmdQ4cO8cEHH5Camkp3dzf/+7//i9Vq5ejR\no3z+859n586dvPnmm7z66qts27aNtLQ02trayM3NxWazsWfPHpYtW8ZTTz017u0lpgJSSuyuPvIy\nAk9tq8tzyQ2meC6vKBqXMahIfxCdvZ7QMnLDjvSdKtKPRFVVFc3NzTQ2NrJ3715ycnIoLCzkO9/5\nDkuXLuWSSy7h1KlTNDU1RT3Ge++9xy233ALA0qVLWbp0aei9F154geXLl1NVVcXBgwc5dOhQzPF8\n8MEHXHvttaSnp5ORkcF1110XirDLy8tZtmwZEMin19XVAfCXv/yFT3/606FjXHzxxWRmZlJQUIDN\nZuOzn/0sQKhVNARuDOvWraOiooJnnnmGgwcj1yled911Q77P7XbT0NDA7Nmzo/6MH3/8MUVFRaxc\nuRKArKys0HoEX/7yl0NpmkxbNgAiqPpGIfAPyulfddVVpKamAuDxeLjzzjupqKjghhtuCP0+N27c\nyO233x5Kl2ntou+44w6eeuopfD4fzz//PF/4whdi/v6Tkc5eLx6fJD8jEOmbjAYuW1zIO0ea6fX4\nxmUMKtIfhBblQ2I5/R63j76gB3pKpHdiRORjyQ033MCLL77ImTNnuPHGG3nmmWdoaWlh165dmM1m\nysrKYrYkjkZtbS2PPPIIO3bsICcnh9tuu21Yx9EY3LpZS++8+eaboWZsg/eL1Coa9Ld41j6rtYoG\neP/990NVuyP9GbXumuZgu2ijQdDX10u47yC8odxjjz3G9OnT2bt3L36/H6vVGvP4119/PT/84Q/5\n1Kc+xYoVK8jLy9M9tmTBHgwI8zP6z5srKgr54/aTbPq4hQ1LCsd8DCrSH0RNU0D0i2xW2hKI9MP3\nnRKiP0HceOONPPfcc7z44ovccMMNOBwOpk2bhtls5t133+XEiRMxP3/BBRfw7LPPAoEIet++fQB0\ndnaSnp6OzWajqamJN9/sb/WUmZlJV1fXkGOtW7eOV155he7ublwuFy+//DLr1q2L+t1SSvbt2xd6\nAtBLtBbPenjrrbe4/PLLgeg/4znnnMPp06fZsWNH6Pu8Xi+XXnopv/71r0M3kOaWwDzGrLJZ7Nq1\nC6NB8Nc3/htJZAePw+GgqKgIg8HA73//e3y+QCR66aWX8tRTT4XmJrS5C6vVymWXXcZXvvIVldqJ\ngj2YDcgLRvoAa2bnkZNmHrdCLSX6g/ikqQur2UDFDBvtCeT0w/dVoh+dxYsX09XVxYwZMygqKuLm\nm29m586dVFRU8PTTTw9ogRyJr3zlKzidThYuXMj3v/99VqxYAUBlZSVVVVUsWLCAL3zhC6xduzb0\nmbvuuosNGzYM6LUPsHz5cm677TZWrVrF6tWrueOOO6iqqor63bt27aKqqirhlaaitXjWw6ZNm7jw\nwguB6D+jxWLh+eef5+tf/zqVlZVceuml9Pb2cscddzBz5szQur/PP/ccAsGDP/gB9957L+vXrcEQ\no4//3//93/O73/2OyspKjhw5EnoK2LBhA1dddRXV1dUsW7YsNBkNcPPNN2MwGAakwBT9tAa1IS+9\nP9LXUjx/Pdw0LikeMdk85dXV1TKe73os+eKT22l19rG0JJv/PXSGnQ9cqutz733Swt8+uR2DgLVz\n8/n9360e45EmzuHDh1m4cOFED2PK8vDDDzN37lxuuummcfm+hoYG7rzzzgFPLSOhvq0bV5+XBUVZ\nADj7vBxvcVKen06mdXQsxo888ggOh4OHHnoo6j5n03lod/ZhMhiwpen7/f1+6wm+98oBtn9nPdOy\n+tNlmn78+tYVXLZ4eCkeIcQuKWV1vP1UTn8QR5u6WD07j9x0M+3dHt1riGqTvmV56SrSP0t54IEH\nxvX7SkpKRk3wIdB3x2zqf7g3Bs/r0SrQuvbaazl27BjvvPPOqBxvsuP3S/7m11uYNy2TX926Qtdn\ntJx+TrplwPY1c/LIDqZ4hiv6elGiH0ZXr4dGRy9zp2WQYjLg80vdhVZaemf+9Ex2nmiLs7dCMf64\nfX4yUvoveaMhKPqj9LSvLQqfLGz6pJljLS5MBv1ZcrvTTXaaOVQgp2E2GrhsUSGv7z9Nr8cX6oI6\nFqicfhiac2f+9Exyg3divXn9tm4PQsDcaRnYXe6olY4TzWRL5ynGB7+UeH3+AWITEv1xbMVwNp1/\nT31YB8CZTv0OKrurb4BzJ5wrlhbh7PPy/tHW0RheVJToh6G1X5g3LYOctIDo63XwtLvc2FLNTLdZ\nkTLxwq7xwGq1Yrfbz6oLT6EPr8+PBCym/lSlQQQ8++Ml+lJK7HZ7XOvnVOBoUxfvH20lPyMFR49H\n92Iorc7+atzBnDcnD1vq2Lt4VHonjJpmJykmA6W5aXT0BDz6+iN9N7lpFgqCd/Hmrr4BEzXjSVev\nhz31HaybVzBge0lJCQ0NDQxnzQK3N+Dr1qJDPUgJfd6xfVTVS6/HF+ohn4z0eXy0ON342yw0hf09\nWjp66LIY6UiLLESjjdVqpaSkJPS6ubOX5q4+lsywjcv3jxZPba7DYjJw94Wzefj1w5xx9DK7IH4V\nfquzj4WFWRHfMxsNfHrRdN46cIY+r48U09hcN0r0w/ikqYs5BRkYDYLc4EXQ3q2vQKuj201OuoWC\nzIDoT2RV7rde2scb+8/w/jcvpjQ3LbTdbDZTXl6e8PF6PT6W/fNf+NyKEh6+pkL359450sSXnt3J\nC19ew6ry3IS/d7Q4ae/m8n9/l+9esZA7L5g9YeOYSF7c1cA3XtvLpm9cRFl+fwHWVx/ZxMLiLB7/\nwvi7adxePzf/5zZOtHXz1r3rdInmZKCj282fdzdwzbJiFhcHblZ6Rd/udA/w6A/m0kXT+dOuBvY3\nOKguG5trRqV3wjja5GTe9MAfLic9MHmrO9J3echJszBNE/0JcvD89XATb+w/A8CWY/ZROebuk+30\nevx8cibmAmhDOHImUBB1sq07zp5jy8fBBnofHhvbXOlkpqE98Dcoyh749JmVaqazJ7FusqPFb94/\nztFmJwJ44JUDUybt+NyOeno9fm5fW06hLfD71JPXd3v9OHo8Azz6gykP3pBPdSS2lkciKNEP4urz\ncqqjh/nTMwHISDFhMoiEcvo5aebQJM1EiH6328v3Xz3IvGkZ5GdY2DxKIqfdPGpaEhN9bWK8cQxP\n4ETGsb22LbRyVLJxqr2H6VkpQ1IGtlQzjgkQ/bpWFz//61GuqCjke1cuYvMxOy9/dCr+BycYr8/P\n05vrOHd2LguLsigMpnC1fl2x0Gzd+ZnRI/2i7EDfo8aO4bcQiYcS/SCaMGjdMYUQ5KRbdEX6UspA\nTj/dQqrFSGaKaUJE/6cbj3Kqo4cfX1fBmjn5bDk+OpO2m4Oi3+Zyh3zGepgson+0ORDpd7t97Gtw\nTOhYJopTHT3MCApKOBMh+lJKvvfqAcxGAz/47GK+sGomVTOzefj1wwlVwU8EfznURKOjl9vXBtKk\nqRYj2WlmzugQfW1t3FiRfkaKCVuqeUyvGSX6QbQe+vPCWiLnpll0ddrs8fhwe/2hgouCzJRxz+kf\nbHTwXx/U8vlVpawsy2XN7DyaOvs43uoa0XFdfV721newuDgw+RTekC4WUkqOBfcdy0dVPRxrdrIw\nWIW6JUlTPA3tPczISRuyfSJE/9U9jbx/tJVvbjiH6VlWDAbBv1xXQWePhx+/cXhcx5IoT31YS2lu\nKpcsnB7aVphl1RXptzqDkX6MnD5AcXaqEv3xoKbZicVkYGbYxGdOullXp03NnqlN/hZkpoxrpO/z\nS77z5/3kpJm5f0NgQu68OYEOh5tHmNffUdeG1y/52zWzAP0pntOOXlzuQB+RiYz0pZQca3GxqiyH\nhUVZI/59TEX8fslpRw8lOZEj/c4ez5AWy2NFR7ebh/7nEMtKs7l59azQ9gWFWdx5wWz+tKth1Oai\nRpsDpxzsqGvni2vKBrjYCm1WmnTk9LWn5LwoPn2NGdlWldMfD442O5mdn44prHglN92iK6ev3Riy\ng/03CjJTQo2VxoM/bD3B3gYH37tyUagHyKy8NIpsVraO8ALactyO2Sj4bGUxaRaj7khf229xcRaN\nHb0TNkl3prMXZ5+XudMyWDM7j10n2setb/lkobmrD49PRk3v+CU4dfrMR8q/vnmEjh4PP762Yoj9\n955PzaM0N5XvvrKfPu/k+xs9+WEtaRYjN1SXDtheZNMX6dudQztsRkJF+uPEJ01doUlcjew0fTl9\n7caQmz7+kf4ZRy///vbHrJuXz1WVxaHtQgjWzMljy3H7iKK4LcfsVJXmkGYxMacgI2HRv3B+AT0e\nHx06ra+jjTaOOdMyOG9OHn1ePx+dHP6i6FMRzbkzI0qkD+AYh7/P9to2nttRzx3nl7OoeKhXPdVi\n5KGrl3C8xcWvNh0f8/EkQktXH/+z9zSfW1EypC1LYVYqrc4+3N7YJoFWVx8Wo4HMlNhO+eLsVDp7\nvXT1js3fRIk+AddLQ3vPgHw+BNI1HToefTuCoh+e0+/q89LjHvto5Yf/fRCPz8/D1ywZUni0ZnYe\nbS43nzQP7SWvB0ePhwOnHKwJpormTtMv+kebnWSnmakIFt1MVF7/aFP/BP2q2bkYRODpJZnQfvel\nEUQ/SxP9Mc7ru71+vvPyfmZkp3LvJfOi7nfROdP4bGUxj79bw/EE3WJjyTPbTuD2+fnieWVD3iu0\naQWZsaN9u9NNfoYlboGg9kSm5+lhOCjRpz8anDco0s9Jt+DzS7p6Yz/6DsnpB3N2rWM8mbvxUBNv\nHjjDPevnMSsvfcj7mlhvrhmeyG2vbcMvGSD6px2BdEk8jjU7mVuQEYouJyqvX9PixJZqpiAjhSxr\n4CaUbJO5De2B331xlPQOMOZe/V//3zFqmp08fM0S0iyxI93vXbkQq9nAd1+eHN59t9fPH7ae5KJz\nCpgToQCr0Bb4vcZz8LQ6++Lm86H/7zRWgdJZLfpur59XPjpFXRwHixYNaoVZGrnBAq14ef12lxsh\n+qMmrSq3WWeK571PWqhPsIAp4Mk/wDnTM7krSpVpSU4aM3PThh3Zbj7WSorJQNXMwNqqmp31mI5o\nv6bFydxpGaETOBHRr2t18T/7GkfFU1/THBiHFl2tmZPPnvoO3b1SxgspJS/tahiTNEtDew+56ZaI\nYmtLMNJ/dc8pXTf9cOpaXfzHuzV8ZmkRFy+YFnf/aZlW7r98IVuO23lp98R791/f30irsy9k0xxM\nkU2fVz9eNa7GjGFcM385eEb3vmel6Pv9klc+OsX6Rzdx3/N7+Paf98fc/5PmLixGA7NyB1rasrWm\na3Hy+m3dbrJTzaGJqYIEqnL9fsldv9/JY//7Sdx9w3n3SAuNjl6+d+WiIW1awzlvTh5bj9uH1VRr\nyzE71WU5oYIeTfTjpXjaXG7aXG7mTssgL92CxWSgMYFH1cc2fsLXnv2Iyx57j9f3nR7RnIT2xKGx\nZk4eHp9kZ137sI85Fmw5buef/rSXn/316Kgf+1RHZOcOEJr41yP6J+wu7n1uD3/cdjKh739xVwM+\nv+QHVy7S/ZmbVpayqCiL32+NvXzmeLDxUDMzslO5YF5+xPdDVblxRb8vpkdfoyAzBZNBJCT6iRS2\nnVWiL6Xk3SPNXPHz97nv+T1kpJi5tmoGW47bOXy6M+rnapqczC4Y6NyB/nRNR7xIv9szYFGERPrv\nNDp66PX42dOQ2OTi3oYOLEZD3J42a+bk0dXr5VBj9J8/EnZnH0fOdHHenP4TfVZuGmajCHUjjUZ4\noZsQghnZqQk9qh5vcQX/HoKvPrubqx//kPePtiT8qN/mcmMP3nw0VpblYDKISZfXf3FXAwB/2lmf\ncCQdj4b27ojOHUgs0tf+hsM5V8+ZnplQA0KDQbBufj6HGzsn3MlzvNXF/OkZUXPxmSkm0izGmK0Y\npJS0utxxPfoQaHldaLMmVJVbm0A9zlkj+rtOtHHjr7dy+2930O328bOblvH618/nB59dhNVs4LfB\n3teROBpMAQxGc+PEi/TbXe7QDQICFXcGoS/Sr2sNpHWOt7joTGC2fm99B4uKs7CYYv8J18zW/PqJ\n5bG3Hg8sBKPl8yGwlmdZXnrcSF+rgNV+p8XZVt1Ri5SSulYX58/N5817L+D/vaGSNpebW/9rOzf/\n5zb21OsXnNDNJyxtl2Yxsaw0e1L59Z19Xt7cf4bK0my6+ry8uLN+1I4tpaQxSjUuQLrFiNEgdIm+\nFsnuS0D0pZTsre+gsjRb92c0qkqzcfv8HEwwYBlNpJScsLsGNKkbjBABkY4V6Tv7vLi9/qi99AdT\nnJ3KqXb918wJu/708Fkh+v/+9hGu/+UWjre6eOjqxWz8xwu5etkMDAZBdpqFa6tKeGXPqYji3eP2\nUd/ePcSuCf1unHhVuW0u94BI32gQ5Kbrs23W2vvv0Pt1tgjw+SX7TzmoLInfjnZalpW50zISFrkt\nx1tJtxhD7huNedMzOBbHVVHT7CTVbKQ4OMFVbNPvO7a73HT1eSnLS8doEFy/ooR3vnEh379yEUfO\ndHHN4x/yc50pkJDoD5p8O29OHvsbOhK6yQ7mhZ31fPvP+0ZlovGN/afp8fj4/pWLWFaaze+2nBi1\nYim7y02vxx81vSOE0F2Vq+Ws69t6dLfjqLN309nr1XWuDqZqZg4AexKw2Lr6vNzyn9vYNUqr1zV3\n9dHt9oWTApvbAAAgAElEQVQaoUUj4NWPfo7r9ehrJPJ03NTZR08CtSdTXvT9fskz2wIz6+998yJu\nXVM2JPq9fW0ZfV4/f9w+NBd5rMWJlAyxa0IgCjIbBW1xqnLbuwPN1sIJePXjP57VtbqwBNNKe3VG\nUMdanHS7fSwt0Rc9rZmdx466xJqNbT5mZ1V57pD5grkFGZywu2I+ctc0O5kzLR1DcI6jODuV5q74\nPmYgNOkefpGlmIx86fxy3vvmxaydm8cftp7QJbbazWdwlHvunDz8EnbUDk8Yzjh6+cGrB/nj9npe\nH4UFL17c1cDs/HSWz8zm9rVl1La62PRJ84iPC/3OnUgtGDT0in541em+U/oCFO2pQO+5Gs70LCtF\nNisfJfB0t63Wzgc1rXz35QOjsjiMljYpi+COC2d6VuxIv1VnNa5GcbaVM529un6GRFI7cBaI/ifN\nXXR0e7hyaXFUK9j86ZmcPzef3285MUT4Qj13pg8VfSEEOXEKtKSUtLs8QxY61lugVdcayF/Pyktj\nr86TW0tx6H1kPm9OXrDZmL7jN3X2crzFNSC1ozFnWgZ+GftEO9bsZN60/ienGdmpSImuUvXQRRYh\nsspIMXH5kiKau/p0Pc7WtATmagyDKj+Xz8zBYjIMO8XzyF8+xueXzM5P51/fPDKiCt8Tdhfba9u4\nfkUJQgiuqChielZKaCm+kaKlCKKldyDgOtMb6ZfkpCIECZ2rVrOB+RGuLz1UzcxmT73+SfdtwRv5\nkTNd/GkU0mSRgpBIFNmsNHf1RRVpre9OtFWzBlOcnYrPL+N6/wHq7GMg+kKIDUKIj4UQNUKI+2Ps\nd70QQgohqoOvLxVC7BJC7A/+/1MJjU4H24K559VxJjRvX1vGmc5e3jww0Np0tNmJ2Sgi+twhkNeP\nld7pdvtw+/wDcvoQ8OrrTe+U5aVTWZKtuwPkvoYOMlNMzI5zImqsDub19fY00fYLn8TViOfgcfZ5\nQ4vLayTiO66zuzAaRNR0hPZ33lYb/2c5FmWuxmo2smJmzrB6vBw45eCl3Q3cfn4ZD12zhIb2Hn67\nuS7h42i8tKsBg4DrlwdWkzIbDdx67izeP9rK0abhFdWFc6ojejWuhk1nT/0zjl7mFGQwtyAjgXPV\nwZJi2xCThF6WlWZT39aju+Zl2/E2VszKoXpWDo/85ZMRT4rX2gNP4pFqHMIptKXi9cuoaS+7K7A9\nkZw+6LNthmcL9BB3TyGEEXgcuBxYBHxeCDHEeyWEyATuBbaFbW4FPiulrAC+CPxe98h0sq3WTrHN\nGlUkNC4+ZxpleWk89WHtgO1Hm7ooz0+PanvMidNpU5sniBjpO/tipiG8Pj/1bd2U5aeztMTGaUcv\nzTqi4b31DipKbEMi2GjkplsSaja2+VgrtlRzqDNlOHMKMhAiuuhrHv7wIpbi4MIdeiam6lq7Kc1J\njfr30Gyg2s0+Gtr6CJHSdhB4+jl0ujOhVr5SSh76n0PkpFn46sVzWTs3n0sWTuMX79QMqxDP75e8\ntPsU588rCNn+AD6/aiYWk4GnRnAz0Who7yHTahrSOiCcRHL6RTYrlaXZ7K3viJti8/j8HDjlGNYk\nrkYieX1Xn5f9pxysLs/lgSsX0ers45ebaob93RAQ1NLc1LjLhBbF6auv5fRzdUb6M0KBkr6n45l5\n0dN3g9Fze1gF1Egpj0sp3cBzwNUR9nsI+AkQGqWU8iMpZWPw5UEgVQih71anAykl22vbWD07L25p\ns8Eg+OJ5ZXx0smOAA+Ros3NIJW44uemWmO4d7YaQMzjSz0zB45MxL6bGjl48Pkl5fhrLghfG3jgR\nVJ/Xx5EznQnnSBNpNrbluJ3V5bkRT3Sr2UhpTlpU0R+8LgEkGLXocEqsKs8NPcZHQ5tsjhTpA5w3\nN/D0o+eJQeMvh5rYVtvGP1w6nyxrQES/fcVCej2+hOssALYet3Oqo4fPrSgZsD0vI4VrlhXz590N\nce3C8TjVHt25o2FLNcUVfbfXj93VR6HNSmWJDbvLHffJ7ZOmLvq8fpYOYxJXY0mxDaNB6HJt7T7Z\njs8vWT07j2Wl2VyzrJjfvF8b6j00HOpau+OmdqDfqx9d9PuwpZrjuu00tIIv3ddMnDmHcPSMYAYQ\nnhxrCG4LIYRYDpRKKV+PcZzrgd1SylHrTXCsxUWr0x03taPxuRUlZKSYQtF+r8fHybbuqNEgBDpn\nxlonN9SCIX3oRC7Etm1qzp2yvHQWB0/ueHn3w6e78Phkwm4Ivc3G6tu6qW/rCbVmjkSsHjw1LU5M\nBsGssMjDajaSl26hMYa7AfrtmvFO4NXluZzq6Il5MUe6+YSztCSbNItR99OP2+vnX944zLxpGXx+\nZX+XxTkFGdxy7iz+uP1kaH5ILy/uaiDTauLTi6YPee/2teX0evw8t2NkeelAYVbsKNCWaqaz1xsz\ncm/u6kXKgBhpAUe8FI/2fuUwJnE1Ui1GFhZl8pGOvP62420YDYIVswJPB//PhgUI4N/f/nhY3+33\nS92Cqol+tHmrVp3VuBqZVjNZVlNc0ff7A3bN8vzRjfRjIoQwAI8C/xRjn8UEngK+HOX9u4QQO4UQ\nO1taWnR/txal6V10O9Nq5obqEl7fd5qmzl5qmgPOnUh2TY3cdAsd3e6oFjqte+SQSF/Hsonhk0Sp\nFiPzp2fGjWj2JjiJqxFqNhbHr68VLa2JkM/XmDstg+OtroiTVjXNzojpsuLs1LiPqi3OPlw67HGr\nyoNReowUT02zdvOJfCyz0cDKslzdov/7rSeos3fz3c8sHJKfvnf9PDJSTDz8uv4FQLp6Pbxx4DSf\nrSzGajYOeX9hURbnzs7l6c11eIfZjkJKSUN79GpcDVuqGZ9fxsx/a86U6VlWFhRlYjEa4k7m7q3v\nwJZqHhAADIdlpdnsrXfEdbJsq7WzpDiLjGAXyxnZqdx1wWxe3dPIRycTr8A+09lLn9cf88lTIzfN\ngsVoiBrptzr7yNdRjRuOnhbLpxMYo4Ye0T8FhDeQLglu08gElgCbhBB1wLnAa2GTuSXAy8DfSimP\nRfoCKeUTUspqKWV1QUGB7sFvO95GQWaKrscvjdvOK8MnJX/YeqK/0VqMSD8nzYJfEtXT3R/pD03v\nQOyq3NpWF+kWY2jfyhIb+xocMSOuvQ0d5GekhB7/9BJqNhanEnXLMTt56ZaYbou5BRm4vf6I/YKi\nTZ7O0HECa4Vq8U7gBYWZ2FLNMVMzNc1OymLM1UCg8Kym2RnXIdHucvOzjZ9wwfwCLjpnaO+YnHQL\n96yfx3uftLDpY31Wyzf2n6bX4x+S2gnn9rXlNDp6+cuhJl3HHExnjxdnn1dHeid+Va5WbVpkSyXF\nFIi+41mM9zY4WFpii5t6jUdVaQ7OPm/M+pBej4+99Y6QaUHj7gvnUJCZwsOvH064pkKvcwcC6eNp\nWSmcifI0a3clFumD5tWPfW6GxjjK6Z0dwDwhRLkQwgLcBLymvSmldEgp86WUZVLKMmArcJWUcqcQ\nIht4HbhfSvmh7lHpIJTPL89N6KSalZfO+gXTeHbbSfafcsSMBiF+VW57txuDIJTj1dCT3qmzu5iV\nlx4a/9KSbBw9nph2xL31HSwrHd6FFK/ZmJSSzcdaWTMn9hzJnCgOnj6vjzq7K6Loa1FLrAtP7wls\nMAhWluWyPUZev2ZQz51IaCmseC6en/31KM4+L9+9YmHUff52TRlleWn86PXDuiLzF3c1MLsgnaoY\nT2yXLJxOaW7qEPOBXhqCzp14kb527sYU/WAEq6UxKkuz2d8QPfrucfv4pKkrNFc1EpYFG/7Fmsz9\n6GQHbp9/SKo3PcXENz49n10n2hOuqQilX3UGlbEWU7E7+xIWfT2RfiyLczTiir6U0gt8DXgbOAy8\nIKU8KIT4ZyHEVXE+/jVgLvB9IcSe4H/x2+zp4GRbN2c6e4fc2fVw+9py7C43z247SXl+eszJFW01\nrGgOnjaXm+w0yxAnTZbVhMVkiJveCY8iKksDefpoEVRXr4fjra5hFbpA/GZjta0umjr7IvrzwwnZ\nNgdFXnWt3fhl5Dx6cbaVbrcvprDU2l2YjSLk9onFubNzqbN3R8yhur1+TrR1R83naywutpFpNbE1\nxtPPsRYnf9h6gptWzeScwuhpQIvJwP2XL+RoszNuHr6u1cWOunZuWFEa8+ZqNAi+uKaMHXXtHNBZ\nDBVOf2HWyCP9045e0ixGsqyB1MnSkmxcbl/UnvcHGwM3hOGeq+GU56VjSzXHzOtvq7UjBFSXDU31\nfm5FKQsKMxOuqahrdZFiMoScOfEotKVGPB+9Pj/t3R7ddk2N4uxUHD2emGk3bYyFifQ10rOTlPIN\nKeV8KeUcKeWPgtu+L6V8LcK+F0kpdwb//bCUMl1KuSzsv1EpNdTrz4/EeXPyOGd6Jj0eX8SirHC0\nSD/aWrkd3Z4h1bgQcJnE8up7fH7q23soC5uAmT89kxSTIeoE2f5TDqRk2G4IrdlYtDz25hj+/HBs\nqWamZaaEWlJr1ESwa2rM0OHVr2t1UZqTpsvTrc3jRBLsOntgviGe6BsNgtXleTHz+v/yxhGsZiP/\neOn8uGO6bPF0Vpfn8tj/fhKzxcNLuwPe/GurZkTdR+OG6lLSLEaeHEa0r6cwC/pbgsfy6p9x9FKY\nZQ3dpJaFApTI5+re0CTu8J07GgaDoLI0O6YJYdvxNhYWZkW0phoNgu9duSjhmoo6ezez8tJ0W6O1\nSH/w06yWJdBbjauhBT+nY10zdldCYwSIvZrBJGZrrZ3cdEvMfHw0hBDctraMb/95/4DK0UhoE7TR\neuq3udxRvbeaVz8SDe09+PxygDPAbDSwZIYt6gTZ3vqRuSG0ZmMv7KznYOPQi/VYs5PCLCtlOibe\n5k7LGBLp1zQ7ESKy6PfbNntZXBxZCGpbY9s1w1lUFJiw21bbxtXLBopnPOdOOGvm5LHxcBO3/Oc2\nBgfdPr9k8zE739qwQFeUJkRAXD77iw/4x+f3cPeFc1gxK2dANO/3B/rmrxvkzY+GLdXM51aU8Nz2\nepbPzOEzFUVDakIGI6XkYGMnGw83kWo2xvWG683ph493dn4GGSkm9tZ3RJyX2FvfQZHNmlBnzVhU\nlWbzH+8cxdXnJX3QcoNur5/dJ9v5wuqZUT8fXlNxY3Vp3N8hDH0Sj8f0LCt9Xn8gEAw7vlaNm6/T\no68RHihFs5XXtroiXm+xmLJtGLbXtrGqLLF8fjjXVs3gmmXFXF5RGHO//kg/ek4/Oy2G6EeJ9KNN\nEi0tsXGg0RExL7yvoYOZuWm6TthofOn8cmblpeHs8w75b7rNyt0Xztb1O507LYNjzc4BUU1Ni5OS\nnFRSLUPdKPG8+lqnQL1+Y5PRQHVZTsS8fqybz2CuqChkzew8XO6hv48ej49rlhVz+9oyXWMCWDLD\nxn3r5/NBTSuf+9UW1v3bu/z720dC1bVbjttpdPTGnMAdzJcvnMPsgnQeeOUAK3+0kTt+t4PX9jYO\nWY6zvq2bX7xzlEsfe48r/+MDtte2cePK2Ckk0NdT/4xjoOgbDIIlM7KiWoz3NXSMyJ8/mGUzs/HL\nyDbRfQ0d9Hn9rC6PnZb8+4vn4uzz6nJs+f2SE236PPoamrlicItlrRo38Ui/P1CKhM8vqW/rSWiM\nMEUj/YBHu4e/Oz/ySjZ6sJqN/PSmqrj7pVmMWIyGmJF+tMi7IDOF3Sei589h6ATMstJsnvqwjk+a\nnEMWj95b38GKCDnLRLiioogrKopGdAwIiL6zz0tTZ19IDGJNnoYWU4ki+lqnwET8xqvKc9n08ccB\nO1zYBXW02cmM7Mg3n8EU2VL5413n6v5OPdx7yTz+bl05bx84wyt7TvHLTcd4/N1jLCrKwmgQZFpN\nXBrBmx+NGdmpvHnvOg6d7uTVPY28tqeRjYebSbcYuWxxIQuLsnjzwGl2B9Mfq8py+dG1S7hiSfyn\nAoAMiwmDiC76Pr+kqbN3iGOssjSbJz+opc/rCy20A4H1J+rs3fzNytLBhxo2y4LX2Ef17UPmnLRC\nvXjW7SXFNiwmA3vq2/nM0tjXQKOjB3eCVsjwxVTCq9kT7bCpMT3LitEgQq00hoyxowe3L7ExwhQV\n/W3HE/PnjwQhBDnpZjoi5PSllEMe5cIpyEihrduNx+cfYh2ss7vITDENacDUX/jSMUD0W7r6aHT0\n8qVRjJ5GgibuNc1OCm1WfH7JsRYn58+NHG0ZDIJimzVqTn84LgQtstte2zbgRlYTxTY6nmSkmLh+\nRQnXryihpauP/9nXyCt7Gtlb38Ft55VF9ObHQgjB4mIbi4ttfGvDArbV2nn1o0beOHCaP390inOm\nZ/LNDedwVWVx3GKswRgMImbTNbuzD69fDpksrCzJxuOTHDndNaBuZDSKsgaTk26hPD89ooNnW20b\n86dnxE1jWUwGlhRnxS1QhDD7cAJWyGjLJmotOhL16RsNgsKs6Iup1Nn1dQAdzBQV/TayrCYWFA7t\nDTMW5KRZIkb6Lq3ZWnrkviYFmSlIGXgamD7ogtHy14Mfvcvy0siymtjb4OCmVf3btcfokfQxGU20\nhUmONndx/rx8Gtq7cXv9McU2lgVtOCfw0hIbqWbjANH3+SXHW5ysjeNAGk8KMlO4fW05t68t54yj\nl5wo54tejAbBeXPyOW9OPj+8ejEtXX2U5o6sACrQfyeyS0RLV2gLgGto5+K+ho5Boh84VytGOUBZ\nVprNBzWtSClD143X52dXXRvXLdeXLquamcMftp6IGIiFo9k1E0mdFGQEFk8a7NW3u9yYjYKs1MTl\nNlZf/UTqCMKZkjn97XVtrIrSG2YsyE2P3F5Z2xYrpw+RvfrReswIIUINrcLZW9+BQcDi4vG50cWj\nICOFLKspNGnaP3kafWI8IPpRopZWfd0MwzEbDayYlTPAwXOqvYc+rz+uK2uiKLRZB6RCRorVbByx\n4EPspmta5Do4vVNss5KfYWFP/cA8+556B7ML0ofUroyUqpnZoSdejQONnbjcPlbP1vfUv6w0mz6v\nnyOnY7fMqGt1kWo2Mj1Lf3RuMhooyEwZktNv7QqsjTuc+cdYq87VtnYnPEaYgqLf3NlLbasr7qTN\naBIt0g9V4yYo+m6vn1PtPZRHccksLbHxcVPXAE/x3gYH86dnRl0zYLwRQgzowaPHMVOcnUpTV2/E\nxVy0ToGJ3shXlefycVNXqDFZTcvApRoV+ogl+oMLszSEECwtyR4wmSulZG9Dx6imdjS0Qq/wlgrb\nE2zFUqUVesXp5VPXGrBCJirUhbbUIemd4VTjahRnp3LGEXkxFc2umegYp5zob9U5aTOa5KSbQz12\nwgl12IySS5wWRfRPtgWKmKLlrytLsvH5ZchWOZYX0kiYO61/6cSaZicFmSkxW/jOyLYiJRFXGEq0\nU6DG6vJcpCTk4tFqB+YWxLbiKgaSlWqmK0akbzaKiMFNZUk2NS3OUAHRmc5eWrr6RsWfP5gFhVmk\nmAwD8vrbjrcxOz+daZn6rKEzslPJz0iJm9evtSdm19QozEoZcn4HqnGH11y4ODvQpz9itiBBS6nG\nlBP97bV2MlJM45rmyE0LNF0bfLfVRD/aBJLmKBns1a+LM2mp5Uc1X359Ww8d3R6Wlk6OSVyNudMy\naHW6aXe5A4vLx7FIRrNtDqdToEZlaTYWkyEk+jXNTvIzUkI2RIU+YkX6TZ29TM+yRiwAWlpqQ8r+\n9Z21c3bpGMw9WUyBOhZt+USfX7K9rk13agcCTyeB1biii374OheJUmRLHSL6rU53wh59jWhFjV6f\nn5PDHOOUE31tZZzhrsQzHHLSg03XBl0U2tq5kSpyIZBvzbKahtyltUnLaD1mpmdZKcyyhtox7NEm\ncSdZpK8VttW0OANLJMbJo4dEf9BE13A6BWpYzUaWlWaHbHs1LU7mTkv8OMmOJvqReiOddvREbfCn\nnZPaubq3oQOTQbAowgI8o0FVaTYHTjlwe/0cPt1JV6834af+ZaXZHG91RV2rQFvnQk+R4mAKbVa6\ngnUeEHhKt7sS77ujES1QOtXRg9cvE2q0pjGlRN/u7ONoszOhO/toEGq6NugkaXdFbrYWTkFmypAu\njrWtLrKsplBfn0gsDXbcBNhX30GKyRCz98tEoOXNN9fY6erzxs2jF9siF5sMp1NgOOeW53Kw0UFn\nr4eaQevzKvRhSzXj9Uu63UN70wQKsyJPsOemWyjNTQ3l9fc1dLCgKDNhS6pels0MTsSe6Qw93SU6\nv9ef148c7dcO0woJYQVawWjf5fbR6/En3HdHQ2vFMFj0h2Nx1phSot//Rx5f0dfcOYMdPG3dbnIi\nNFsLJ1JVbl0wXxhrAqayNJvaVheObg/7GhwsKs6KaTGbCGZkp2I1G3jrYGDd4XjpnVRLoCXA4EfV\nkZzAEFgD2C/hrf1n6OqNf/NRDCVaKwYpJacdvRTGcIgsLQn0u/f7JfsaHKPSZC0aoeUT6zvYVmun\nNDc1IccXBMYrBFHz+sO1QgIha7Ym+tqaucPN6WdazWRGWEylP0Wc+NPI5FKROGyrbcNqNlAxY3zT\nHNoE1uAVtDq63XErHgsyrUNFvzV+Lq4yrAJx/ynHpEvtQKCoZ3Z+BodPdwL6HDORLGjD6RQYzvKZ\ngUZyz2w7oXscioFEE31Hj4c+rz9qpA+BatlTHT3sPNFOV683VD07FhTbrKFK90Br9cRdfBkpJs6J\nsWDR4HUuEqG/QCtwjrcOsxo3nEh99evs3YExDuNmMuVEf8WsHN3rTI4WWjHNkEjf5Y6az9cY3Gmz\n1+Oj0dET99FRK2x5afcpejy+UNvlyYYmsJlWk66LpNg2tEBLc+4k0ikwnFSLkaUltlBnRyX6iRNN\n9KN59MPReuz8fmvgpjuWhgMhBFWl2fzlUBPt3Z5hu/iWlQYmcyPNYQxe5yIRtEhfa7FsH2Y1bjiR\nihqjFXfqYcqIvqPbw5EznawqG/9Ky+g5fc+QZRIHU5CZgsvtwxWc2Klv60bK+I+OtlQzs/PTeTO4\n8MNkjPShf9WxedMydJ2AxdmpnGofuJhK4AQeWYGRtq5CptUUssoq9BNN9KN59MNZMsOGQcCb+0+T\nZjGO+ZzKspnZobmHc4dZr1M1M7BgkZZaDGe4VkgIGAty0syhm6XdNfJIvzjbOsT8EK24Uw9TRvS3\n17UhJeM+iQuQajZiMRki5vTj9fvQol+t/0Yi+eulJTa8fkmm1TSsSaXxQIuq9UbXM7JTcbl9dAZL\n/rVOgcM9gTW0eZ65Om8+ioFEFX2tBUOM1Ft6iol50zLx+iVLim1jXilfVRrI6xfZrJTmJpbP11gW\nPMbgvH6kdS4SpTDMttnapeX0RyL6qXR0e0KBo8fnp6G9Z9jGh6kj+rV2LEbDqCy/lihCBApTwlfP\nCjRb05PTH1igFc+uGY7m168syR526mOs0WyaekW/eJDvWOsUONwTWGPFrByMBhF3MlkRmWgLqZx2\n9GIQxE3daenH8UhDLi0JPFmsSnCp1HDmTgusBzA4rx9pnYtECV820e5yk2k1jaj1hubV1+YJ6tu6\nA2M82yP9XSfaWVpiGzMrWDxy0i0hXz6As8+Lxyd15fShX/RrW7vJSTPrKh7SXBCj2Zd8tJlTkMGP\nr63ghhX62ugOtqCN1LmjkWk18/Obqrj7ojkjOk6ykpliQkRor3zG0UNBZkpc51j/uTr2QVl6iomf\nf76Ke9fPG/YxjAbB0hLbENEfiXNHo9BmDeX0B7f9Hg79gVLgmKHAcZhPI1NC9Hs9Pg6c6mTFrJwJ\nG0NuunlApN8eKszSGekH0zt1CawOVTHDxt9Ul3Dd8vjL6k0UQgi+sHqm7oVdZgwq0KobRjfDaHxm\naVHCqwgpAhgMgizr0Krc0zE8+uF8evF0rl5WzAXzC8ZqiAO4cmkxs0f4t66amc3h050DelyNRhBS\nmGXF7nLT6/Fhd7qHtE9PlJDot2uBUuJtn8OZEqJ/sNGB2+dn+QSKfnbawE6bbXFaMGjkplswiIHp\nHb2pDIvJwL99rjJm58qpRn5GChajIZTeqW11kWYxqsnXSUCkVgxNnbE9+hrTMq387KaqmL2XJhvL\nSnPw+uWAReejrXORCNqkd3Nn34iqcTWmZwZaNmtPx3WtLjKtprjaE40pIfq7TwQewZbPnMBIf1BO\nP16zNQ2jQZAXtG32uH2cdvSOOJUxlTEYBEXZ/QtDBLoZDs96phhdIon+aUcvRToi/alIf9fO/hTP\nSKyQGuHLJtqd7mEXZmmYjIbgYir9T8fxijtjMSVEf9eJdmbmpg2rWGK0yEm30NHjCTVd06L+eOkd\n6Pfqn2gbnfz1VCfcq183zEZritFnsOg7+7x09Xp1LeA+FSnITKEkJ3VAXn8kVkgNTfQb2rtp63aP\nOKcPQatz2NPxSCaaJ73oSynZdbJ9QvP5ALlpZqTsn+iK10s/nILMFFqcfSPuMXO2oBWbhLoZJvnv\nY7IwWPTP6CjMmuosK80O9eePt86FXrQCrcOnO5ES8keY3gGYkZNKo6OHPq+Pxo6RWZwnveg3tPfQ\n0tXH8pkTW5ykpXE0sW/vdocWuY6H1n8nNAGT5JHtjOyAu6HO3o13BNYzxeiSlWoeYNnUHCiDl/o8\nm6iamUOjo5emzt6461zoJdNqJiPFxIFTgfYkeSOoxtXQFlM5YQ+McSRPx5NjGaYY7A7ehSdyEhf6\n0zhaO9b2bg85aWZd/vmCzBRanX3UtjrJz7CQOcrLyE01irNT8UtCyxyOhnNHMXLC2ysLIXS1YJjq\nhOf1TcFreTSCkEKbNbQI0kgnciFwzXh8MtR08qxO7+w60U66xcg50yfWwZI7ONJ3uaOujTuYgowU\nPD7JnvoOlcqg34K2+VgrMLITWDF62FLNeHySnqCFUVvg+2yO9BcXZ2E2CvbUdyRUOBmPwiwrnb2B\nCtpRSe8E61u0a2YkgdKkF/3dJ9upLM0e10VTIqGldzTXTpvLrSufD/1e/U+anCqVQb/obzkWWAVt\nNNvI8dAAABAXSURBVC4KxcgZ3IrhtKOX3HTLhBVEjgdWs5FFRVl8dLKd2lYXtlSz7pqTWIRPfo/W\nRC4ErpnsNLPugDMSk1r0XX1eDp/umvBJXOifsNWqctu73aHum/EIdx2pVEZ/VW57t4ey/MQXdlaM\nDYNFX1sm8WynamYO+085ONYyekGZlhIzBYveRoom+u3dnhE/GU9q0d/b0IHPLyc8nw+B9r0pJsOA\nnL7e4ohw0VepDEizmELtK9TvY/IQEv3u/kj/bM7naywrDXTt3FnXPmLnjoYW6eemx15kSS9ZVjOZ\nKYEp2JEGjrpEXwixQQjxsRCiRghxf4z9rhdCSCFEddi2bwc/97EQ4rJEBrf7RHASt3TiRR8Cf8A2\nlxspZWI5/XDRT3LnjoYWuagnn8nD4Eg/sEzi2S/62vKJo+kk07qSjrQwKxztmhnzSF8IYQQeBy4H\nFgGfF0IsirBfJnAvsC1s2yLgJmAxsAH4/4LH08Xukx3MnZahqznZeJATrMrt6vPi9UvdOf3MFBMp\nwYVfVGQbYLROYMXoES76fV4fdpeboiRI78zMTQs9tY9WEKLdLEdzvkpLi440cNQT6a8CaqSUx6WU\nbuA54OoI+z0E/AQIX9frauA5KWWflLIWqAkeLy5+v2T3yXZWTGDrhcFokX6oGldnekcIQUFmCtMy\nU0hPmfQu2XFBa7ymJrYnD+Gi39wZ6BU1PQkifSFEyLo5WkGI1rpipM3Wwhmtp2M9oj8DqA973RDc\nFkIIsRwolVK+nuhno3G81UVHt2dSTOJqZKeZae/29Ffj6pzIhUA0cU7h2dM4baTMLkjHbBTMKVCi\nP1nItAbaK3f2eJLCox/OyrJczEZB+SidjzlpZmypZkpyRi+dO7sgA4vRMOJAacRhpxDCADwK3DaC\nY9wF3AUwc+ZMILwoa/IsE5ibHkjvdAQnuhKxTT124zKUSaWfG1eWcu7svBFZzxSji8EgyEwx4ejx\nhBbsSBbRv31tGesXThsVpw0Enh5e/epa8kexX9jNq2dywbz8EY9Rj+ifAsJXyCgJbtPIBJYAm4LW\nu0LgNSHEVTo+C4CU8gngCYDq6moJgUncwDqxk6c/ek6aBUePJ9QmWW9OH87uApfhkGIyMn+CC+4U\nQ7GlBapytRYMenrpnw1YzaN/Po526tJqNjJvFMaoJ72zA5gnhCgXQlgITMy+pr0ppXRIKfOllGVS\nyjJgK3CVlHJncL+bhBApQohyYB6wXc/Adp1oZ/nMybVMYG66BSmhNli5NxpFHArFZEJbSOW0o5eM\nFBMZag7qrCOu6EspvcDXgLeBw8ALUsqDQoh/DkbzsT57EHgBOAS8BXxVSumL9RkITCQdbXZOaP/8\nSGQHXUTHW5wYDYIsHc3WFIqphNZ/J1nsmsmILtWSUr4BvDFo2/ej7HvRoNc/An6UyKC0VqeTaRIX\n+vvvHG9xkZNmVpWkirMOW6qZps5e/DJ58vnJxqSsyN19oh2DgMrSyTOJC/2dNuvsLl2LpygUU41A\npO8NLpOoRP9sZFLmJ3af7GBBYdak87Rrkb7HJ1U+X3FWEhB9N36JSu+cpUzKSP+jSbBSViTCo/tE\nnDsKxVQhK9he2eeXSvTPUiad6Pd6fLjcvkkp+qkWI1Zz4Femt8OmQjGV0KpyQeX0z1Ymneh3uwPm\nnsko+tAf4aucvuJsJFz0VW3J2cmkE32X20t+RmCV+smIlsvX21ZZoZhKDIz0J+c1qBgZk070u/t8\nrJiVPWntkJrYq0hfcTaiib7FZAiteaA4u5h0ou/2+Sdtagf6++2onL7ibEQT/SKbddIGXoqRMelE\nH5h0lbjh5AajHxXpK85GNNFX+fyzl0kn+iaDYMkM20QPIyoqp684m8kKi/QVZyeTTvQXFmVhNete\nXGvcWViURX5GCtMy1UWhOPswGgQLCjOpLJlc1fCK0UNIKSd6DAOorq6WO3funOhhKBQKxZRCCLFL\nSlkdb79JF+krFAqFYuxQoq9QKBRJhBJ9hUKhSCKU6CsUCkUSoURfoVAokggl+gqFQpFEKNFXKBSK\nJEKJvkKhUCQRSvQVCoUiiVCir1AoFEmEEn2FQqFIIpToKxQKRRKhRF+hUCiSCCX6CoVCkUQo0Vco\nFIokQom+QqFQJBFK9BUKhSKJ0CX6QogNQoiPhRA1Qoj7I7x/txBivxBijxDiAyHEouB2sxDid8H3\nDgshvj3aP4BCoVAo9BNX9IUQRuBx4HJgEfB5TdTDeFZKWSGlXAb8G/BocPsNQIqUsgJYAXxZCFE2\nSmNXKBQKRYLoifRXATVSyuNSSjfwHHB1+A5Sys6wl+mAtvCuBNKFECYgFXAD4fsqFAqFYhzRI/oz\ngPqw1w3BbQMQQnxVCHGMQKR/T3Dzi4ALOA2cBB6RUrZF+OxdQoidQoidLS0tCf4ICoVCodDLqE3k\nSikfl1LOAb4FPBDcvArwAcVAOfBPQojZET77hJSyWkpZXVBQMFpDUigUCsUg9Ij+KaA07HVJcFs0\nngOuCf77C8BbUkqPlLIZ+BCoHs5AFQqFQjFy9Ij+DmCeEKJcCGEBbgJeC99BCDEv7OVngKPBf58E\nPhXcJx04Fzgy0kErFAqFYniY4u0gpfQKIb4GvA0YgSellAeFEP8M7JRSvgZ8TQhxCeAB2oEvBj/+\nOPCUEOIgIICnpJT7xuIHUSgUCkV8hJQy/l7jSHV1tdy5c+dED0OhUCimFEKIXVLKuOlzVZGrUCgU\nSYQSfYVCoUgilOgrFApFEqFEX6FQKJIIJfoKhUKRRCjRVygUiiRCib5CoVAkEUr0FQqFIolQoq9Q\nKBRJhBJ9hUKhSCKU6CsUCkUSoURfoVAokggl+gqFQpFEKNFXKBSKJEKJvkKhUCQRSvQVCoUiiVCi\nr1AoFEmEEn2FQqFIIpToKxQKRRKhRF+hUCiSCCX6CoVCkUQo0VcoFIokQom+QqFQJBFK9BUKhSKJ\nUKKvUCgUSYQSfYVCoUgilOgrFApFEqFEX6FQKJIIJfoKhUKRROgSfSHEBiHEx0KIGiHE/RHev1sI\nsV8IsUcI8YEQYlHYe0uFEFuEEAeD+1hH8wdQKBQKhX7iir4Qwgg8DlwOLAI+Hy7qQZ6VUlZIKZcB\n/wY8GvysCfgDcLeUcjFwEeAZveErFAqFIhH0RPqrgBop5XEppRt4Drg6fAcpZWfYy3RABv/9aWCf\nlHJvcD+7lNI38mErFAqFYjjoEf0ZQH3Y64bgtgEIIb4qhDhGINK/J7h5PiCFEG8LIXYLIb4Z6QuE\nEHcJIXYKIXa2tLQk9hMoFAqFQjejNpErpXxcSjkH+BbwQHCzCTgfuDn4/2uFEOsjfPYJKWW1lLK6\noKBgtIakUCgUikHoEf1TQGnY65Lgtmg8B1wT/HcD8J6UslVK2Q28ASwfzkAVCoVCMXL0iP4OYJ4Q\nolwIYQFuAl4L30EIMS/s5WeAo8F/vw1UCCHSgpO6FwKHRj5shUKhUAwHU7wdpJReIcTXCAi4EXhS\nSnlQCPHPwE4p5WvA14QQlxBw5rQDXwx+tl0I8SiBG4cE3pBSvj5GP4tCoVAo4iCklPH3Gkeqq6vl\nzp07J3oYCoVCMaUQQuySUlbH209V5CoUCkUSoURfoVAokggl+gqFQpFEKNFXKBSKJEKJvkKhUCQR\nSvQVCoUiiVCir1AoFEmEEn2FQqFIIpToKxQKRRKhRF+hUCiSCCX6CoVCkUQo0VcoFIokQom+QqFQ\nJBFK9BUKhSKJUKKvUCgUSYQSfYVCoUgilOgrFApFEqFEX6FQKJKI/7+9+w/Vc4zjOP7+NBORZixp\nP2xYaYWp0xBqLWpM5o8lv0ooqQlFjJRRiqXZitRi7A+MEIskseIvHL9iW2t+JDS2hZgyxscf9z17\nzrPOzjN2nvvm+rzqdO7ruq+n8z3fzvM9V9d9P/eVoh8RUZAU/YiIgqToR0QUJEU/IqIgKfoREQVJ\n0Y+IKEiKfkREQVL0IyIKkqIfEVGQFP2IiIIc0MsgSXOB5cAY4BHb93advxZYCPwBbAeusb2+4/wU\nYD2w2Pb9e/1h2zbBY/P25XeIiIgejTjTlzQGeAg4F5gBXCJpRtewJ22faHsmsARY2nV+KfDKfog3\nIiL+hV5m+rOAT21/DiBpNTCfauYOgO2fOsYfAnhXQ9KFwBfALz1FdOR0uPLlnoZGRETtKvU0rJc1\n/YnAVx3tr+u+ISQtlPQZ1Uz/+rrvUOBW4K6eoomIiFG13y7k2n7I9nFURf6Ounsx8IDt7Xt7raRr\nJA1KGty6dev+CikiIrr0srzzDTC5oz2p7hvOauDh+vhUYIGkJcA44E9Jv9p+sPMFtlcAKwAGBgZM\nRESMil6K/rvAdEnTqIr9xcClnQMkTbe9qW7OAzYB2D6rY8xiYHt3wY+IiP4Zsejb3inpOuBVqls2\nV9peJ+luYND2GuA6SWcDvwM/AFeMZtAREfHPyG7XasrAwIAHBwebDiMi4j9F0nu2B0Yal0/kRkQU\nJEU/IqIgrVvekfQzsLHpOFrmSGBb00G0SPIxVPKxpxJzcoztCSMN6unZO322sZd1qZJIGkxOdks+\nhko+9pScDC/LOxERBUnRj4goSBuL/oqmA2ih5GSo5GOo5GNPyckwWnchNyIiRk8bZ/oRETFKWlX0\nJc2VtFHSp5IWNR1Pv0laKWmLpE86+sZLek3Spvr74U3G2E+SJktaK2m9pHWSbqj7S87JQZLekfRR\nnZO76v5pkt6u3ztPSzqw6Vj7SdIYSR9IeqluF52PvWlN0e9xh67/u8eBuV19i4DXbU8HXq/bpdgJ\n3GR7BnAasLD+myg5JzuAObZPBmYCcyWdBtxH9Rjz46mef3V1gzE24QZgQ0e79HwMqzVFn44dumz/\nRvWI5vkNx9RXtt8Evu/qng+sqo9XARf2NagG2d5s+/36+GeqN/VEys6JO/anGFt/GZgDPFv3F5UT\nSZOonu77SN0WBedjJG0q+j3t0FWgo2xvro+/BY5qMpimSJoKnAK8TeE5qZcyPgS2AK8BnwE/2t5Z\nDyntvbMMuAX4s24fQdn52Ks2Ff0YgatbrYq73aredvM54Mau/ZiLzIntP2zPpNrQaBZwQsMhNUbS\n+cAW2+81Hct/RZsew7CvO3SV4jtJR9veLOloqtldMSSNpSr4T9h+vu4uOie72P5R0lrgdGCcpAPq\n2W1J750zgAsknQccBBwGLKfcfIyoTTP9v3foqq+0XwysaTimNljD7k1prgBebDCWvqrXZh8FNthe\n2nGq5JxMkDSuPj4YOIfqWsdaYEE9rJic2L7N9iTbU6lqxhu2L6PQfPSiVR/Oqv9bL2P3Dl33NBxS\nX0l6CphN9YTA74A7gReAZ4ApwJfARba7L/b+L0k6E3gL+Jjd67W3U63rl5qTk6guTI6hmrQ9Y/tu\nScdS3fwwHvgAuNz2juYi7T9Js4GbbZ+ffAyvVUU/IiJGV5uWdyIiYpSl6EdEFCRFPyKiICn6EREF\nSdGPiChIin5EREFS9CMiCpKiHxFRkL8A3e2ZAnOjxHIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdd3652bc18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5Oeh6FQVJW6l",
        "colab_type": "code",
        "outputId": "ede9fd09-46c3-4767-93f1-95e977ea3754",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loss（損失関数）を表示\n",
        "results[['main/loss', 'validation/main/loss']].plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd36211898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdd36223550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OCyJFTSFJW6n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "こちらのように、精度が訓練データに対して約40%強、検証データに対して約35%程度にとどまっています。\n",
        "検証データが運用した際に得られる精度の目安になるため、運用後は良くても35％程度しか正解しないようなモデルであることがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "MWqw8mhlJW6n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 実践のヒント\n",
        "\n",
        "今回は一通りの流れを説明しましたが、まだまだ精度が良くないと不満に思った方もいるかと思います。\n",
        "ここからは試行錯誤の世界になるのですが、まずいちばん手っ取り早く精度を上げることが出来る方法として、**BatchNormalization**が挙げられます。\n",
        "\n",
        "実装としては、各バッチ毎に、平均と標準偏差を定めて正規化を行うといった非常に簡単な手法なのですが、これをかませることによって、各変数感のスケールによる差を吸収できます。\n",
        "\n",
        "それでは、BatchNormazliationがある場合で試してみましょう。\n",
        "\n",
        "宣言していたニューラルネットワークのクラスを以下のように変更して、もう一度学習を行ってみましょう。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "QxiNt2DoJW6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NN(chainer.Chain):\n",
        "\n",
        "    # モデルの構造\n",
        "    def __init__(self, n_mid_units=5, n_out=3):\n",
        "        super().__init__()\n",
        "        with self.init_scope():\n",
        "            self.fc1 = L.Linear(None, n_mid_units)\n",
        "            self.fc2 = L.Linear(None, n_out)\n",
        "            self.bn = L.BatchNormalization(10)  # Batch Normalizationは平均と分散がパラメータ\n",
        "\n",
        "    # 順伝播\n",
        "    def __call__(self, x):\n",
        "        h = self.bn(x)  # Batch Normalizationの処理を追加\n",
        "        h = self.fc1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.fc2(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "gsY2dZfRJW6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 乱数のシードを固定\n",
        "np.random.seed(1)\n",
        "\n",
        "# モデルのインスタンス化\n",
        "nn = NN()\n",
        "model = L.Classifier(nn)\n",
        "\n",
        "# Optimizerの定義\n",
        "optimizer = chainer.optimizers.SGD()\n",
        "optimizer.setup(model)  # modelと紐付ける\n",
        "\n",
        "# Iteratorの定義\n",
        "batchsize = 10\n",
        "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "# Updaterの定義\n",
        "updater = chainer.training.StandardUpdater(train_iter, optimizer, device=-1)\n",
        "\n",
        "# trainerとそのextensionsの設定\n",
        "epoch = 50\n",
        "trainer = training.Trainer(updater, (epoch, 'epoch'), out='result/wine')\n",
        "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
        "trainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n",
        "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=(1, 'epoch'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dHGgyNbcJW6q",
        "colab_type": "code",
        "outputId": "7e653dfc-0038-440a-c33c-e4cb42b5317d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 学習の実行\n",
        "trainer.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/accuracy  validation/main/accuracy  main/loss   validation/main/loss  elapsed_time\n",
            "\u001b[J1           0.415385       0.341667                  1.10392     1.21442               0.0324014     \n",
            "\u001b[J2           0.575          0.475                     1.0031      0.993539              0.0635639     \n",
            "\u001b[J3           0.553846       0.608333                  0.942188    0.922005              0.0964929     \n",
            "\u001b[J4           0.641667       0.625                     0.848846    0.856451              0.126369      \n",
            "\u001b[J5           0.65           0.625                     0.81297     0.80548               0.159143      \n",
            "\u001b[J6           0.684615       0.608333                  0.74872     0.771339              0.190904      \n",
            "\u001b[J7           0.675          0.625                     0.719701    0.728936              0.22096       \n",
            "\u001b[J8           0.753846       0.625                     0.704584    0.70214               0.255656      \n",
            "\u001b[J9           0.716667       0.641667                  0.688909    0.673809              0.288155      \n",
            "\u001b[J10          0.8            0.683333                  0.594708    0.65686               0.320836      \n",
            "\u001b[J11          0.784615       0.7                       0.588698    0.634453              0.35252       \n",
            "\u001b[J12          0.758333       0.75                      0.626121    0.602156              0.381661      \n",
            "\u001b[J13          0.8            0.791667                  0.560623    0.590054              0.413213      \n",
            "\u001b[J14          0.866667       0.808333                  0.480577    0.576962              0.442442      \n",
            "\u001b[J15          0.858333       0.808333                  0.556047    0.550731              0.473163      \n",
            "\u001b[J16          0.869231       0.808333                  0.506974    0.541605              0.504492      \n",
            "\u001b[J17          0.866667       0.808333                  0.478951    0.521063              0.53473       \n",
            "\u001b[J18          0.861538       0.825                     0.471306    0.507851              0.56626       \n",
            "\u001b[J19          0.9            0.841667                  0.441507    0.490725              0.595704      \n",
            "\u001b[J20          0.866667       0.841667                  0.471907    0.481671              0.625229      \n",
            "\u001b[J21          0.876923       0.916667                  0.452109    0.463697              0.656747      \n",
            "\u001b[J22          0.883333       0.9                       0.453664    0.445717              0.687249      \n",
            "\u001b[J23          0.892308       0.9                       0.380661    0.433952              0.718971      \n",
            "\u001b[J24          0.875          0.916667                  0.410088    0.419765              0.748346      \n",
            "\u001b[J25          0.9            0.9                       0.374395    0.397687              0.777901      \n",
            "\u001b[J26          0.915385       0.9                       0.352433    0.387938              0.810841      \n",
            "\u001b[J27          0.916667       0.933333                  0.364845    0.367715              0.841276      \n",
            "\u001b[J28          0.930769       0.916667                  0.306647    0.355292              0.875592      \n",
            "\u001b[J29          0.933333       0.95                      0.325068    0.348403              0.90916       \n",
            "\u001b[J30          0.875          0.966667                  0.388985    0.329933              0.940931      \n",
            "\u001b[J31          0.938462       0.966667                  0.311822    0.315558              0.97363       \n",
            "\u001b[J32          0.933333       0.95                      0.316743    0.310268              1.00606       \n",
            "\u001b[J33          0.961538       0.966667                  0.290442    0.294099              1.04096       \n",
            "\u001b[J34          0.925          0.95                      0.273505    0.283344              1.07346       \n",
            "\u001b[J35          0.95           0.966667                  0.25971     0.270989              1.10541       \n",
            "\u001b[J36          0.915385       0.95                      0.283717    0.258128              1.14092       \n",
            "\u001b[J37          0.908333       0.966667                  0.324117    0.250026              1.17347       \n",
            "\u001b[J38          0.938462       0.966667                  0.257327    0.239251              1.20741       \n",
            "\u001b[J39          0.95           0.983333                  0.234977    0.230012              1.23908       \n",
            "\u001b[J40          0.958333       0.966667                  0.194902    0.226905              1.27157       \n",
            "\u001b[J41          0.976923       0.966667                  0.196919    0.222974              1.30445       \n",
            "\u001b[J42          0.908333       0.983333                  0.278829    0.208401              1.338         \n",
            "\u001b[J43          0.938462       0.966667                  0.229717    0.207539              1.37272       \n",
            "\u001b[J44          0.933333       0.966667                  0.236867    0.199324              1.40843       \n",
            "\u001b[J45          0.933333       0.966667                  0.206753    0.191793              1.44096       \n",
            "\u001b[J46          0.915385       0.966667                  0.281936    0.190416              1.47434       \n",
            "\u001b[J47          0.958333       0.983333                  0.207116    0.180302              1.50772       \n",
            "\u001b[J48          0.946154       0.983333                  0.241741    0.170533              1.5417        \n",
            "\u001b[J49          0.925          0.983333                  0.310244    0.16517               1.57297       \n",
            "\u001b[J50          0.975          0.966667                  0.185174    0.16843               1.60785       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "xwjiJEQvJW6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# logファイルから結果の読み込み\n",
        "with open('result/wine/log') as f:\n",
        "    logs = json.load(f)\n",
        "    results = pd.DataFrame(logs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IZNBWihkJW6s",
        "colab_type": "code",
        "outputId": "db27c854-1872-467f-cad1-2a571509a376",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# accuracy（精度）を表示\n",
        "results[['main/accuracy', 'validation/main/accuracy']].plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd3392f400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdd36228828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WoihNFyUJW6v",
        "colab_type": "code",
        "outputId": "30598f42-e3b8-4e70-8458-4634995febd0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loss（損失関数）を表示\n",
        "results[['main/loss', 'validation/main/loss']].plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd338dc2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XdcVfX/wPHXhz1FZKgICA7EgYjiCmdomZqWpVZajtS0\nbb+G9e3bHt/KbGlZzjQbZmmWmqVibhQ0J6KoqIgKiOwNn98fl8zBUq5cxvv5eNwH3HM+55z3PQ99\n3w+f8xlKa40QQojaxczUAQghhDA+Se5CCFELSXIXQohaSJK7EELUQpLchRCiFpLkLoQQtZAkdyGE\nqIUkuQshRC0kyV0IIWohC1Nd2NXVVfv4+Jjq8kIIUSNFRkYmaa3dyitnsuTu4+NDRESEqS4vhBA1\nklLqZEXKSbOMEELUQpLchRCiFpLkLoQQtZDJ2tyFEJCfn09cXBw5OTmmDkVUMzY2Nnh6emJpaXlD\nx0tyF8KE4uLicHR0xMfHB6WUqcMR1YTWmgsXLhAXF4evr+8NnUOaZYQwoZycHFxcXCSxiysopXBx\ncanUX3SS3IUwMUnsoiSV/XdRbnJXSs1XSiUopQ6Usn+UUmqfUmq/UmqbUiqwQldOP3edoQohhKio\nitTcFwIDyth/AuittQ4A3gS+qtCVM85BQV6Figohqp+IiAiefPLJCpWdPHkyW7duZezYsSxbtuwm\nRyagAslda70JSC5j/zat9cXitzsAzwpdWWtIPl6hokKI6ic4OJhPP/20QmV37NhBt27dbnJE4nLG\nbnN/GFhT4dKJUUa+vBDiesTGxuLv78/YsWPx8/Nj1KhRrFu3jpCQEFq2bMnOnTvZuXMn3bt3Jygo\niFtuuYXo6GgANm7cyODBgwF47bXXGD9+PH369KFZs2ZXJP2oqCj8/PwwNze/4trr168nKCiIgIAA\nxo8fT25uLgDTpk2jTZs2tG/fnmeffRaAH3/8kXbt2hEYGEivXr2q4tbUeEbrCqmU6oshufcoo8wk\nYBJAp8bmkBhtrMsLUeO9/utBDsWnGfWcbTzq8eqdbcssExMTw48//sj8+fPp3Lkz3377LVu2bGHl\nypW88847LFq0iM2bN2NhYcG6det46aWX+Omnn645z+HDhwkLCyM9PZ1WrVoxZcoULC0tWbNmDQMG\nXNmym5OTw9ixY1m/fj1+fn489NBDfPHFFzz44IMsX76cw4cPo5QiJSUFgDfeeIO1a9fSpEmTS9tE\n2YxSc1dKtQfmAkO11hdKK6e1/kprHay1DsbCChIPG+PyQohK8PX1JSAgADMzM9q2bUtoaChKKQIC\nAoiNjSU1NZXhw4fTrl07pk6dysGDB0s8z6BBg7C2tsbV1RV3d3fOnz8PwNq1a69J7tHR0fj6+uLn\n5wfAmDFj2LRpE05OTtjY2PDwww/z888/Y2dnB0BISAhjx45lzpw5FBYW3sS7UXtUuuaulPIGfgYe\n1FofqfiVbaTmLsRlyqth3yzW1taXfjczM7v03szMjIKCAv773//St29fli9fTmxsLH369Cn3PObm\n5hQUFJCVlUVKSgoeHh4VisXCwoKdO3eyfv16li1bxsyZM9mwYQOzZ88mPDycVatW0alTJyIjI3Fx\ncbnxD10HlJvclVLfAX0AV6VUHPAqYAmgtZ4NvAK4AJ8X98ss0FoHl39lG0g6CoUFYC4DZYWorlJT\nU2nSpAkACxcuvK5jw8LC6Nu37zXbW7VqRWxsLDExMbRo0YLFixfTu3dvMjIyyMrKYuDAgYSEhNCs\nWTMAjh07RteuXenatStr1qzh9OnTktzLUW5W1VrfX87+CcCE67+yDRRlwsUT4Nryug8XQlSN559/\nnjFjxvDWW28xaNCg6zp2zZo13Hvvvddst7GxYcGCBQwfPpyCggI6d+7M5MmTSU5OZujQoeTk5KC1\nZsaMGQA899xzHD16FK01oaGhBAZWbDhNXaa01ia5cHBgGx1x9xkY+Q20vtMkMQhhalFRUbRu3drU\nYdw0HTt2JDw8/IYnv6rrSvr3oZSKrEjriOmmH7CwMfyUh6pC1Fq7d++WxG4ipkvuygycvOShqhBC\n3ASmnTjMrZXU3IUQ4iYwcXL3N/SYKZJ+q0IIYUymr7kX5EBKhRbzFkIIUUGmr7mDtLsLIYSRmTa5\nuxqGHku7uxA1g4ODAwDx8fEl9l8H6NOnDxEREWWe5+OPPyYrK+vS+4EDB1ZqzpgdO3YwceLEGz7+\nH7Nnz2bRokUVKtupUydyc3Px8fEhKSmp0tc2NtMODbWtD46NpeYuRA3j4eFRqXnZP/74Y0aPHn1p\n7pjVq1dXKp6SJie7EZMnT65QuRMnTtCkSZMrplyobky/zJ70mBHCZKZNm8asWbMuvX/ttdd46623\nCA0NpWPHjgQEBPDLL79cc1xsbCzt2rUDIDs7m/vuu4/WrVtz9913k52dfanclClTCA4Opm3btrz6\n6qsAfPrpp8THx9O3b99LUxNcXvudMWMG7dq1o127dnz88ceXrte6dWsmTpxI27Ztue222664zvr1\n6+nXrx8LFy7krrvuon///vj4+DBz5kxmzJhBUFAQ3bp1IznZsDTFnDlz6Ny5M4GBgdxzzz2X/op4\n7bXXmD59OmD4C+SFF16gS5cu+Pn5sXnz5kvX+/3330v8Mikp9szMTAYNGkRgYCDt2rXjhx9+uHTv\nr57a2JhMP6mLW2vYvQiKisDM9N81QpjMmmlwbr9xz9koAO74X6m7R44cydNPP81jjz0GwNKlS1m7\ndi1PPvkk9erVIykpiW7dujFkyJBS1/T84osvsLOzIyoqin379tGxY8dL+95++20aNGhAYWEhoaGh\n7Nu3jyeffJIZM2YQFhaGq6vrFeeKjIxkwYIFhIeHo7Wma9eu9O7dG2dnZ44ePcp3333HnDlzGDFi\nBD/99BOjR48mKSkJS0tLnJycADhw4AB79uwhJyeHFi1a8N5777Fnzx6mTp3KokWLePrppxk2bNil\nZpyXX36ZefPm8cQTT1zz2QoKCti5cyerV6/m9ddfZ926dYAhuX/00UcViv348eN4eHiwatUqwDBX\nz4ULF0qc2tiYTJ9N3VpBfiakxZk6EiHqnKCgIBISEoiPj2fv3r04OzvTqFEjXnrpJdq3b0+/fv04\nc+bMpel7S7Jp0yZGjx4NQPv27Wnfvv2lfUuXLqVjx44EBQVx8OBBDh06VGY8W7Zs4e6778be3h4H\nBweGDRt2qcbs6+tLhw4dAEN7d2xsLAB//PEHt91226Vz9O3bF0dHR9zc3HBycuLOOw3Tm/wzhTEY\nvgB69uxJQEAAS5YsKXUa42HDhl1zvby8POLi4i5NalZe7AEBAfz555+88MILbN68GScnp1KnNjYm\nk9XcTyUXP0y5vMdMfW9ThSOE6ZVRw76Zhg8fzrJlyzh37hwjR45kyZIlJCYmEhkZiaWlJT4+PuTk\n5Fz3eU+cOMH06dPZtWsXzs7OjB079obO84+rpxT+p1lmzZo1PPPMMyWWK2kKY4CxY8eyYsUKAgMD\nWbhwIRs3bizzmv9MYQywefNmevQodU2ia/j5+bF7925Wr17Nyy+/TGhoKK+88kqJUxsbk8lq7qnZ\n+cQkZBhq7iDt7kKYyMiRI/n+++9ZtmwZw4cPJzU1FXd3dywtLQkLC+PkybLHofTq1Ytvv/0WMNSI\n9+3bB0BaWhr29vY4OTlx/vx51qz5dwVOR0dH0tPTrzlXz549WbFiBVlZWWRmZrJ8+XJ69uxZ6rW1\n1uzbt+9Sjb6i0tPTady4Mfn5+SxZsuS6jv3999+54447Khx7fHw8dnZ2jB49mueee47du3eTkZFB\namoqAwcO5KOPPmLv3r3XFUNFmLTN/Ze/z/B/t7UCe3dJ7kKYSNu2bUlPT6dJkyY0btyYUaNGceed\ndxIQEEBwcDD+/v5lHj9lyhTGjRtH69atad26NZ06dQIgMDCQoKAg/P398fLyIiQk5NIxkyZNYsCA\nAXh4eBAWFnZpe8eOHRk7dixdunQBYMKECQQFBV1qErlaZGQkQUFBpT4PKM2bb75J165dcXNzo2vX\nriV+0ZRm48aNvPHGG9dsLy32tWvX8txzz2FmZoalpSVffPEF6enpJU5tbEwmm/LXxae1bj1lFpue\n64vZojsNI1UnrDNJLEKYSm2f8vdme+utt2jRogX33XdflVwvLi6OiRMnXvFXyM1UmSl/TVZzd7az\nJO5iNpGnLtLZzR/2/QBaw3V+Awsh6q6XX365Sq/n6elZZYm9skzW5l7P1hJbS3OW7zljaHfPTYP0\ns6YKRwghahWTJXczpbitbUNW7TtLXgOZhkDUXaZqGhXVW2X/XZi0n/vdQU1Izc5na2rxQAaZhkDU\nMTY2Nly4cEESvLiC1poLFy5gY2Nzw+cwaW+ZHi1ccXWwYumhbPraNpCau6hzPD09iYuLIzEx0dSh\niGrGxsYGT0/PGz7epMndwtyMOwM9WLLjFAW+flhIzV3UMZaWlvj6+po6DFELmXz6gbuDmpBXWESs\n8oKEKEOPGSGEEJVi8uQe0MSJZm72bE51gZwUyJQ/T4UQorJMntyVUtzdoQnrkpwNG6TdXQghKs3k\nyR1gaIcmHC0qfnAg7e5CCFFp1SK5e7vY4e3tSwb26ASpuQshRGVVi+QOcFdHT6KLPMg8U/K8ykII\nISqu2iT3we0bcwxPaXMXQggjKDe5K6XmK6USlFIHStmvlFKfKqVilFL7lFIdSypXnvp2VuDaCoeC\nixRmVL+VxIUQoiapSM19IVDWsuJ3AC2LX5OAL240GN/WhnmgD+zdeaOnEEIIQQWSu9Z6E5BcRpGh\nwCJtsAOor5RqfCPBBAR1BSB6364bOVwIIUQxY7S5NwFOX/Y+rnjbdbNx8SbXzI7MMwc5FJ9mhNCE\nEKJuqtIHqkqpSUqpCKVURIkTJSmFuXsrAi1O8erKAzJTnhBC3CBjJPczgNdl7z2Lt11Da/2V1jpY\nax3s5uZW4sks2gyiI1HknIxkxd8lnkYIIUQ5jJHcVwIPFfea6Qakaq1vfEmlLo+gbZ15xfEX3ll9\nmPScfCOEKIQQdUtFukJ+B2wHWiml4pRSDyulJiulJhcXWQ0cB2KAOcCjlYrIph7qlifpnLcLz8yD\nfLLuaKVOJ4QQdVG587lrre8vZ78GHjNaRABdJsH2mbzn8Bt3bGvJiM5e+DV0NOolhBCiNqs2I1Sv\nYO0AIU/hl7GTHlYxvLbyoDxcFUKI61A9kztA5wlg78b/XH5j27ELrNp/4834QghR11Tf5G5lDz2m\n0vhCOCPcTvH2qigycwtMHZUQQtQI1Te5AwSPB4eG/Nd+BWdTc5gZFmPqiIQQokao3snd0hZ6PIPj\nuR083yqBuZuPczwxw9RRCSFEtVe9kztAp7Hg2JiJBd9hY2HGR9I1UgghylX9k7ulDfT8PyzPhPNc\ny7OsPXCOi5l5po5KCCGqteqf3AE6PgT1PLk3fTF5hYUs3yPTEgghRFlqRnK3sIZez2J3PpJx7jH8\nsOu09HsXQogy1IzkDtBhFNT35gn9HUfOp7I3LtXUEQkhRLVVc5K7hRWEvkqD9MOMtNrGD7tOl3+M\nEELUUTUnuQO0HQYeHZlm9SN/7I0lK08GNQkhRElqVnI3M4Pb3qJ+QSIjC35l1T6ZkkAIIUpSs5I7\ngE8IutVAHrNcyZrw/aaORgghqqWal9wB1f8NbFUevc/OJyZBRqwKIcTVamRyx7Ulue0fYpT5etZt\n3mLqaIQQotqpmckdsO3/H/LNbPA/MJ28giJThyOEENVKjU3uOLhxtt1k+uhd7Nn8m6mjEUKIaqXm\nJneg6eBnOY8LbtvfgiKpvQshxD9qdHI3t7Znd4vHaZYXzcWIH0wdjhBCVBs1OrkDtB0wiYNFTTFf\n/zrk55g6HCGEqBZqfHL3dnXgF/cp1Ms9S9GWj0wdjhBCVAs1PrkDtO0xhBWFt8CmD+D0LlOHI4QQ\nJlcrkvvtbRsx1/FRzhY1IHfpeMhNN3VIQghhUrUiudtYmvPVpH68azsVi7TTJP34tKlDEkIIk6oV\nyR3Ao74t/5kyniVWw3GNWcaxsEWmDkkIIUym1iR3gMZOttz+6AwOmfnhunEafx84YOqQhBDCJGpV\ncgdo6OxIw7GLsVSF5P04kR0xCaYOSQghqlytS+4ALt7+FNz+Hl3UIbYueoVtx5JMHZIQQlSpCiV3\npdQApVS0UipGKTWthP3eSqkwpdQepdQ+pdRA44d6fep1G0OO3xCeMlvKjIXfcyg+zdQhCSFElSk3\nuSulzIFZwB1AG+B+pVSbq4q9DCzVWgcB9wGfGzvQ66YUNnd/inJsyIfmM/lg5U601qaOSgghqkRF\nau5dgBit9XGtdR7wPTD0qjIaqFf8uxMQb7wQK8HWGfNhX+GlEngq/nnC/o42dURCCFElKpLcmwCn\nL3sfV7ztcq8Bo5VSccBq4ImSTqSUmqSUilBKRSQmJt5AuDfAtyd6+CLamJ3EZ+Vw8i5Wj+8dIYS4\nmYz1QPV+YKHW2hMYCCxWSl1zbq31V1rrYK11sJubm5EuXT7zNoM51HceDYvOk/PVbXDxZJVdWwgh\nTKEiyf0M4HXZe8/ibZd7GFgKoLXeDtgArsYI0FgCew1lesP3IDuZovkDIPGIqUMSQoibpiLJfRfQ\nUinlq5SywvDAdOVVZU4BoQBKqdYYknsVtbtUjFKK+4bdy315L5OVnQ0L7oCze00dlhBC3BTlJnet\ndQHwOLAWiMLQK+agUuoNpdSQ4mL/B0xUSu0FvgPG6mrYNaVVI0c6dO7J0Kz/km9mDQvvhFM7TB2W\nEEIYnTJVDg4ODtYRERFVft2kjFz6fLCRgd75vJ/1KqTFw9jfoEmnKo9FCCGul1IqUmsdXF65WjlC\ntSyuDtY81rcFS48qdvb5Buxd4bv7IeV0+QcLIUQNUeeSO8C4EB88nW15ZX0ihfcvNSzP9+0IyJFR\nrEKI2qFOJncbS3Om3eHP4XPp/HjSHkZ8DUlHYNk4KCwwdXhCCFFpdTK5AwwKaEynps5M/+MIsU5d\nYNCHELMO1jwP1e9ZsBBCXJc6m9yVUrw5tB0FRUUMmbmFMIeBcMuTEDEPdph+ahwhhKiMOpvcAdp4\n1OPXx3vQxNmO8Qt3McviQXTrO2Htf+DwKlOHJ4QQN6xOJ3cArwZ2/DzlFu5s78EHfxzlqdwpFDbu\nAD9NgPg9pg5PCCFuSJ1P7gC2VuZ8cl8H/jOwNb9FpfBAxtMU2DjDN/dAzHpThyeEENdNknsxpRQT\nezVj0fiuRGfacXf6c2RYNIBvhsG616Aw39QhCiFEhUlyv0qPlq78+ngPCpxbEJzwEqstb4ctH1E4\nfyCknDJ1eEIIUSGS3Evg1cCO5Y/ewhv3dObzek/wRN7jZMftJ/uzW4jf8aOpwxNCiHLVubllrpfW\nmj2nU1jz11aGHP0vAWbH+d1+KKr/m4QGeGFhLt+PQoiqU9G5ZSS5X4eklDTOLHuBwLhv2Vfky+s2\n07gtpDMjO3tR387K1OEJIeoASe43UWHUKop+foScAngs91F2mgcxrKMn427xoWVDR1OHJ4SoxWRW\nyJvIvPUgLCf/haObN19bvc+njf/kp8hT9P9oE6PnhhN9Lt3UIQoh6jhJ7jfKpTlMWIcKGM5tCfPY\n32oh/wn14EB8Ki+v2G/q6IQQdZwk98qwsoNhX8HA6Vid2MDEQ+N4qWMhu2Ivciwxw9TRCSHqMEnu\nlaUUdJkIY1dDQQ7D/x7HJItVrAiXBbiFEKYjyd1YvLvCI5tQTW/hJYslTIi4k6L1b0PmBVNHJoSo\ngyS5G5ODOzz4M+G3/sCOQn/MNr8PH7WF1c/L6FYhRJWyMHUAtVHHkNvovsmCLY1SedN1vWGO+F1z\nIeBe6DMNGjQzdYhCiFpOau43gaW5Gfd0bMK3x21JCJ0BT+2FrpMh6jf4vDts+gAKck0dphCiFpPk\nfpMMD/aisEizfPcZcPKEAe/AExHgNwA2vAWze8CJzaYOUwhRS0lyv0lauDvQqakzSyNOc2kUcD0P\nw2Lco5YZau5fD4blkyEj0bTBCiFqHUnuN9HIYC+OJWay+9TFK3e07A+P7oCez8L+ZTAzGCIXysLc\nQgijkeR+Ew1s3xg7K3OW7oq7dqeVHYT+F6ZshYbt4NenYMUUWRRECGEUktxvIgdrCwa3b8xv++LJ\nzC0ouZBbKxj7G/T9D+z9Dr4dAbn/zk1zKD6Nd9dEkVtQWEVRCyFqA0nuN9mIYC8y8wpZte9s6YWU\ngt7Pw5CZcPwvWDgI0s9z+FwaD8zdwZd/HWfRtpNVF7QQosarUHJXSg1QSkUrpWKUUtNKKTNCKXVI\nKXVQKfWtccOsuTo1daaZmz1LI06XX7jjg/DAD5B0lPw5/Xjxq+XYWJgT3NSZzzYc5WJm3s0PWAhR\nK5Sb3JVS5sAs4A6gDXC/UqrNVWVaAi8CIVrrtsDTNyHWGkkpxchgLyJOXiQmoQKTibXsz5m7lpGe\nlsKCov+w7E4L3r47gIzcAj7bEHPzAxZC1AoVqbl3AWK01se11nnA98DQq8pMBGZprS8CaK0TjBtm\nzXZ3xyaYmyl+jCy/9n46OYt7V+Ywzuxt7Oo1wPOXkbRK2czIzl4s3hHLyQuZVRCxEKKmq0hybwJc\nnpXiirddzg/wU0ptVUrtUEoNMFaAtYG7ow23+rvzU+QZ8guLSi0Xn5LNA3N3kJlbwDsThmI1aT24\n+8P39/Nm/CSeMF/O1yv/rMLIhRA1lbHmlrEAWgJ9AE9gk1IqQGudcnkhpdQkYBKAt7e3kS5dM4wI\n9uLPQ+d5dMlugrzr09LdkZbuDng1sMPcTJGQlsOoueGkZObzzYSutPVwMhw4dhXs+QaLg8t5wuxH\n1MmlZH3ij12He6DNXeDmZ9oPJoSolspdQ1Up1R14TWt9e/H7FwG01u9eVmY2EK61XlD8fj0wTWu9\nq7Tz1uQ1VG9EQWERL/68ny0xSZxNzbm03drCjOZuDqRm53MxK4/FD3ehU9MGJZ4jK+kUn3/+EQPN\nw2mdfwiFNvSRbz8CAoYbRsAKIWo1oy2QrZSyAI4AocAZYBfwgNb64GVlBgD3a63HKKVcgT1AB611\nqZOZ17Xkfrm0nHxiEjI4ej6do+czOJqQQXJmHi8NbE335i5lHvv9zlNM+3k/84Y1IbRoBxxYBnG7\nAAW+vaD9SGgzBKxloW4haiOjJffikw0EPgbMgfla67eVUm8AEVrrlUopBXwIDAAKgbe11t+Xdc66\nnNwro7BIM/CTzeQUFPLn1N5YWZjBhWOwbyns+wEungALW/AfBF0mGRYREULUGkZN7jeDJPcbFxad\nwLgFu3hlcBvG9/D9d4fWhlr83u/h4M+QnQI9pkLfl8Dc0nQBCyGMpqLJXUao1kB9/Nzo0cKVTzcc\nJTXrsrlolAKvLjB4Bkw9aBgUtWUGzB8AySdMF7AQospJcq+BlFK8ONCf1Ox8Zm0sZWCTlT0M+QyG\nL4SkozC7p6HpRghRJ0hyr6HaejgxLMiThdtiSUwvY1WntnfDlC3QsC38PBGWTyb88EkZDCVELSfJ\nvQZ7tG9z8gqKWLyjnEnF6nsb+sv3nobe9wONvuvPvC+mk5pYwlTEQohaQZJ7DdbczYF+rRuyeHss\n2XnlTAlsbgF9X2RBy5lYUMgbBTNwmtUWPasrrPo/OLgCMpOqJG4hxM0nyb2Gm9SrGRez8lm2u/xa\neFJGLu9HNeDTtktZ2Xkx/8u/jzNFLvD3d/DjGPiguWEB711zobCU+eeFEDWCJPcarrOPM4Fe9Zm3\n+TiFRWV3a5235QR5BUU80rcVdw68kxi/CfQ99zj7H9wHD6+D0FcND2JX/Z9hAe+YdVX0KYQQxibJ\nvYZTSjGpZzNiL2Tx56HzpZZLzcpn8faTDAxoTDM3B5RSfHBvIK4O1jz+w37S3TpAz2fg4T9hxGIo\nyIZv7oFv7oXE6Cr8REIIY5DkXgvc3rYhXg1smbP5eKllvt4eS0ZuAY/1bXFpm7O9FZ/eH0TcxWz+\ns/wAWmtDX/k2Q+CxndD/TTgdbmiqWfUsZJY6m4QQopqR5F4LWJib8XCIL5EnLxJ5Mvma/Zm5Bczf\neoJ+rd1p3bjeFfs6+zRgar+WrNwbf+VqURbWEPIkPLkHOo2FiHnwaZAhycdFGkbDCiGqLUnutcTw\nYC+cbC2Zs+nakajfhp8iJSv/ilr75ab0aUFICxdeXXmQI+fTr9xp72oY8TplG7QIhd2LYO6tMDMY\n/voALsrarkJUR5Lcawl7awtGd/Nm7aFzxCb9O0ApJ7+QrzYfJ6SFC0HeziUea26m+GhkBxysLXhs\nye6Su1W6t4bhC+C5o4aRrw4NIewt+KQ9zL8Ddi+G/JxrjxNCmIQk91pkTHcfLM3MmLfl39r7jxGn\nSUzPLbXW/g93Rxs+GtmBmMQMHpi7g/iU7JIL2jhBx4dg3Gp4ah/c+jJkJsLKxw2JfsvHkJNmzI8l\nhLgBktxrEfd6NtwV5MGPkadJzswjv7CI2X8dp6N3fbo3K3ueeICeLd2Y9UBHjpxLZ/BnW9hytJxB\nTc5Noddz8PgueGgluLeBda/Cx+1g/ZsyKEoIE5LkXstM6NmMnPwivtlxkhV7znAmJZvHb22BYcr9\n8g0MaMzKJ3rgYm/Fg/PDmbnhKEXl9J9HKWjWGx5aARPDwLc3bP4QPmoHq5+D5NJ78Qghbg6Zz70W\nGrdgJ/viUnGytcTG0pxVT/aocHL/R2ZuAS8t388vf8dzq787H43ogJPddcwJn3gEtn4C+76HogJw\n9gGfHuDT0/DTyfP6PpQQApDFOuq0bceSeGBOOACzHujIoPaNb+g8Wmu+2XGSN347RMN6NnwxqhMB\nnk7Xd5LUODi0Ek5uhdgtkFO8Zvo/yd5/MPgNMNT+hRDlkuReh2mtuWvWVjLzCln7dC/MzSqXOPec\nushjS3aTmJFLB6/6BHrWJ9CrPh286uPpbFvxvwqKiiDhkCHJx242JPzsi9AwAHo/b0j0ZtJSKERZ\nJLnXcSlZeRRpaGBvZZTzJWfm8cXGGCJPXuRAfBp5BUWA4fyBnk50bebCuBAfrC3MK3zOn3bF4nJi\nJb3OfY3+TbpHAAAc4ElEQVRZcgy4t4Xez0HroZLkhSiFJHdx0+QXFhF9Lp2/T6ew93QKe+NSOHI+\ng+Cmzsx+sBOuDtZlHl9QWMQbvx1i0XbDAKgm9SyZ0eYYXU7PQ104Cm6tDUm+zV1gVvEvCyHqAknu\nokr9ujee55btpYGdFXPGBNPWo+S2+dTsfB7/djebjybxSK9m9G7lxntrDrM3LpU2De2Y3uY4rY9+\niUqKBtdWhuaatndLkheimCR3UeUOnEll4qIIUrLy+XBEIAMDrnyQG5uUycNf7+JUchZv3xXAiM5e\ngOEZwar9Z3n/92hOJWfRo3l93ml1HO/9syAxCu3qR273Z0hrMYTsAsNfDr6uDpV+liBETSTJXZhE\nQnoOkxdHsvtUCk+FtuSp0JaYmSm2H7vAlCWRKGD26E50LWFQVV5BEd+Gn+TTDTEkZ+bRwNacngXb\nmaJ+wt/sNMeKGjOz4C5WFt3CM7e3KXfUrRC1kSR3YTK5BYX8Z/kBlkXGMaBtI0JauPD6r4fwcbVn\n3phgmrrYl3l8Wk4+i7bFcj4tFzsrc2wtFW1SNxF8ci4N0qM5a+7BD4V9efiRp3Bs3KqKPpUQ1YMk\nd2FSWmvmbTnBO6ujKNLQy8+NmQ8EUc/mOgZCXa2oCKJXkxX2IXYJuw3bGraD1kOgzVBw9zdO8EJU\nY5LcRbWwLSaJA/GpjA/xxcLceN0bn5/7G25xfzDV8zAWcTsBDa5+hiQfeD+4NDfatYSoTiS5i1pt\nX1wKQ2Zu5bnbW/FYsANE/Wp4xW4BXQhNexhmr2wzBCxtTR2uEEZT0eQuI0VEjdTesz63+rszZ/Nx\nMqxcoctEGLMSnomCfq9BejwsnwTTWxlWjzq7z9QhC1GlJLmLGuup0JakZOXz9bbYfzc6NoQeU+GJ\n3TDmN/C73bB61Jc9Yc6tcHK7yeIVoipVKLkrpQYopaKVUjFKqWlllLtHKaWVUuX+ySBEZQV61adP\nKzfmbj5OZm7BlTuVAt+ecM8ceDYa7vgA0s/DggGw4jGZa17UeuUmd6WUOTALuANoA9yvlGpTQjlH\n4Ckg3NhBClGap0JbcjEr/9JUBiUpsq7PjLQ+3JY/nfPtHzVMQ/xZJ4iYb+iBI0QtVJGaexcgRmt9\nXGudB3wPDC2h3JvAe4AspCmqTJC3M7393JhTUu0dSM/JZ9LiSD5df5QzmYp+e/twaOgaaBQAv02F\nef0g/m8TRC7EzVWR5N4EOH3Z+7jibZcopToCXlrrVUaMTYgKeapfS5Iz8/hmx5W199ikTIZ9vo2w\n6ARevbMNfz7TmwYOVoz4+SIRvb+GYXMg5TTM6QsrHjX0tslOMdGnEMK4Kv1AVSllBswA/q8CZScp\npSKUUhGJiYmVvbQQAHT0dqZnS1e+2nScrDxD7X3TkUSGzNxCYkYui8Z3YVyILx71bflhUnfcHK15\naMEuwh1CDeu/dp4AB1fAD6PhfV+Y2w82vA0nt0FBnok/nRA3ptx+7kqp7sBrWuvbi9+/CKC1frf4\nvRNwDMgoPqQRkAwM0VqX2pFd+rkLY4o8mcw9X2znpYH+KBTvronCr6EjXz0YjLeL3RVlE9JyuH/O\nDuJTcpg3NphbmrsaknjcLjgeBsfCIH436CKwcoDWd0Lfl6C+9039DL/ujefd1VGseDwEd0ebm3ot\nUXMZbRCTUsoCOAKEAmeAXcADWuuDpZTfCDxbVmIHSe7C+B6cF862YxcoLNLc0a4R04cHYm9tUWLZ\nhPQcRs0J5/TFLOY+1JkeLV2vLJB90TAgKmYd7P0etIbujxq6Wdpc51KDFZCZW0Cf6RtJTM9lSp/m\nvDBAplIQJTPaICatdQHwOLAWiAKWaq0PKqXeUEoNqXyoQhjHM/39sLU055n+fsx6oGOpiR3A3dGG\n7yZ1o2kDex7+ehcboxOuLGDrbKix3/kJPB4Bbe+CLR/Bpx1h5xwovPbhbWXM/usYiem5tPWoxzfb\nT5KWk2/U84u6R6YfELVKUZHG7DrmeU/OzGPU3HAOn0tjVFdvnrvNHye7UiY3O7Mb/njZsParqx/0\nf9MwSKqSi3ufScnm1ukbub1tIyb1asbgz7bw/IBWPNpHpjQW15LpB0SddD2JHQxrwC59pBtjuvvw\nbfgpbv1wI8si4yix0tOkI4xdBfd9S2FRIXw3ktyZt8DmDyH5xA3H/N6awwC8cIc/7Zo40bOlK/O3\nxJKTX3jD5xRCkruo8xxtLHltSFt+faIHTV3sePbHvYz4cjtRZ9OuKJeZW8Ave+OZEO5OwPnXeSn/\nYWJSimD9G/BpB8P0BttmQuqZCl9796mLrNwbz8SezWhS3zDB2aN9WpCUkcuyyDijfk5Rt0izjBCX\nKSrSLIuM4901UaTlFDCmuw+dmjqzan88Gw4nkJNfRKN6Ngxq3xhPZ1te//UQr/dyYEy9PXDwZzi7\n13Ai7+7g08MwWKpRe3D2uab5RmvNsC+2EXcxm43P9rn0jEBrzd2fbyM5M48N/9fbqFMli5qvos0y\npT9xEqIOMjNTjOjsRf82Dfngj2gWbDvB/K0ncHWwYkSwF4PbexDc1PlS88+u2GTe2ZZA76cn4tPj\naUiKMST5Qyth8wzD9MMA1vX+TfQeQdB6MCsPpbDnVArv39v+ioe/Simm9GnOI4sjWbX/LEM7NCkp\nVCHKJDV3Icpw+FwaFzPz6ezjXGIN+nxaDqEf/kWQd30Wje+Curx2np8NCYcM0w2f2w/n9sH5g5Cf\nhbZ355OcQfxVbzA/PRF6zbOCoiLNbR9vwsJMseapnleeV9Rp8kBVCCPwb1SP7s1dSm0aaVjPhucH\ntGLz0SRW7o2/cqelLTTpBMHjYPAMmLAOXoyDsauJs2jK04UL+CHnUcwi5kJB7hWHmpkpJvduzuFz\n6Ww8IqO5xfWT5C5EJY3q2pRATyfe/O0QqVnl9E83M+d8g07cfvFZPvT4ECu3ZrD6WUP/+YgFV0x3\nMCTQAw8nG74IO3aTP4GojSS5C1FJ5maKd4YFcDErn/fWHi63/PS10eQXFnHPsPth3Bp4cAXUawy/\nPQ2fdYRN0yH9HFYWZkzs1YydsclExCZXwScRtYkkdyGMoK2HE+NuMfSVjzxZciJOzszj3TVRLNsd\nx7gQX3xc7Q09aJr3hYf/hFHLDL1qNrwJM9rA96O4v0E0LrZmzP6r+tfel++J4/VfD5Y8RkBUOekt\nI4SRTO3vx+r9Z3np5wP89mQPLIvb6S9m5jFn83EWboslO7+Quzo04cnQllcerBS07G94XTgGu7+G\nPUuwOfwbYdaNmHckhOOHrWjm1w7MzAFIy8nn1IUsTiVn4etqT+vG9ar6I1+yZv9Znlm6F62hq68L\nA9o1MlkswkB6ywhhROsOnWfCogheGODPA128mbflOPO3xpKZV8Dg9h48FdqCFu6OFTtZQR5EryZ/\n1wIsYzcaNilLzpo14lhhQ44UNOSEbkSsbkQUvowP7cBjfVtgfp2jdCsr/PgFHpy/k3Ye9UjLKaBI\na/54upf0z79B+YVFZOcXUs+m5GkwjDYr5M0iyV3UVo8sjmBjdCJWFmak5xQwMKART4X60apRBZN6\nCeau3EDMzjUE2CThZ3EeL87imheHRZHhAWyusuH7/J7sbnwf00YPorGTrbE+TpkOn0tj+OztuDta\ns2zyLeyKTWbS4kjevrsdo7o2rZIYaptnf9zLtpgktrxwa4nTaUhyF8JEzqZmM+zzbbRr4sTUfn60\n8TBOc8k1k6IVFUHaGUg6Agd+pnDfD6jCAv5Swdj3eYouvQdXelKzspxJyeaez7eh0fw05RY8ne3Q\nWjN89nZOJmfx13N9sLOSlt/rEXU2jYGfbkZrWPFYCB286l9TRvq5C2EijZ1s2f5iKHMeCjZaYocS\nJkUzM4P6XtAiFO6ahfnUg6R2fopOKpouG0dz5v2u5O354aasJpWSlceY+TvJzC3g6/Fd8HQ2LIii\nlOLFgf4kpucyd/ONT6ZWV01fG42DlQVmCsIOJ5R/QBkkuQtRWzg2xHnw69g8H8UanxfIyUzD6pdJ\nFL7XDJY+BH9/CxmVHxCVk1/IhK8jOHUhi68eCsa/0ZVfYJ2aNuD2tg358q9jJGXklnIWcbWI2GTW\nH05gcp/mBHk7E3b1GgPXSZK7ELWMla0Dd4x9iTOj/uIJs5f5ITuYi4c3w4op6OktDWvEbvrAMCXC\ndTbLFhQW8cR3e4g8dZGPRnage3OXEss9P8CfnIIiPlt/1BgfqdbTWvP+79G4OVozLsSHvq3c2BeX\nSmL6jX85SnIXopbq1aoh774wlczbZnCH+ZcMyn2bJbYPcDEzBza8BbN7wKdBhimLzx0oN9HHJmXy\nwNxw/jx0nlcHt2FQ+8allm3u5sDIzl4sCT9FbFKmsT9ambTWnEvNqZJrZeYWMHbBTnaeqNwgs41H\nEtkZm8yTt7bAzsqCvv7uAPxViaknJLkLUYs5WFswsVcz/nohlDHDhjLfYgRBZ1/kbtsF7Gj7KoX1\nm8KWj2F2CMzqAmHvQmL0FecoLNLM23KCAZ9sIupsGtOHBzI2xLfcaz8d2hJLczM++CO63LLGNPuv\n43T/33o2VcGcPN+Gn2JjdCLvrI664cFbRUWGWrt3AztGdjYswt6mcT3cHa0r1TQjyV2IOsDawpwR\nnb1YN7U3s0d3osihIfdFtiLw+KO81Xo5J7u/hXZwh7/eMyT5L0Jg8wxOHo9mxJfbefO3Q4Q0d+XP\nqb25t5Nnha7pXs+GiT19WbXvLHtPp9zkT2iQW1DI/K0n0BqeWfo3CWk3rwafk1/IV5uP42htwd+n\nU9gac+GGzvPb/rNEnU3jmf5+WFkYUrJSir6t3Nl0JJH8wqIbOq8kdyHqEDMzxYB2jVjx6C0sfaQ7\nA9o1Ysn+bHqHNaPfhedYdMvvpPd9G21pB+tfp+miLrx0/hmWd41m7vBmNHKyua7rTerdHBd7K95d\nc+M12+vx696zJKbn8t/BbcjILeDpH/6msOjmXPfHiNMkpufy2QNBNKpnw6cbrv/5Qn5hER/+EY1/\nI0eGBHpcsa+vvxvpOQXsPnnxhuKT5C5EHaSUootvA6YPD2TXy/14/572NLC34pUNF+iwthm9kl+k\nR+7HLHceT2CDQoL2vo76sBV8ex/sW1rhpQQdrC14MrQlO44nszH65jaTaG1oPmrp7sD4EB/eGNKO\nbccu8HlYjNGvlV9YxOy/jtPRuz69/dx4pHczdp5IJvz49dXel0ac5uSFLJ4f0Oqarq4hLVyxNFeE\n3eB9kxEGQtRxDtYWjOjsxYjOXhxPzGBZZBy7YpMZfdttDAkciwJDz5r9S2H/T3BkjeHAek3AszN4\ndQGvroZVpiysrjn//V28mb/1BE9+v4fni6dluBlTJGw/foGos2n8b1gASimGB3uy9VgSH607Qtdm\nLnTxbWC0a63Yc4YzKdm8eVdblFLc19mbWWExzAyLoWuzknsQXS07r5BP1h0luKkzfVu5X7Pf0caS\nzj4N2BidwLQ7/K87RknuQohLmrk58PyAEhJJ4/aGV7/X4ezfcHoXnA6HuF1waIWhjLk1eAZDy9vA\nbwC4tQKlsLIw4+txXXhp+X7+u+IAyyLjePuudrRr4mTU2OdvOUEDeyvuCjIsS6iU4q272vH36RSe\n+n4Pq5/sibP9tV8+16uwSPP5xmO0aVzvUlK2tTJnQs9m/G/NYf4+nVLiyNKrfb09loT0XGaN6ljq\nSlt9W7nz9uoozqRkX1pAvaKkWUYIUXFm5obVpbpNhuELYOoBeOYwjFgEXSZCbhqsexU+7wqfBMLq\n5+HYBnzqW7BkQlc+HtmBMxezGDJzC2/8eoiM3AKjhHU8MYN1UQmM7tYUG0vzS9sdbSyZeX9HkjJy\nefbHvUZp91+9/ywnkjJ5/NYWVyTl0d2aUt/Okpkbym8GSs3O54uNx7jV353OPqX/RdHX3w2AjTfQ\na0aSuxCicuo1hjZD4fa3YfIWmHoIBn8E7q0NUxcvvhveb4b6/gHuyvmFsNFujOriyYJtJwj9cCOr\n95+tdNJdsDUWK3MzHux27WRlAZ5OvHhHa9YfTmD+1tgSj0/NymfbsSROJ2eVeZ2iIs2ssBhauDsw\noO2V0xo7WFswPsSXdVHnORSfVuo5svMKefzb3aTl5PPsba3KvF5zNwc8nW0JO3z97e7SLCOEMC6n\nJhA83vDKy4LYzRC9Bo5vhOjVOAJv2jbgmVZd+e58U2Z8e4wtwV15e1jgDS0EnpKVx7LIOIZ28MDN\n0brEMuNCfNh27AL/WxOFfyNHCos0B+JTOXAmlf1nUjmdnA2AjaUZM0Z0YGBAyQO01h9O4PC5dGaM\nCCxxxsYxt/gwZ9NxZm2MYdYDHa/Zn56Tz8MLI4g4mcz797Qvd+6hf7pELouMI7egEGsL8zLLX06S\nuxDi5rGyA7/bDS+A1Dg4sRliN+N8YhOPZq/hUWso2qfIjqqPnXMjsHcFe7d/X46NoJ6H4QFuPQ+w\nuTIhfrvzFNn5hTzcs/SBVUopPri3PQM/3cyoueGXtns3sCOgiRP3d/GmVUNHPt94jEeX7GZqPz+e\nDL2y2UVrzcwNR/FqYHtNt8V/ONla8tAtTfl84zFiEjJo4e5waV9KVh4Pzd/Jofg0Pr0/iMHtSz7H\n1W71d2fxjpOEH0+ml59bhY4BSe5CiKrk5Akd7je8tIaLsejYzYTtiOBcfBw9lKZpYRac3QuZSZCb\neu05rBwMSb6+NwWth7J0qwshLVyumcDsas72ViwY15ktR5No07gebT2ccLK7ckGMHi1defHn/Xy0\n7ghHEtKZfm8gtlaG2vKWmCT2xqXyzt0BZS5EMj7El/lbYvl8YwwzRnQAIDE9lwfnhXM8KZMvH+xE\naOuGFb5l3Zq5YG1hRlh0giR3IUQNoBQ08EU18KV34GimLNnNy1Hn+ezyWm1BLqSfhbSzhrnr0+KL\nX2cg4RAWvz7BSm1Lms0wOOcAjdqVeUn/RvXK/BKwtjDnw+GBtGroyP9+P8ypC1nMeSiYRk42fLYh\nhkb1bLinU5Myr+HiYM2ort4s2BbL06F+WFooRs0J52xqDvPHdKZHS9fruk22VuZ0b+7CxuhEXr2z\n4sdVaLEOpdQA4BPAHJirtf7fVfufASYABUAiMF5rfbKsc8piHUKIy+XkF/LgvHD+Pp3CwnFdCGlR\ndhLURUVM+3gO/bJW009vRxXmGvrddxoLbYcZmoQqYX3UeZ78bg/21hZM7t2cN347xCuD2zC+R/nz\n6pxPy6Hn+2H09nMj6mwaqVn5zB/XucyeMWX5elssr648SNizfWjm5mCclZiUUubAEaA/EAfsAu7X\nWh+6rExfIFxrnaWUmgL00VqPLOu8ktyFEFdLzcpnxJfbOZOSzfeTupXZF37niWRGfLndsKRfgCPs\n/Q4iFsCFo6DMwMIWzC3B3Kr4Vfy7vauhP75XV/DsAg6lN3VEn0vn4a93EXcxGxd7K7a8cOulZpry\n/HfFARbvOEl9O0sWj+9KgOeN9+s/dSGLXh+E8crgNjzcs5nRknt34DWt9e3F718E0Fq/W0r5IGCm\n1jqkrPNKchdClORcag73fLGN3IIifprSnaYu9iWWe2RxBOEnktk+LfTfhKs1nNwGx9YbmnQK84pf\n+f/+nnrG0KZflG84pkEzQ6L36mKo+bu1BvN/W6wvZOTyysqD9G/d8NIAqYo4n5bDu6ujmNKnRaXW\nz/1H6Icb8ahvyzcTulUouVekzb0JcPqy93FA1zLKPwysKWmHUmoSMAnA29u7ApcWQtQ1jZxs+Hp8\nF4bP3sZD83dyb0dPMnILSMspICO3gIycfDJyC4g4eZFH+zS/siatFPiEGF5lyc8pHmkbDqd3Qsw6\nQ80fDDX+xu3BoyM06YiLR0dm3dfBsKzhdWhYz4aP7wu6zk9fur6t3Fm0vczW7isY9YGqUmo0EAz0\nLmm/1vor4Csw1NyNeW0hRO3Rwt2B+WM7M2b+Tj788wg2lmY4WFviaGOBg7UFjjYWDApozPgKzCtf\nIksb8O5meEFxz50TEBcJ8bvhzG6IXAjhXxj22ziBowdY2l71sjO8PIIMa9k6VWw65BvR19+duVsq\nvi5tRZL7GcDrsveexduuoJTqB/wH6K21loUThRCVEuTtTMTL/VEKLMvoemgUShmaZxo0g/bDDdsK\nCyAxypDo4/dA1gXIzza8spINPwuyIScVIhcYjnHzhxb9oPmt0DTE8CViJME+zthXsL0fKpbcdwEt\nlVK+GJL6fcADlxcobmf/Ehigta7cqq5CCFHsn8UrTMLcAhoFGF6dxpReTmtIPGxo2olZDzvnwPaZ\nhuYdnxBo1hea9wX3NoYvkRtkbWFOz5ZuHCq/KFDxrpADgY8xdIWcr7V+Wyn1BhChtV6plFoHBABn\niw85pbUeUtY55YGqEKJWysuCk1sNiT5mnaH3DoBDQ2jWx5Dsm/UxzMlznQqLNBbmZsbpLXOzSHIX\nQtQJqXGGeXWOhRl+ZiUZtru0NEyL7NIcXFr8+7J3M9TwtYa8DMhIgMzESz9VlwlG6y0jhBDiRjl5\nQtBow6uoCM4fgONhcCocko7CkbX/dssEsHIEW2dDQi/IvuHLSnIXQoiqYmb278In//TWLCyA1NNw\n4RhciIHkY4aHtP9MnObgDvbuhsFW9u7wesUmHJPkLoQQpmRuAQ18Da+W/Yx2WlmsQwghaiFJ7kII\nUQtJchdCiFpIkrsQQtRCktyFEKIWkuQuhBC1kCR3IYSohSS5CyFELWSyuWWUUulAtEkuXn25Akmm\nDqIakftxJbkf16qL96Sp1rr0tQGLmXKEanRFJr+pS5RSEXJP/iX340pyP64l96R00iwjhBC1kCR3\nIYSohUyZ3L8y4bWrK7knV5L7cSW5H9eSe1IKkz1QFUIIcfNIs4wQQtRCJknuSqkBSqlopVSMUmqa\nKWIwJaXUfKVUglLqwGXbGiil/lRKHS3+6WzKGKuSUspLKRWmlDqklDqolHqqeHtdvic2SqmdSqm9\nxffk9eLtvkqp8OL/Oz8opaxMHWtVUkqZK6X2KKV+K35fp+9HWao8uSulzIFZwB1AG+B+pVSbqo7D\nxBYCA67aNg1Yr7VuCawvfl9XFAD/p7VuA3QDHiv+N1GX70kucKvWOhDoAAxQSnUD3gM+0lq3AC4C\nD5swRlN4Coi67H1dvx+lMkXNvQsQo7U+rrXOA74HhpogDpPRWm8Ckq/aPBT4uvj3r4G7qjQoE9Ja\nn9Va7y7+PR3Df94m1O17orXWGcVvLYtfGrgVWFa8vU7dE6WUJzAImFv8XlGH70d5TJHcmwCnL3sf\nV7ytrmuotT5b/Ps5oKEpgzEVpZQPEASEU8fvSXETxN9AAvAncAxI0VoXFBepa/93PgaeB4qK37tQ\nt+9HmeSBajWkDV2Y6lw3JqWUA/AT8LTWOu3yfXXxnmitC7XWHQBPDH/x+ps4JJNRSg0GErTWkaaO\npaYwxfQDZwCvy957Fm+r684rpRprrc8qpRpjqK3VGUopSwyJfYnW+ufizXX6nvxDa52ilAoDugP1\nlVIWxbXVuvR/JwQYopQaCNgA9YBPqLv3o1ymqLnvAloWP+W2Au4DVpogjupmJTCm+PcxwC8mjKVK\nFbedzgOitNYzLttVl++Jm1KqfvHvtkB/DM8iwoB7i4vVmXuitX5Ra+2ptfbBkDM2aK1HUUfvR0WY\nZBBT8bfvx4A5MF9r/XaVB2FCSqnvgD4YZrQ7D7wKrACWAt7ASWCE1vrqh661klKqB7AZ2M+/7akv\nYWh3r6v3pD2GB4TmGCphS7XWbyilmmHohNAA2AOM1lrnmi7SqqeU6gM8q7UeLPejdDJCVQghaiF5\noCqEELWQJHchhKiFJLkLIUQtJMldCCFqIUnuQghRC0lyF0KIWkiSuxBC1EKS3IUQohb6fzh2TURf\n69YbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fdd9a9d5898>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vSS8F1ExJW6x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記のようにAccuracyの値がぐっと良くなっていれば成功です。\n",
        "\n",
        "このように、ディープラーニングでは、BatchNormalizationを含めた細かなポイントがあったりするため、調べながら進めてみてください。\n",
        "Chainerでは、ほとんどの機能がすでに実装されているため、上記のコードのように少し付け加えるだけでその効果を検証できるため、非常に便利です。"
      ]
    },
    {
      "metadata": {
        "id": "0eI2lWlHJW6y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 学習済みモデルを保存\n",
        "\n",
        "学習が終わると、学習済みモデルが得られます。 Trainerのextensionsでsnapshotを取ることも可能ですが、今回は手動で学習済みモデルを保存する方法を紹介します。\n",
        "\n",
        "chainerで準備されている`serializers`のモジュールを使用すれば保存できます。\n",
        "保存の際には、モデルの名前と学習済みモデルを指定しましょう。"
      ]
    },
    {
      "metadata": {
        "id": "P9ULAPhsJW6y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chainer.serializers.save_npz('models/wine.npz', model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IOfUYaX3JW60",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "こちらでmodelsのフォルダ内に `wine.npz` というファイルができていれば学習済みモデルの保存が完了です。"
      ]
    },
    {
      "metadata": {
        "id": "3S71I8uDJW60",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 学習済みモデルを使用した推論"
      ]
    },
    {
      "metadata": {
        "id": "P7S2mFGLJW62",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習済みモデルのロード\n",
        "\n",
        "学習済みモデルは単にファイルをロードするだけでなく、まずはモデルの構造を明示しておき、そのモデルに対して、パラメータの値を当てはめながらロードしていくことになります。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "PGOU9O8VJW62",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = L.Classifier(NN())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Qk0oKI4JW64",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chainer.serializers.load_npz('models/wine.npz', model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JoDBUGYCJW65",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 予測値の計算\n",
        "\n",
        "今回は一番最初のサンプルに対する予測値を計算してみましょう。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Xg_rmiC2JW65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_new = x[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JJrWuE-JW66",
        "colab_type": "code",
        "outputId": "35b221c4-5a5f-4e14-9a30-6719a06d0904",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_new.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "metadata": {
        "id": "KPWy6gakJW67",
        "colab_type": "code",
        "outputId": "64879d93-b32a-4ae4-a6d8-42aeb6122843",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 予測値の計算\n",
        "y = model.predictor(x_new)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidType",
          "evalue": "\nInvalid operation is performed in: BatchNormalization (Forward)\n\nExpect: in_types[0].ndim >= in_types[1].ndim + 1\nActual: 1 < 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidType\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-755be9e0f1f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 予測値の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-86-73aafd83ba18>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 順伝播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Batch Normalizationの処理を追加\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/links/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             ret = functions.batch_normalization(\n\u001b[1;32m    143\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 running_var=self.avg_var, decay=decay)\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# Use running average statistics or fine-tuned statistics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/functions/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[0;34m(x, gamma, beta, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     return BatchNormalization(eps, running_mean, running_var, decay).apply(\n\u001b[0;32m--> 720\u001b[0;31m         (x, gamma, beta))[0]\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/function_node.py\u001b[0m in \u001b[0;36m_check_data_type_forward\u001b[0;34m(self, in_data)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0min_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in_types'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function_check_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/functions/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mcheck_type_forward\u001b[0;34m(self, in_types)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mgamma_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbeta_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mgamma_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbeta_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         )\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/utils/type_check.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(*bool_exprs)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexpr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbool_exprs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/utils/type_check.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    480\u001b[0m             raise InvalidType(\n\u001b[1;32m    481\u001b[0m                 \u001b[0;34m'{0} {1} {2}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                 '{0} {1} {2}'.format(left, self.inv, right))\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidType\u001b[0m: \nInvalid operation is performed in: BatchNormalization (Forward)\n\nExpect: in_types[0].ndim >= in_types[1].ndim + 1\nActual: 1 < 2"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lIYber0ZJW68",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "推論で使用する際には、`(バッチサイズ, 入力変数の数)` という形式となっていないとエラーが起きます。\n",
        "今回であれば、`(1, 10)`が望ましいデータの形といえます。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "hbzkAGmlJW6_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_new = x_new[np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5BmOjUFvJW7A",
        "colab_type": "code",
        "outputId": "8e5c92ba-5474-45b8-8a02-3ad3959bb62a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_new.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "metadata": {
        "id": "MqWjIhAEJW7G",
        "colab_type": "code",
        "outputId": "4f49178b-37be-458c-fc9e-d79f3dcc70b6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 予測値の計算\n",
        "y = model.predictor(x_new)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.5/dist-packages/chainer/functions/normalization/batch_normalization.py:67: UserWarning: A batch with no more than one sample has been given to F.batch_normalization. F.batch_normalization will always output a zero tensor for such batches. This could be caused by incorrect configuration in your code (such as running evaluation while chainer.config.train=True), but could also happen in the last batch of training if non-repeating iterator is used.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable([[-0.5496615 ,  0.19866087, -0.40578216]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "metadata": {
        "id": "nZp1tZuwJW7I",
        "colab_type": "code",
        "outputId": "34f8b056-8972-4941-ab9f-b6430990c3bd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = F.softmax(y)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variable([[0.234291  , 0.49516267, 0.27054632]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "id": "Qs7oqYV4JW7M",
        "colab_type": "code",
        "outputId": "116509bc-4dd1-42b4-97f6-44295578b14c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y.array"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.234291  , 0.49516267, 0.27054632]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {
        "id": "83qZ-EkeJW7N",
        "colab_type": "code",
        "outputId": "094fcaf1-0ecf-4821-b3bf-c8fa1074881f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.argmax(y.array)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "metadata": {
        "id": "hP3UzJcfJW7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このように学習済みモデルを使用した推論を実行できました。"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "0QGIoXQ_JW7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}