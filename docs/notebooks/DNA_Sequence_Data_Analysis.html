

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="ja" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="ja" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>7. 実践編: ディープラーニングを使った配列解析 &mdash; メディカルAIコース オンライン講義資料&lt;Paste&gt;  ドキュメント</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="検索" href="../search.html" />
    <link rel="next" title="8. 実践編: ディープラーニングを使ったモニタリングデータの時系列解析" href="Sequential_Data_Analysis_with_Deep_Learning.html" />
    <link rel="prev" title="6. 実践編: 血液の顕微鏡画像からの細胞検出" href="Blood_Cell_Detection.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> メディカルAIコース オンライン講義資料<Paste>
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Basic_Math_for_ML.html">1. 機械学習に必要な数学の基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_ML_libs.html">2. 機械学習ライブラリの基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_Neural_Network.html">3. ニューラルネットワークの基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="Introduction_to_Chainer.html">4. Deep Learningフレームワークの基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="Image_Segmentation.html">5. 実践編: MRI画像のセグメンテーション</a></li>
<li class="toctree-l1"><a class="reference internal" href="Blood_Cell_Detection.html">6. 実践編: 血液の顕微鏡画像からの細胞検出</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">7. 実践編: ディープラーニングを使った配列解析</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#環境構築">7.1. 環境構築</a></li>
<li class="toctree-l2"><a class="reference internal" href="#配列解析について">7.2. 配列解析について</a></li>
<li class="toctree-l2"><a class="reference internal" href="#データセット">7.3. データセット</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Dilated-Convolutionを用いた解析">7.4. Dilated Convolutionを用いた解析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#配列解析の戦略">7.4.1. 配列解析の戦略</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Dilated-Convolution">7.4.2. Dilated Convolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ブロック">7.4.3. ブロック</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Sequential_Data_Analysis_with_Deep_Learning.html">8. 実践編: ディープラーニングを使ったモニタリングデータの時系列解析</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">メディカルAIコース オンライン講義資料<Paste></a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>7. 実践編: ディープラーニングを使った配列解析</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/DNA_Sequence_Data_Analysis.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<p><a class="reference external" href="https://colab.research.google.com/github/japan-medical-ai/medical-ai-course-materials/blob/master/notebooks/DNA_Sequence_Data_Analysis.ipynb"><img alt="colab-logo" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="実践編:-ディープラーニングを使った配列解析">
<h1>7. 実践編: ディープラーニングを使った配列解析<a class="headerlink" href="#実践編:-ディープラーニングを使った配列解析" title="このヘッドラインへのパーマリンク">¶</a></h1>
<p>近年，次世代シーケンサ（NGS; Next Generation
Sequencer）の発展により，遺伝子の塩基配列が高速，大量，安価に読み取られるようになってきました．</p>
<p>ここではディープラーニングを用いて，DNA配列からエピジェネティックな影響や転写制御を予測する問題に取り組みます．ディープラーニングは複雑なモデルを表現でき，遠距離の影響も考慮することができます．この予測モデルを使うことで，ある遺伝子変異が遺伝子発現にどのような影響を与えるのかを予測することができるようになります．</p>
<div class="section" id="環境構築">
<h2>7.1. 環境構築<a class="headerlink" href="#環境構築" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>ここで用いるライブラリは</p>
<ul class="simple">
<li>Chainer</li>
<li>Cupy</li>
<li>matplotlib</li>
</ul>
<p>です．Google
Colab上では，以下のようにしてインストールすることができます．以下のセルを実行（Shit+Enter）してください．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>!set -ex
!apt -y -q install cuda-libraries-dev-9-2
!pip install cupy-cuda92==6.0.0a1
!pip install chainer==6.0.0a1
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Reading package lists...
Building dependency tree...
Reading state information...
The following additional packages will be installed:
  cuda-cublas-dev-9-2 cuda-cufft-dev-9-2 cuda-curand-dev-9-2
  cuda-cusolver-dev-9-2 cuda-cusparse-dev-9-2 cuda-npp-dev-9-2
  cuda-nvgraph-dev-9-2 cuda-nvrtc-dev-9-2
The following NEW packages will be installed:
  cuda-cublas-dev-9-2 cuda-cufft-dev-9-2 cuda-curand-dev-9-2
  cuda-cusolver-dev-9-2 cuda-cusparse-dev-9-2 cuda-libraries-dev-9-2
  cuda-npp-dev-9-2 cuda-nvgraph-dev-9-2 cuda-nvrtc-dev-9-2
0 upgraded, 9 newly installed, 0 to remove and 7 not upgraded.
Need to get 332 MB of archives.
After this operation, 972 MB of additional disk space will be used.
Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cublas-dev-9-2 9.2.148.1-1 [50.4 MB]
Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cufft-dev-9-2 9.2.148-1 [106 MB]
Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-curand-dev-9-2 9.2.148-1 [57.8 MB]
Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cusolver-dev-9-2 9.2.148-1 [8,184 kB]
Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-cusparse-dev-9-2 9.2.148-1 [27.8 MB]
Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-nvrtc-dev-9-2 9.2.148-1 [9,348 B]
Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-nvgraph-dev-9-2 9.2.148-1 [30.1 MB]
Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-npp-dev-9-2 9.2.148-1 [52.0 MB]
Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  cuda-libraries-dev-9-2 9.2.148-1 [2,598 B]
Fetched 332 MB in 6s (51.9 MB/s)
Selecting previously unselected package cuda-cublas-dev-9-2.
(Reading database ... 26397 files and directories currently installed.)
Preparing to unpack .../0-cuda-cublas-dev-9-2_9.2.148.1-1_amd64.deb ...
Unpacking cuda-cublas-dev-9-2 (9.2.148.1-1) ...
Selecting previously unselected package cuda-cufft-dev-9-2.
Preparing to unpack .../1-cuda-cufft-dev-9-2_9.2.148-1_amd64.deb ...
Unpacking cuda-cufft-dev-9-2 (9.2.148-1) ...
Selecting previously unselected package cuda-curand-dev-9-2.
Preparing to unpack .../2-cuda-curand-dev-9-2_9.2.148-1_amd64.deb ...
Unpacking cuda-curand-dev-9-2 (9.2.148-1) ...
Selecting previously unselected package cuda-cusolver-dev-9-2.
Preparing to unpack .../3-cuda-cusolver-dev-9-2_9.2.148-1_amd64.deb ...
Unpacking cuda-cusolver-dev-9-2 (9.2.148-1) ...
Selecting previously unselected package cuda-cusparse-dev-9-2.
Preparing to unpack .../4-cuda-cusparse-dev-9-2_9.2.148-1_amd64.deb ...
Unpacking cuda-cusparse-dev-9-2 (9.2.148-1) ...
Selecting previously unselected package cuda-nvrtc-dev-9-2.
Preparing to unpack .../5-cuda-nvrtc-dev-9-2_9.2.148-1_amd64.deb ...
Unpacking cuda-nvrtc-dev-9-2 (9.2.148-1) ...
Selecting previously unselected package cuda-nvgraph-dev-9-2.
Preparing to unpack .../6-cuda-nvgraph-dev-9-2_9.2.148-1_amd64.deb ...
Unpacking cuda-nvgraph-dev-9-2 (9.2.148-1) ...
Selecting previously unselected package cuda-npp-dev-9-2.
Preparing to unpack .../7-cuda-npp-dev-9-2_9.2.148-1_amd64.deb ...
Unpacking cuda-npp-dev-9-2 (9.2.148-1) ...
Selecting previously unselected package cuda-libraries-dev-9-2.
Preparing to unpack .../8-cuda-libraries-dev-9-2_9.2.148-1_amd64.deb ...
Unpacking cuda-libraries-dev-9-2 (9.2.148-1) ...
Setting up cuda-npp-dev-9-2 (9.2.148-1) ...
Setting up cuda-curand-dev-9-2 (9.2.148-1) ...
Setting up cuda-nvrtc-dev-9-2 (9.2.148-1) ...
Setting up cuda-cusolver-dev-9-2 (9.2.148-1) ...
Setting up cuda-cufft-dev-9-2 (9.2.148-1) ...
Setting up cuda-cusparse-dev-9-2 (9.2.148-1) ...
Setting up cuda-cublas-dev-9-2 (9.2.148.1-1) ...
Setting up cuda-nvgraph-dev-9-2 (9.2.148-1) ...
Setting up cuda-libraries-dev-9-2 (9.2.148-1) ...
Collecting cupy-cuda92==6.0.0a1
  Downloading https://files.pythonhosted.org/packages/51/8a/b18c425488fb7ed3a42662767363b822de697f9bcfca19eb3fa980e07817/cupy_cuda92-6.0.0a1-cp27-cp27mu-manylinux1_x86_64.whl (260.4MB)
    100% |████████████████████████████████| 260.4MB 77kB/s
Collecting fastrlock&gt;=0.3 (from cupy-cuda92==6.0.0a1)
  Downloading https://files.pythonhosted.org/packages/d4/e6/6d198d91ae20353140563ba32eac2efba236446aa6cf73b2d652d9d9d038/fastrlock-0.4-cp27-cp27mu-manylinux1_x86_64.whl
Requirement already satisfied: numpy&gt;=1.9.0 in /usr/local/lib/python2.7/dist-packages (from cupy-cuda92==6.0.0a1) (1.14.6)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python2.7/dist-packages (from cupy-cuda92==6.0.0a1) (1.11.0)
Installing collected packages: fastrlock, cupy-cuda92
Successfully installed cupy-cuda92-6.0.0a1 fastrlock-0.4
Collecting chainer==6.0.0a1
  Downloading https://files.pythonhosted.org/packages/64/53/970152ecb9684a96950b81323b6511bfcc169b5c3981c2c2611579179955/chainer-6.0.0a1.tar.gz (517kB)
    100% |████████████████████████████████| 522kB 20.3MB/s
Collecting filelock (from chainer==6.0.0a1)
  Downloading https://files.pythonhosted.org/packages/2a/bd/6a87635dba4906ae56377b22f64805b2f00d8cafb26e411caaf3559a5475/filelock-3.0.10.tar.gz
Requirement already satisfied: numpy&gt;=1.9.0 in /usr/local/lib/python2.7/dist-packages (from chainer==6.0.0a1) (1.14.6)
Requirement already satisfied: protobuf&gt;=3.0.0 in /usr/local/lib/python2.7/dist-packages (from chainer==6.0.0a1) (3.6.1)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python2.7/dist-packages (from chainer==6.0.0a1) (1.11.0)
Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf&gt;=3.0.0-&gt;chainer==6.0.0a1) (40.6.2)
Building wheels for collected packages: chainer, filelock
  Running setup.py bdist_wheel for chainer ... - \ | / - done
  Stored in directory: /root/.cache/pip/wheels/06/17/03/677a942d2d45e98fa9d137d6dd5de27a9d8351f52fa2b37af0
  Running setup.py bdist_wheel for filelock ... - done
  Stored in directory: /root/.cache/pip/wheels/46/b3/26/8803692ec1f1729fcf201583b5de74f112da1f1488f36e47b0
Successfully built chainer filelock
Installing collected packages: filelock, chainer
Successfully installed chainer-6.0.0a1 filelock-3.0.10
</pre></div></div>
</div>
<p>インストールが完了したら，以下のセルを実行して，各ライブラリのバージョンを確認してください．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>import chainer
import cupy
import matplotlib

chainer.print_runtime_info()
print(&#39;matplotlib:&#39;, matplotlib.__version__)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Platform: Linux-4.14.65+-x86_64-with-Ubuntu-18.04-bionic
Chainer: 6.0.0a1
NumPy: 1.14.6
CuPy:
  CuPy Version          : 6.0.0a1
  CUDA Root             : /usr/local/cuda
  CUDA Build Version    : 9020
  CUDA Driver Version   : 9020
  CUDA Runtime Version  : 9020
  cuDNN Build Version   : 7201
  cuDNN Version         : 7201
  NCCL Build Version    : 2213
iDeep: Not Available
(&#39;matplotlib:&#39;, &#39;2.1.2&#39;)
</pre></div></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">Platform</span><span class="p">:</span> <span class="n">Linux</span><span class="o">-</span><span class="mf">4.14</span><span class="o">.</span><span class="mi">65</span><span class="o">+-</span><span class="n">x86_64</span><span class="o">-</span><span class="k">with</span><span class="o">-</span><span class="n">Ubuntu</span><span class="o">-</span><span class="mf">18.04</span><span class="o">-</span><span class="n">bionic</span>
<span class="n">Chainer</span><span class="p">:</span> <span class="mf">6.0</span><span class="o">.</span><span class="mi">0</span><span class="n">a1</span>
<span class="n">NumPy</span><span class="p">:</span> <span class="mf">1.14</span><span class="o">.</span><span class="mi">6</span>
<span class="n">CuPy</span><span class="p">:</span>
  <span class="n">CuPy</span> <span class="n">Version</span>          <span class="p">:</span> <span class="mf">6.0</span><span class="o">.</span><span class="mi">0</span><span class="n">a1</span>
  <span class="n">CUDA</span> <span class="n">Root</span>             <span class="p">:</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span>
  <span class="n">CUDA</span> <span class="n">Build</span> <span class="n">Version</span>    <span class="p">:</span> <span class="mi">9020</span>
  <span class="n">CUDA</span> <span class="n">Driver</span> <span class="n">Version</span>   <span class="p">:</span> <span class="mi">9020</span>
  <span class="n">CUDA</span> <span class="n">Runtime</span> <span class="n">Version</span>  <span class="p">:</span> <span class="mi">9020</span>
  <span class="n">cuDNN</span> <span class="n">Build</span> <span class="n">Version</span>   <span class="p">:</span> <span class="mi">7201</span>
  <span class="n">cuDNN</span> <span class="n">Version</span>         <span class="p">:</span> <span class="mi">7201</span>
  <span class="n">NCCL</span> <span class="n">Build</span> <span class="n">Version</span>    <span class="p">:</span> <span class="mi">2213</span>
<span class="n">iDeep</span><span class="p">:</span> <span class="n">Not</span> <span class="n">Available</span>
<span class="p">(</span><span class="s1">&#39;matplotlib:&#39;</span><span class="p">,</span> <span class="s1">&#39;2.1.2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="配列解析について">
<h2>7.2. 配列解析について<a class="headerlink" href="#配列解析について" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>次世代シーケンサの発展・普及とともに，大量の遺伝子配列が読み取られるようになりました．そうした中で，塩基配列で表現された遺伝子型と病気や形態などの表現型との関係を推定するようなGWAS（Genome
Wide Association Study;
ゲノムワイド関連解析）が行われてきましたが，遺伝子の変異だけでは全ての表現型の変化を説明できないことがわかってきました．特に，非翻訳領域が遺伝子発現に影響を与え，表現型の変化を生じさせていることが様々な実験結果からわかってきています．遺伝子発現時に周辺領域がどのように影響を与えているのかを調べるために様々な手法が提案されています．</p>
<div class="figure" id="id8">
<img alt="エピゲノム解析概略図(Encode Projectより引用)" src="https://www.encodeproject.org/images/c45f4d8c-0340-4fcb-abe3-e4ff0bb919be/&#64;&#64;download/attachment/EncodeDatatypes2013-7.png" />
<p class="caption"><span class="caption-text">エピゲノム解析概略図(Encode Projectより引用)</span></p>
</div>
<p>例えば，ChIP-Seq（クロマチン免疫沈降）は，転写調節因子やそのほかのタンパク質が直接の相互作用を起こすDNAの特定部位を分離し，それらをシーケンシングして同定し，どの程度出現していたかを定量化します．これにより，タンパク質のDNA中の結合部位を正確かつ効率的に同定することができます．</p>
<p>このような技術で抽出された配列を学習データとして利用し，DNA配列のみからそこが結合部位かどうかだけでなく，どの程度，出現していたのかというカバレッジ値を推定します．例えば，修飾ヒストンのChiPの学習データを利用した場合はDNA配列を入力としてそのどこがヒストン修飾サイトであるかを推定できるようになります，様々な種類の実験データを学習データと用いることでDNA配列から，転写因子，クロマチンアクセシビリティ，ヒストン修飾を予測することができるようになり，様々な遺伝子変異に対する有益な洞察を与えてくれます．</p>
<p>一方で，DNA配列中のどの領域がそのような特徴を持つのかを調べるためには非常に遠距離のDNA配列も必要である場合が多く，これが機械学習による解析を困難としていました．今回紹介する手法はこのような遠距離の関係を捉えるため，10万超の長さのDNA配列を入力として受け取り，128
bpごとにその領域がどの程度各手法で発現していたのか，カバレッジ値を予測するタスクを考えます．</p>
</div>
<div class="section" id="データセット">
<h2>7.3. データセット<a class="headerlink" href="#データセット" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>ここでは，Basenji[1]で使われた実験データセットの一部を利用します.これらはCAGEなどの配列解析した結果に作られたデータ・セットです．</p>
<p>下のセルを実行してデータをダウンロードしてください．</p>
<p>この配列はそれぞれが長さ131072からなり，128塩基毎に対しそのカバレッジ値が記録されています．このカバレッジ値の配列の長さは131072/128=1024です．</p>
<p>この問題の目標は長さ131072の配列を入力として受け取った時に，この128塩基毎のカバレッジ値を推定することが目標です．</p>
<p>今回は10種類の異なる実験のカバレッジ値を同時に予測する問題を扱います．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>!wget https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--2018-12-03 19:34:11--  https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5
Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113
Connecting to github.com (github.com)|192.30.253.112|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/c79a0800-f713-11e8-8d6c-255563d45b1b?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181203%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20181203T193412Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=ceb275d8272fc12568fd7fad12a9b708b9d9bd084ad0cac0db633bf7608948b8&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;response-content-disposition=attachment%3B%20filename%3Dseq.h5&amp;response-content-type=application%2Foctet-stream [following]
--2018-12-03 19:34:12--  https://github-production-release-asset-2e65be.s3.amazonaws.com/153412006/c79a0800-f713-11e8-8d6c-255563d45b1b?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181203%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20181203T193412Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=ceb275d8272fc12568fd7fad12a9b708b9d9bd084ad0cac0db633bf7608948b8&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;response-content-disposition=attachment%3B%20filename%3Dseq.h5&amp;response-content-type=application%2Foctet-stream
Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.236.27
Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.236.27|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 594118876 (567M) [application/octet-stream]
Saving to: ‘seq.h5’

seq.h5              100%[===================&gt;] 566.60M  29.8MB/s    in 19s

2018-12-03 19:34:31 (29.7 MB/s) - ‘seq.h5’ saved [594118876/594118876]

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>!ls -lh
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
total 567M
drwxr-xr-x 2 root root 4.0K Nov 29 18:21 sample_data
-rw-r--r-- 1 root root 567M Dec  3 06:54 seq.h5
</pre></div></div>
</div>
<p>data.h5というファイルが正しくダウンロードされているかを確認してください．サイズは567MBです．</p>
<p>data.h5はHDF5形式でデータを格納したファイルです．HDF5ファイルは，ファイルシステムと同様に，階層的にデータを格納することができ，行列やテンソルデータをそれぞれの位置で名前付きで格納することができます．</p>
<p>HDF5形式のファイルを操作するためにh5pyというライブラリがあります．h5pyのFile()関数でファイルを開き，keys()関数でその中に含まれているキーを列挙します．また取得したキーを’[]’内で指定することでそのキーに紐付けられて格納されている各データを参照することができます．</p>
<p>テンソルデータはnumpyと同様にshapeという属性でそのサイズを取得することができます．</p>
<p>以下のセルを実行して格納されているデータを確認してください．</p>
<p>各データの名前にtrain（学習），validate（検証），test（テスト）の接頭辞がつけられ，inが入力の塩基配列，outが出力のカバレッジ値に対応します．</p>
<p>例えば，’train_in’は学習用の入力データであり(6240, 131072,
4)というサイズを持ちます．これは長さが130172からなる配列が6240個あり，それぞれA,
T, C, Gの対応する次元の値が1, それ以外は0であるような配列です．</p>
<p>また,‘train_out’は学習用の出力データであり,（’6240, 1024,
3’)というサイズを持ちます.これは長さが1024からなる配列が6240個あり,それぞれが3種類の異なるChipSeqの結果のカバレッジ値が格納されています.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>import h5py
import numpy as np

with h5py.File(&#39;seq.h5&#39;, &#39;r&#39;) as hf:
    for key in hf.keys():
        print(key, hf[key].shape, hf[key].dtype)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(u&#39;target_labels&#39;, (10,), dtype(&#39;S29&#39;))
(u&#39;test_in&#39;, (500, 131072, 4), dtype(&#39;bool&#39;))
(u&#39;test_out&#39;, (500, 1024, 10), dtype(&#39;&lt;f2&#39;))
(u&#39;train_in&#39;, (5000, 131072, 4), dtype(&#39;bool&#39;))
(u&#39;train_out&#39;, (5000, 1024, 10), dtype(&#39;&lt;f2&#39;))
(u&#39;valid_in&#39;, (500, 131072, 4), dtype(&#39;bool&#39;))
(u&#39;valid_out&#39;, (500, 1024, 10), dtype(&#39;&lt;f2&#39;))
</pre></div></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="sa">u</span><span class="s1">&#39;target_labels&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,),</span> <span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;S29&#39;</span><span class="p">))</span>
<span class="p">(</span><span class="sa">u</span><span class="s1">&#39;test_in&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">131072</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;bool&#39;</span><span class="p">))</span>
<span class="p">(</span><span class="sa">u</span><span class="s1">&#39;test_out&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;&lt;f2&#39;</span><span class="p">))</span>
<span class="p">(</span><span class="sa">u</span><span class="s1">&#39;train_in&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">131072</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;bool&#39;</span><span class="p">))</span>
<span class="p">(</span><span class="sa">u</span><span class="s1">&#39;train_out&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;&lt;f2&#39;</span><span class="p">))</span>
<span class="p">(</span><span class="sa">u</span><span class="s1">&#39;valid_in&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">131072</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;bool&#39;</span><span class="p">))</span>
<span class="p">(</span><span class="sa">u</span><span class="s1">&#39;valid_out&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;&lt;f2&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>h5py形式のファイルをnumpyデータとして扱うには，コピーする必要があります．以下のコードは’train_in’というキーに対応するテンソルデータをnumpyデータとして読み出し，そのデータを一部を表示します．</p>
<p>試しに最初のデータを取り出して，それの出力の値を表示してみます．</p>
<p>下のセルを実行してみてください．最初のデータの出力の三つの値を線グラフで出力します．（ここまでのセルを実行していてください）．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>%matplotlib inline
import matplotlib.pyplot as plt

with h5py.File(&#39;seq.h5&#39;) as hf:
    y = hf[&#39;train_out&#39;][:100]
    fig_size = plt.rcParams[&quot;figure.figsize&quot;]
    fig_size[0] = 20
    fig_size[1] = 5
    for i in range(3):
        plt.bar(range(y.shape[1]), y[0,:,i])
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_DNA_Sequence_Data_Analysis_15_0.png" src="../_images/notebooks_DNA_Sequence_Data_Analysis_15_0.png" />
</div>
</div>
</div>
<div class="section" id="Dilated-Convolutionを用いた解析">
<h2>7.4. Dilated Convolutionを用いた解析<a class="headerlink" href="#Dilated-Convolutionを用いた解析" title="このヘッドラインへのパーマリンク">¶</a></h2>
<div class="section" id="配列解析の戦略">
<h3>7.4.1. 配列解析の戦略<a class="headerlink" href="#配列解析の戦略" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>今回は配列データが入力であるような問題である．</p>
<p>配列データを扱うためには大きく３つの戦略があります．</p>
<p>一つ目は，配列中の順序情報は捨てて，配列をその特徴の集合とみなすことです．これはBag
of
Words（BoW）表現とよびます．このBoW表現は特徴に十分情報が含まれていれば強力な手法ですがDNA配列のような4種類の文字からなる配列やその部分配列だけではその特徴を捉えることは困難です．</p>
<p>二つ目は配列中の要素を左から右に順に読み込んでいき計算していく手法です．これは4章でも少し触れたRNNを用いて解析します．RNNは各時刻毎に入力を一つずつ読み取り内部状態を更新していきます．RNNの問題点はその計算が逐次的であり計算量が配列長に比例するという点です．現在の計算機は計算を並列化することで高速化を達成していますがRNNは計算を並列化することが困難です．もう一つの問題は遠距離間の関係を捉えることが難しいという点です．RNNはその計算方式から，計算の途中結果を全て固定長の内部状態ベクトルに格納する必要があります．遠距離間の関係を捉えようとすると，多くの情報を覚えておかなければなりませんが状態ベクトルサイズは有限なので，遠距離間の関係を捉えることが困難となっていきます．</p>
<p>三つ目は配列データを1次元の画像とみなし，画像処理の時と同様にCNNを用いて解析する手法です．CNNはRNNの場合と違って各位置の処理を独立に実行できるため並列に処理することができます．また，後述するDilated
Convolutionを使うことで各位置の処理は遠距離にある情報を直接読み取ることができます．次の章でDilated
Convolutionについてさらに詳しくみていきます．</p>
</div>
<div class="section" id="Dilated-Convolution">
<h3>7.4.2. Dilated Convolution<a class="headerlink" href="#Dilated-Convolution" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>従来の畳み込み層を使って配列解析をする場合を考えてみます．
以下の図のようにある位置の入力の情報は各層で隣接する位置からしか読み込まれません．どのくらい離れた位置から情報を取得するかはカーネルサイズによって決定され，カーネルサイズがKの時，Dだけ離れた距離にある情報を取得するためにはD/K層必要となります．今回の問題の場合Dは数百から数万，Kは3や5といった値ですので必要な層数も百から万といった数になってしまい現実的ではありません．</p>
<div class="figure" id="id9">
<img alt="従来の畳み込み層の計算イメージ" src="http://musyoku.github.io/images/post/2016-09-17/naive_conv.png" />
<p class="caption"><span class="caption-text">従来の畳み込み層の計算イメージ</span></p>
</div>
<p><a class="reference external" href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">WaveNet: A Generative Model for Raw
Audio</a>より引用</p>
<p>それに対し，Dilated Convolution（atrous convolutionやconvolution weith
holesともよばれます）は読み取る場所をずらしたところからうけとります．例えばDilation=4の場合，4だけ離れた位置から情報を受け取ります．このDilatedを倍々にしていき，カーネルサイズを2とした場合，Dだけ離れた位置の情報を受取るには
log_2
D層だけ必要になります．今回のDが数百から数万の場合，10から20層程度あれば済むことになります．</p>
<p>今回はこのDilated
Convolutionを使うことで遠距離にある情報を考慮できるモデルを作成します．</p>
<div class="figure" id="id10">
<img alt="Dilated Convolutionの計算イメージ" src="https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif" />
<p class="caption"><span class="caption-text">Dilated Convolutionの計算イメージ</span></p>
</div>
<p><a class="reference external" href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">WAVENET: A GENERATIVE MODEL FOR RAW AUDIO,
blog</a>より</p>
</div>
<div class="section" id="ブロック">
<h3>7.4.3. ブロック<a class="headerlink" href="#ブロック" title="このヘッドラインへのパーマリンク">¶</a></h3>
<p>それでは最初に，ネットワークの全体を設計します．
このネットワークは二つのブロックから構成されます．</p>
<p>１つ目のブロックは長さが<span class="math">\(2^{17}\)</span>から配列を入力として長さが<span class="math">\(2^{10}\)</span>のベクトルを出力とします．これにより入力の128
bpが出力の1つの位置に対応するようになります．これを実現しているのが，SqueezeBlockです．</p>
<p>二つ目のブロックは遠距離にある情報を考慮して各ベクトルの値を計算していく部分であり，DilatedBlockが担当します．</p>
<p>それでは，以下のコードを実行してみましょう．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>import chainer
import chainer.functions as F
import chainer.links as L
import cupy as cp

bc = 24 # base channel

default_squeeze_params = [
    # out_ch, kernel, stride, dropout
    [bc*2, 21, 2, 0], #1 128 -&gt; 64
    [int(bc*2.5), 7, 4, 0.05], #2  64 -&gt; 16
    [int(bc*3.2), 7, 4, 0.05], #3  16 -&gt; 4
    [bc*4, 7, 4, 0.05]  #4  4 -&gt; 1
]


default_dilated_params = [
# out_ch, kernel, dilated
  [bc, 3, 1, 0.1],
  [bc, 3, 2, 0.1],
  [bc, 3, 4, 0.1],
  [bc, 3, 8, 0.1],
  [bc, 3, 16, 0.1],
  [bc, 3, 32, 0.1],
  [bc, 3, 64, 0.1]
]


class Net(chainer.Chain):

    def __init__(self, squeeze_params=default_squeeze_params, dilated_params=default_dilated_params, n_targets=10):
        super(Net, self).__init__()
        self._n_squeeze = len(squeeze_params)
        self._n_dilated = len(dilated_params)
        with self.init_scope():
            in_ch = 4
            for i, param in enumerate(squeeze_params):
                out_ch, kernel, stride, do_rate = param
                setattr(self, &quot;s_{}&quot;.format(i), SqueezeBlock(in_ch, out_ch, kernel, stride, do_rate))
                in_ch = out_ch
            for i, param in enumerate(dilated_params):
                out_ch, kernel, dilated, do_rate = param
                setattr(self, &quot;d_{}&quot;.format(i), DilatedBlock(in_ch, out_ch, kernel, dilated, do_rate))
                in_ch += out_ch
            self.l = L.ConvolutionND(1, None, n_targets, 1)

    def forward(self, x):
        # x : (B, X, 4)
        xp = cp.get_array_module(x)
        h = xp.transpose(x, (0, 2, 1))
        h = h.astype(xp.float32)

        for i in range(self._n_squeeze):
            h = self[&quot;s_{}&quot;.format(i)](h)

        hs = [h]
        for i in range(self._n_dilated):
            h = self[&quot;d_{}&quot;.format(i)](hs)
            hs.append(h)

        h = self.l(F.concat(hs, axis=1))
        h = xp.transpose(h, (0, 2, 1))
        return h
</pre></div>
</div>
</div>
<p>このネットワークは初期化時の引数としてSqueezeBlockに関するパラメータと，DilatedBlockに関するパラメータを受け取ります．</p>
<p>それぞれ，出力チャンネル，カーネルサイズ，プーリングの三つ組からなるリストと，出力チャンネル，カーネルサイズ，dilatedサイズの三つ組からなるリストを受け取ります．</p>
<p>次に，ブロックの定義をします．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>import chainer
import chainer.functions as F
import chainer.links as L
import cupy as cp

class WNConvolutionND(L.ConvolutionND):
    def __init__(self, *args, **kwargs):
        super(WNConvolutionND, self).__init__(*args, **kwargs)
        self.add_param(&#39;g&#39;, self.W.data.shape[0])
        norm = np.linalg.norm(self.W.data.reshape(
            self.W.data.shape[0], -1), axis=1)
        self.g.data[...] = norm

    def __call__(self, x):
        norm = F.batch_l2_norm_squared(self.W) ** 0.5
        channel_size = self.W.data.shape[0]
        norm_broadcasted = F.broadcast_to(
            F.reshape(norm, (channel_size, 1, 1)), self.W.data.shape)
        g_broadcasted = F.broadcast_to(
            F.reshape(norm, (channel_size, 1, 1)), self.W.data.shape)
        return F.convolution_nd(
            x, g_broadcasted * self.W / norm_broadcasted, self.b, self.stride,
            self.pad, self.cover_all, self.dilate)

class SqueezeBlock(chainer.Chain):
    def __init__(self, in_ch, out_ch, kernel, stride, do_rate):
        super(SqueezeBlock, self).__init__()

        self.do_rate = do_rate
        with self.init_scope():
            pad = kernel // 2
            self.conv = WNConvolutionND(1, in_ch, out_ch*2, kernel, pad=pad, stride=stride)

    def forward(self, x):
        h = self.conv(x)
        h, g = F.split_axis(h, 2, 1)
        h = F.dropout(h * F.sigmoid(g), self.do_rate)
        return h

class DilatedBlock(chainer.Chain):
     def __init__(self, in_ch, out_ch, kernel, dilate, do_rate):
        super(DilatedBlock, self).__init__()
        self.do_rate = do_rate
        with self.init_scope():
            self.conv = WNConvolutionND(1, in_ch, out_ch*2, kernel, pad=dilate, dilate=dilate)

     def forward(self, xs):
        x = F.concat(xs, axis=1)
        h = self.conv(x)
        h, g = F.split_axis(h, 2, 1)
        h = F.dropout(h * F.sigmoid(g), self.do_rate)
        return h

</pre></div>
</div>
</div>
<p>WeightNormalizationはパラメータの表現を長さと向きに分解して表現する手法で，今回の系列問題のような場合に使われる正規化法です．コード中ではWeightNormalizationが適用された畳み込み層である<code class="docutils literal"><span class="pre">WNConvolutionND</span></code>が定義されています.</p>
<p>SqueezeBlockは配列を縮めていき，長さが<span class="math">\(2^{17}\)</span>の配列を<span class="math">\(2^{10}\)</span>に縮めるためのブロックです．
1次元配列を扱うためWNConvolutionNDを使い，最初の引数で1次元配列であることを示す<code class="docutils literal"><span class="pre">1</span></code>を指定しています．
また，活性化関数では<span class="math">\(h = Wx * sigmoid(Ux)\)</span>と表されるGated
Linear
Unitを利用しています．これは，2倍のチャンネル数を持つ出力を計算した後にチャンネルをそれぞれ半分にし<span class="math">\((Wx, Ux)\)</span>片方にsigmoid関数を適用しています．</p>
<p>DilatedBlockはすでに長さ1024の長さになった配列に対し，Dilated
Convolutionを使って遠距離にある情報も使って計算していく部分です．引数としてdilatedを受け取ります．Dilated
Convolutionを使う場合は通常のConvolution層（今回はConvolutionNDだが，Convolution2Dも同様）の引数にdilatedを加えるだけで計算できます．</p>
<p>また，計算の際は入力結果に現在の結果を足しこみます．これはResNetと呼ばれるネットワークで提案された手法です．これにより，学習がしやすくなります．</p>
<p>それでは，試しにネットワークを構築して，そこにサンプルデータを流してみましょう．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>import numpy as np
n = Net()
size = 131072 # 128 * 1024
batchsize = 4
x = np.empty((batchsize, size, 4), dtype=np.bool)
y = n.forward(x)
print(y.shape)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(4, 1024, 10)
</pre></div></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>ここで，もともとバッチサイズ(B)=4, 入力長(L)=131072,
入力チャンネル数(C)=4だった配列が計算後はB=4, L=1024,
C=3の配列となりました．</p>
<p>今回の学習では対数ポアソン損失関数を利用します．これはモデルはポアソン分布の唯一のパラメータである平均を出力し，そのポアソン分布を学習データを使った最尤推定をします．この際，学習対象パラメータ以外は無視しています．
また，この最適化関数の最小値はそのままだと<span class="math">\(0\)</span>にはならので，最小値である<span class="math">\(t \log t\)</span>をひいておき，損失関数の最小値が<span class="math">\(0\)</span>となるようにします．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>import chainer.functions as F
import math
import sklearn
import numpy as np

def log_poisson_loss(log_x, t):
    #return F.mean(F.exp(log_x) - t * log_
    loss =  F.mean(F.exp(log_x) - t * log_x)
    t = chainer.cuda.to_cpu(t.astype(np.float32))
    offset = F.mean(cp.array(t - t * np.ma.log(t)))
    return loss - offset


def log_r2_score(log_x, t):
    return F.r2_score(F.exp(log_x), t)
</pre></div>
</div>
</div>
<p>また，学習率の調整にCosineSchedulerを使います．ニューラルネットワークの学習では，徐々に学習率を小さくしていくと，より汎化性能の高い解を見つけられることがわかっています．焼きなまし法のように最初は学習率を高くして極小解にはまらないようにし，後半は徐々に学習率を0に近づけていき収束させるというものです．
CosineSchedulerはCosine関数の0度から90度までの変化のように学習率を変化させます．また学習は初期が不安定なので最初にn_warmup回，学習率を0から初期学習率まで線形に増やしていきます．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>from chainer import training
import numpy as np
import math

class CosineScheduler(training.Extension):

    def __init__(self, attr=&#39;lr&#39;, init_val=0.0001, n_decays=200, n_warmups=3, target=None, optimizer=None):
        self._attr = attr
        self._target = target
        self._optimizer = optimizer
        self._min_loss = None
        self._last_value = None
        self._init_val = init_val
        self._n_decays = n_decays - n_warmups
        self._decay_count = 0
        self._n_warmups = n_warmups

    def __call__(self, trainer):
        updater = trainer.updater
        optimizer = self._get_optimizer(trainer)
        epoch = updater.epoch
        if epoch &lt; self._n_warmups:
            value = self._init_val / (self._n_warmups + 1) * (epoch + 1)
        else:
            value = 0.5 * self._init_val * (1 + math.cos(math.pi * (epoch - self._n_warmups) / self._n_decays))
        self._update_value(optimizer, value)


    def _get_optimizer(self, trainer):
        return self._optimizer or trainer.updater.get_optimizer(&#39;main&#39;)

    def _update_value(self, optimizer, value):
        setattr(optimizer, self._attr, value)
        self._last_value = value
</pre></div>
</div>
</div>
<p>最後に学習中に訓練データに意味を変えない変化を加えるData
Augmentationを適用します．これは画像において回転させたり，平行移動させたりする場合と同じです．
まず，入力配列を反転させたものを入力としても出力を反転させたものと一致するはずなので0.5の確率で入力と出力を同時に反転させます．また，今回は128bp毎にカバレッジ値を予測していますが，数塩基（例えば4~8など）移動したとしてもカバレッジ値は同じ程度になることが規定されます．そこで最大max_shift分だけ配列を前後にシフトします（完全にランダムな塩基配列を余った部分に入れると実際の塩基配列の分布と変わる可能性があるのでここではroll()関数を巡回シフトしています）．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>import chainer
import random

class PreprocessedDataset(chainer.dataset.DatasetMixin):

    def __init__(self, xs, ys, max_shift):
        self.xs = xs
        self.ys = ys
        self.max_shift = max_shift

    def __len__(self):
        return len(self.xs)

    def get_example(self, i):
        # It applies following preprocesses:
        #     - Cropping
        #     - Random flip

        x = self.xs[i]
        y = self.ys[i]


        s = random.randint(-self.max_shift, self.max_shift)
        x = np.roll(x, s, axis=0)
        return x, y
</pre></div>
</div>
</div>
<p>これで全部準備ができました．残りはchainerのtrainerを改造して学習するだけです．以下のコードを実行してください．</p>
<p>元々のデータ全体では学習に時間がかかるので，データ/<code class="docutils literal"><span class="pre">ratio</span></code>分だけを学習，検証用データとして利用します．今回<code class="docutils literal"><span class="pre">ratio</span></code>は1に設定されています．この場合30分程度で学習が完了します．短い時間で試したい方はratio=1をratio=10やratio=20として実験してみてください．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>import chainer
import chainer.functions as F
import chainer.links as L
import numpy as np
from chainer.training import extensions
from chainer import training
import h5py

ml_h5 = h5py.File(&#39;seq.h5&#39;)e

train_x = ml_h5[&#39;train_in&#39;]
train_y = ml_h5[&#39;train_out&#39;]

valid_x = ml_h5[&#39;valid_in&#39;]
valid_y = ml_h5[&#39;valid_out&#39;]

test_x = ml_h5[&#39;test_in&#39;]
test_y = ml_h5[&#39;test_out&#39;]

ratio = 1
train_x = train_x[:len(train_x)//ratio]
train_y = train_y[:len(train_y)//ratio]
valid_x = valid_x[:len(valid_x)//ratio]
valid_y = valid_y[:len(valid_y)//ratio]


max_shift_for_data_augmentation = 5
train = PreprocessedDataset(train_x, train_y, max_shift_for_data_augmentation)
val = chainer.datasets.TupleDataset(valid_x, valid_y)

batchsize = 8

train_iter = chainer.iterators.SerialIterator(train, batchsize)
val_iter = chainer.iterators.SerialIterator(val, batchsize, repeat=False, shuffle=False)

model = L.Classifier(Net(), lossfun=log_poisson_loss, accfun=log_r2_score)

lr = 0.001
optimizer = chainer.optimizers.Adam(alpha=lr, beta1=0.97, beta2=0.98)
optimizer.setup(model)
optimizer.add_hook(chainer.optimizer_hooks.GradientClipping(threshold=0.01))


updater = training.updaters.StandardUpdater(
     train_iter, optimizer, device=0)

n_epochs = 10
n_warmups = 0
out = &quot;out&quot;
trainer = training.Trainer(updater, (n_epochs, &#39;epoch&#39;), out=out)
trainer.extend(CosineScheduler(attr=&#39;alpha&#39;, init_val=lr, n_decays=n_epochs, n_warmups=n_warmups), trigger=(1, &#39;epoch&#39;))

trainer.extend(extensions.Evaluator(val_iter, model, device = 0))
trainer.extend(extensions.LogReport(trigger=(0.2, &#39;epoch&#39;)))
trainer.extend(extensions.snapshot_object(model, &#39;model_epoch_{.updater.epoch}&#39;), trigger=(1, &#39;epoch&#39;))

trainer.extend(extensions.PrintReport(
          [&#39;epoch&#39;, &#39;main/loss&#39;, &#39;validation/main/loss&#39;, &#39;elapsed_time&#39;]), trigger = (0.1, &#39;epoch&#39;))

# trainer.extend(extensions.ProgressBar())

trainer.run()

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
epoch       main/loss   validation/main/loss  elapsed_time
0           2.0873                            63.4775
0           1.94705                           109.895
0           1.89719                           156.686
0           1.85084                           202.743
1           1.77888     1.86543               258.092
1           1.78996                           304.509
1           1.78814                           350.91
1           1.74196                           396.958
1           1.73552                           443.75
2           1.75989     1.746                 498.737
2           1.77673                           544.786
2           1.73285                           591.564
2           1.69361                           637.962
2           1.59723                           684.382
3           1.67331     1.70796               739.356
3           1.68685                           785.395
3           1.62153                           832.188
3           1.70951                           878.581
3           1.60378                           925.019
4           1.65392     1.69343               980.008
4           1.63665                           1026.45
4           1.66334                           1072.52
4           1.61375                           1119.34
4           1.60533                           1165.77
5           1.58547     1.68659               1220.76
5           1.62216                           1267.17
5           1.53686                           1313.22
5           1.66557                           1360.02
5           1.62918                           1406.44
6           1.53379     1.63333               1461.43
6           1.56805                           1507.85
6           1.60791                           1553.91
6           1.55378                           1600.67
6           1.5594                            1647.1
7           1.6058      1.62044               1702.11
7           1.57387                           1748.55
7           1.54682                           1794.97
7           1.55528                           1841.4
7           1.57045                           1887.83
8           1.58875     1.62074               1942.82
8           1.56817                           1989.25
8           1.57042                           2035.68
8           1.57602                           2082.11
8           1.54231                           2128.17
9           1.53811     1.61316               2183.5
9           1.55894                           2229.94
9           1.53187                           2276.37
9           1.57317                           2322.8
9           1.55031                           2368.86
</pre></div></div>
</div>
<p>学習が成功したならば，ディレクトリのout以下に学習されたモデルが出力されているはずです．実際にモデルが出力されているのかを確認しましょう．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>!ls -l out/
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
total 14168
-rw-r--r-- 1 root root   10468 Dec  3 20:15 log
-rw-r--r-- 1 root root 1445790 Dec  3 19:40 model_epoch_1
-rw-r--r-- 1 root root 1447771 Dec  3 20:16 model_epoch_10
-rw-r--r-- 1 root root 1446082 Dec  3 19:44 model_epoch_2
-rw-r--r-- 1 root root 1446744 Dec  3 19:48 model_epoch_3
-rw-r--r-- 1 root root 1447061 Dec  3 19:52 model_epoch_4
-rw-r--r-- 1 root root 1447356 Dec  3 19:56 model_epoch_5
-rw-r--r-- 1 root root 1447450 Dec  3 20:00 model_epoch_6
-rw-r--r-- 1 root root 1447525 Dec  3 20:04 model_epoch_7
-rw-r--r-- 1 root root 1447743 Dec  3 20:08 model_epoch_8
-rw-r--r-- 1 root root 1447760 Dec  3 20:12 model_epoch_9
</pre></div></div>
</div>
<p>次に，学習したモデルを用いてテストデータに対しても予測してみます．次のようにして学習が終わったモデルを読み込み，テストデータに対してモデルを適用してみましょう．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>import chainer
import chainer.links as L
%matplotlib inline
import matplotlib.pyplot as plt

model_n_epoch = 10
out_dir = &#39;out&#39;
model = L.Classifier(Net())
chainer.serializers.load_npz(&#39;{}/model_epoch_{}&#39;.format(out_dir, model_n_epoch), model)
predictor = model.predictor

print(len(test_x))
with chainer.no_backprop_mode():
    test_y_estimated = F.exp(predictor(test_x[:1]))

test_y = test_y[:1]

print(test_y_estimated.shape)
print(test_y_estimated[0,:,0])


</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
500
(1, 1024, 10)
variable([1.7427167 1.7872047 1.7081542 ... 0.8705853 0.7520541 0.6031048])
</pre></div></div>
</div>
<p>結果を抜粋して表示してみましょう．ここでは3つ目（i=2）の出力について正解と推定結果を出力しています．今回の場合でも，学習データを絞り（クラス数を10とした），学習回数も少ないですが，ピークをか捉えられていることがわかると思います．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [21]:
</pre></div>
</div>
<div class="input_area highlight-none"><div class="highlight"><pre>
<span></span>y = test_y_estimated.data
fig_size = plt.rcParams[&quot;figure.figsize&quot;]
fig_size[0] = 20
fig_size[1] = 10
i = 0
b1 = plt.bar(range(y.shape[1]), y[0,:,i])
b2 = plt.bar(range(y.shape[1]), test_y[0,:,i])
plt.legend((b1, b2), (&#39;estimated&#39;, &#39;observed&#39;))

</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[21]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&lt;matplotlib.legend.Legend at 0x7f30e6b6d590&gt;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_DNA_Sequence_Data_Analysis_44_1.png" src="../_images/notebooks_DNA_Sequence_Data_Analysis_44_1.png" />
</div>
</div>
<p>時間に余裕があれば学習のn_epochsを60から200程度に増やしたり，総数を増やしたり，チャンネル数を増やしたり，学習データ数（ratio=20をratio=5などにして）に増やしたりして，より高精度なモデルが学習できるのかを調べてみましょう．</p>
<p>[1] “Sequential regulatory activity prediction across chromosomes with
convolutional neural networks”, D. R. Kelly and et al., Genome Res.
2018. 28: 739-750</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Sequential_Data_Analysis_with_Deep_Learning.html" class="btn btn-neutral float-right" title="8. 実践編: ディープラーニングを使ったモニタリングデータの時系列解析" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Blood_Cell_Detection.html" class="btn btn-neutral" title="6. 実践編: 血液の顕微鏡画像からの細胞検出" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Preferred Networks &amp; キカガク

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'',
              LANGUAGE:'ja',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/translations.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>